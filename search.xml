<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[pt-online-schema-change的安装]]></title>
    <url>%2F2019%2F07%2F01%2Fpt-online-schema-change%E7%9A%84%E5%AE%89%E8%A3%85%2Fpt-online-schema-change%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[12345678910111213# 下载[root@localhost admin]# wget percona.com/get/percona-toolkit.tar.gz# 解压[root@localhost admin]# tar -zvxf percona-toolkit.tar.gz[root@localhost admin]# cd percona-toolkit-3.0.13/# 安装perl依赖[root@localhost percona-toolkit-3.0.13]# yum install perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker[root@localhost percona-toolkit-3.0.13]# perl Makefile.PL# 编译安装[root@localhost percona-toolkit-3.0.13]# make[root@localhost percona-toolkit-3.0.13]# make install# 验证[root@localhost percona-toolkit-3.0.13]# pt-online-schema-change 若报错 缺少perl-Digest-MD5包， 安装perl-Digest-MD5即可解决 1[root@localhost percona-toolkit-3.0.13]# yum -y install perl-Digest-MD5 其他情况，同理。 出现如下结果，成功。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot@Component注解下的类无法@Autowired的问题]]></title>
    <url>%2F2019%2F06%2F26%2FSpringBoot%40Component%E6%B3%A8%E8%A7%A3%E4%B8%8B%E7%9A%84%E7%B1%BB%E6%97%A0%E6%B3%95%40Autowired%E7%9A%84%E9%97%AE%E9%A2%98%2FSpringBoot%40Component%E6%B3%A8%E8%A7%A3%E4%B8%8B%E7%9A%84%E7%B1%BB%E6%97%A0%E6%B3%95%40Autowired%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[这个问题心累在把我的一个非Web程序迁移从Spring迁移到SpringBoot时，出现了在@Component注解下@Autowired的类为null的情况，也就是没注入成功，或者说是此类在bean加载之前就被调用了。 试了各种办法，修改扫描包，修改@Component注解等等，皆未成功，后来看到了一个方法，探究了一下。 123456789101112@Componentpublic class ComponentClass &#123; @Autowired private JedisClient jedisClient; public static ComponentClass componentClass; @PostConstruct public void init()&#123; componentClass = this; componentClass.jedisClient = this.jedisClient; &#125;&#125; 声明一个此类的静态变量，用以保存bean。 使用@PostConstruct注解，将需要注入的类添加到静态变量中。 接下来，使用这个静态变量来调用注入类就行了。 @PostConstruct这个注解的具体作用就是： 注解在方法上，表示此方法是在Spring实例化该bean之后马上执行此方法，之后才会去实例化其他bean。 这样在Spring实例化ComponentClass之后，马上执行此方法，初始化ComponentClass静态对象和成员变量jedisClient。]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>注入问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Amazon Linux下解决shadowsocks服务端EVP_CIPHER_CTX_cleanup() 函数报错]]></title>
    <url>%2F2019%2F06%2F24%2FAmazon-Linux%E4%B8%8B%E8%A7%A3%E5%86%B3shadowsocks%E6%9C%8D%E5%8A%A1%E7%AB%AFEVP-CIPHER-CTX-cleanup-%E5%87%BD%E6%95%B0%E6%8A%A5%E9%94%99%2FAmazon-Linux%E4%B8%8B%E8%A7%A3%E5%86%B3shadowsocks%E6%9C%8D%E5%8A%A1%E7%AB%AFEVP-CIPHER-CTX-cleanup-%E5%87%BD%E6%95%B0%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[Amazon Linux下解决shadowsocks服务端EVP_CIPHER_CTX_cleanup() 函数报错Amazon Linux的openssl版本高于1.1.0以上版本，导致shadowsocks服务出现undefined symbol: EVP_CIPHER_CTX_cleanup 错误而无法启动。 1234567891011121314151617181920212223242526Traceback (most recent call last): File &quot;/root/miniconda3/bin/ssserver&quot;, line 10, in &lt;module&gt; sys.exit(main()) File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/server.py&quot;, line 34, in main config = shell.get_config(False) File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/shell.py&quot;, line 262, in get_config check_config(config, is_local) File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/shell.py&quot;, line 124, in check_config encrypt.try_cipher(config[&apos;password&apos;], config[&apos;method&apos;]) File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/encrypt.py&quot;, line 44, in try_cipher Encryptor(key, method) File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/encrypt.py&quot;, line 83, in __init__ random_string(self._method_info[1])) File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/encrypt.py&quot;, line 109, in get_cipher return m[2](method, key, iv, op) File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/crypto/rc4_md5.py&quot;, line 33, in create_cipher return openssl.OpenSSLCrypto(b&apos;rc4&apos;, rc4_key, b&apos;&apos;, op) File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/crypto/openssl.py&quot;, line 76, in __init__ load_openssl() File &quot;/root/miniconda3/lib/python3.7/site-packages/shadowsocks/crypto/openssl.py&quot;, line 52, in load_openssl libcrypto.EVP_CIPHER_CTX_cleanup.argtypes = (c_void_p,) File &quot;/root/miniconda3/lib/python3.7/ctypes/__init__.py&quot;, line 369, in __getattr__ func = self.__getitem__(name) File &quot;/root/miniconda3/lib/python3.7/ctypes/__init__.py&quot;, line 374, in __getitem__ func = self._FuncPtr((name_or_ordinal, self))AttributeError: /root/miniconda3/lib/python3.7/lib-dynload/../../libcrypto.so.1.1: undefined symbol: EVP_CIPHER_CTX_cleanup 这是由于在openssl 1.1.0中废弃了 EVP_CIPHER_CTX_cleanup() 函数而引入了 EVE_CIPHER_CTX_reset() 函数所导致的： EVP_CIPHER_CTX was made opaque in OpenSSL 1.1.0. As a result, EVP_CIPHER_CTX_reset() appeared and EVP_CIPHER_CTX_cleanup() disappeared. EVP_CIPHER_CTX_init() remains as an alias for EVP_CIPHER_CTX_reset(). 因此，可以通过将 EVP_CIPHER_CTX_cleanup() 函数替换为 EVP_CIPHER_CTX_reset() 函数来解决该问题。具体解决方法如下： 根据错误信息定位到文件/root/miniconda3/lib/python3.7/site-packages/shadowsocks/crypto/openssl.py。 搜索 cleanup 并将其替换为 reset 。 12[root]vi /root/miniconda3/lib/python3.7/site-packages/shadowsocks/crypto/openssl.py[root]/cleanup ​ 不止一处，替换完。 重新启动 shadowsocks, 该问题解决。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shdowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot+Thymeleaf配置外部静态资源访问]]></title>
    <url>%2F2019%2F06%2F23%2FSpringBoot-Thymeleaf%E9%85%8D%E7%BD%AE%E5%A4%96%E9%83%A8%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE%2FSpringBoot-Thymeleaf%E9%85%8D%E7%BD%AE%E5%A4%96%E9%83%A8%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[#####配置外部资源访问（html、css、js） 我的thymeleaf配置： 12345678910# thymeleaf# html目录配置spring.thymeleaf.prefix=file:d:/tt/templates/spring.thymeleaf.suffix=.htmlspring.thymeleaf.cache=falsespring.thymeleaf.servlet.content-type=text/htmlspring.thymeleaf.enabled=truespring.thymeleaf.encoding=UTF-8# 一代填 spring.thymeleaf.mode=HTML5spring.thymeleaf.mode=HTML css与js静态资源访问通过实现WebMvcConfigurer来配置： 如下配置文件的方式无法访问到： 12spring.mvc.static-path-pattern=/**#spring.resources.static-locations= classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/,file:d:/tt/static/ MVCConfig： 1234567@Configuration //申明这是一个配置@EnableWebMvcpublic class MySrpingMVCConfig implements WebMvcConfigurer &#123; public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/**").addResourceLocations("file:d:/tt/static/"); &#125;&#125; html文件： 123456789101112131415// 引入头&lt;html xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;title&gt;AdminLTE 2 | Dashboard&lt;/title&gt; &lt;meta content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no" name="viewport"&gt; &lt;!-- Bootstrap 3.3.7 --&gt;// bower_components/bootstrap/dist/css/bootstrap.min.css位于static目录下 &lt;link rel="stylesheet" href="../static/bower_components/bootstrap/dist/css/bootstrap.min.css" th:href="@&#123;bower_components/bootstrap/dist/css/bootstrap.min.css&#125;"&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt;&lt;/html&gt; 这样所有的前端页面就在项目之外了。]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>thymeleaf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring boot属性配置列表]]></title>
    <url>%2F2019%2F06%2F17%2FSpring-boot%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE%E5%88%97%E8%A1%A8%2FSpring-boot%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[可以在application.properties/application.yml文件中指定各种属性，也可以在命令行开关中指定。 记录一下，方便查看，来源（spring.io） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194# ===================================================================# COMMON SPRING BOOT PROPERTIES## This sample file is provided as a guideline. Do NOT copy it in its# entirety to your own application. ^^^# ===================================================================# ----------------------------------------# CORE PROPERTIES# ----------------------------------------# BANNERbanner.charset=UTF-8 # Banner file encoding.banner.location=classpath:banner.txt # Banner file location.banner.image.location=classpath:banner.gif # Banner image file location (jpg/png can also be used).banner.image.width= # Width of the banner image in chars (default 76)banner.image.height= # Height of the banner image in chars (default based on image height)banner.image.margin= # Left hand image margin in chars (default 2)banner.image.invert= # If images should be inverted for dark terminal themes (default false)# LOGGINGlogging.config= # Location of the logging configuration file. For instance `classpath:logback.xml` for Logbacklogging.exception-conversion-word=%wEx # Conversion word used when logging exceptions.logging.file= # Log file name. For instance `myapp.log`logging.level.*= # Log levels severity mapping. For instance `logging.level.org.springframework=DEBUG`logging.path= # Location of the log file. For instance `/var/log`logging.pattern.console= # Appender pattern for output to the console. Only supported with the default logback setup.logging.pattern.file= # Appender pattern for output to the file. Only supported with the default logback setup.logging.pattern.level= # Appender pattern for log level (default %5p). Only supported with the default logback setup.logging.register-shutdown-hook=false # Register a shutdown hook for the logging system when it is initialized.# AOPspring.aop.auto=true # Add @EnableAspectJAutoProxy.spring.aop.proxy-target-class= # Whether subclass-based (CGLIB) proxies are to be created (true) as opposed to standard Java interface-based proxies (false). Defaults to &quot;true&quot; when using Spring Transaction Management, otherwise &quot;false&quot;.# IDENTITY (ContextIdApplicationContextInitializer)spring.application.index= # Application index.spring.application.name= # Application name.# ADMIN (SpringApplicationAdminJmxAutoConfiguration)spring.application.admin.enabled=false # Enable admin features for the application.spring.application.admin.jmx-name=org.springframework.boot:type=Admin,name=SpringApplication # JMX name of the application admin MBean.# AUTO-CONFIGURATIONspring.autoconfigure.exclude= # Auto-configuration classes to exclude.# SPRING COREspring.beaninfo.ignore=true # Skip search of BeanInfo classes.# SPRING CACHE (CacheProperties)spring.cache.cache-names= # Comma-separated list of cache names to create if supported by the underlying cache manager.spring.cache.caffeine.spec= # The spec to use to create caches. Check CaffeineSpec for more details on the spec format.spring.cache.couchbase.expiration=0 # Entry expiration in milliseconds. By default the entries never expire.spring.cache.ehcache.config= # The location of the configuration file to use to initialize EhCache.spring.cache.guava.spec= # The spec to use to create caches. Check CacheBuilderSpec for more details on the spec format.spring.cache.infinispan.config= # The location of the configuration file to use to initialize Infinispan.spring.cache.jcache.config= # The location of the configuration file to use to initialize the cache manager.spring.cache.jcache.provider= # Fully qualified name of the CachingProvider implementation to use to retrieve the JSR-107 compliant cache manager. Only needed if more than one JSR-107 implementation is available on the classpath.spring.cache.type= # Cache type, auto-detected according to the environment by default.# SPRING CONFIG - using environment property only (ConfigFileApplicationListener)spring.config.location= # Config file locations.spring.config.name=application # Config file name.# HAZELCAST (HazelcastProperties)spring.hazelcast.config= # The location of the configuration file to use to initialize Hazelcast.# PROJECT INFORMATION (ProjectInfoProperties)spring.info.build.location=classpath:META-INF/build-info.properties # Location of the generated build-info.properties file.spring.info.git.location=classpath:git.properties # Location of the generated git.properties file.# JMXspring.jmx.default-domain= # JMX domain name.spring.jmx.enabled=true # Expose management beans to the JMX domain.spring.jmx.server=mbeanServer # MBeanServer bean name.# Email (MailProperties)spring.mail.default-encoding=UTF-8 # Default MimeMessage encoding.spring.mail.host= # SMTP server host. For instance `smtp.example.com`spring.mail.jndi-name= # Session JNDI name. When set, takes precedence to others mail settings.spring.mail.password= # Login password of the SMTP server.spring.mail.port= # SMTP server port.spring.mail.properties.*= # Additional JavaMail session properties.spring.mail.protocol=smtp # Protocol used by the SMTP server.spring.mail.test-connection=false # Test that the mail server is available on startup.spring.mail.username= # Login user of the SMTP server.# APPLICATION SETTINGS (SpringApplication)spring.main.banner-mode=console # Mode used to display the banner when the application runs.spring.main.sources= # Sources (class name, package name or XML resource location) to include in the ApplicationContext.spring.main.web-environment= # Run the application in a web environment (auto-detected by default).# FILE ENCODING (FileEncodingApplicationListener)spring.mandatory-file-encoding= # Expected character encoding the application must use.# INTERNATIONALIZATION (MessageSourceAutoConfiguration)spring.messages.always-use-message-format=false # Set whether to always apply the MessageFormat rules, parsing even messages without arguments.spring.messages.basename=messages # Comma-separated list of basenames, each following the ResourceBundle convention.spring.messages.cache-seconds=-1 # Loaded resource bundle files cache expiration, in seconds. When set to -1, bundles are cached forever.spring.messages.encoding=UTF-8 # Message bundles encoding.spring.messages.fallback-to-system-locale=true # Set whether to fall back to the system Locale if no files for a specific Locale have been found.# OUTPUTspring.output.ansi.enabled=detect # Configure the ANSI output.# PID FILE (ApplicationPidFileWriter)spring.pid.fail-on-write-error= # Fail if ApplicationPidFileWriter is used but it cannot write the PID file.spring.pid.file= # Location of the PID file to write (if ApplicationPidFileWriter is used).# PROFILESspring.profiles.active= # Comma-separated list (or list if using YAML) of active profiles.spring.profiles.include= # Unconditionally activate the specified comma separated profiles (or list of profiles if using YAML).# SENDGRID (SendGridAutoConfiguration)spring.sendgrid.api-key= # SendGrid api key (alternative to username/password).spring.sendgrid.username= # SendGrid account username.spring.sendgrid.password= # SendGrid account password.spring.sendgrid.proxy.host= # SendGrid proxy host.spring.sendgrid.proxy.port= # SendGrid proxy port.# ----------------------------------------# WEB PROPERTIES# ----------------------------------------# EMBEDDED SERVER CONFIGURATION (ServerProperties)server.address= # Network address to which the server should bind to.server.compression.enabled=false # If response compression is enabled.server.compression.excluded-user-agents= # List of user-agents to exclude from compression.server.compression.mime-types=text/html,text/xml,text/plain,text/css,text/javascript,application/javascript # Comma-separated list of MIME types that should be compressed.server.compression.min-response-size=2048 # Minimum response size that is required for compression to be performed.server.connection-timeout= # Time in milliseconds that connectors will wait for another HTTP request before closing the connection. When not set, the connector&apos;s container-specific default will be used. Use a value of -1 to indicate no (i.e. infinite) timeout.server.context-parameters.*= # Servlet context init parameters. For instance `server.context-parameters.a=alpha`server.context-path= # Context path of the application.server.display-name=application # Display name of the application.server.max-http-header-size=0 # Maximum size in bytes of the HTTP message header.server.error.include-stacktrace=never # When to include a &quot;stacktrace&quot; attribute.server.error.path=/error # Path of the error controller.server.error.whitelabel.enabled=true # Enable the default error page displayed in browsers in case of a server error.server.jetty.acceptors= # Number of acceptor threads to use.server.jetty.max-http-post-size=0 # Maximum size in bytes of the HTTP post or put content.server.jetty.selectors= # Number of selector threads to use.server.jsp-servlet.class-name=org.apache.jasper.servlet.JspServlet # The class name of the JSP servlet.server.jsp-servlet.init-parameters.*= # Init parameters used to configure the JSP servletserver.jsp-servlet.registered=true # Whether or not the JSP servlet is registeredserver.port=8080 # Server HTTP port.server.server-header= # Value to use for the Server response header (no header is sent if empty)server.servlet-path=/ # Path of the main dispatcher servlet.server.use-forward-headers= # If X-Forwarded-* headers should be applied to the HttpRequest.server.session.cookie.comment= # Comment for the session cookie.server.session.cookie.domain= # Domain for the session cookie.server.session.cookie.http-only= # &quot;HttpOnly&quot; flag for the session cookie.server.session.cookie.max-age= # Maximum age of the session cookie in seconds.server.session.cookie.name= # Session cookie name.server.session.cookie.path= # Path of the session cookie.server.session.cookie.secure= # &quot;Secure&quot; flag for the session cookie.server.session.persistent=false # Persist session data between restarts.server.session.store-dir= # Directory used to store session data.server.session.timeout= # Session timeout in seconds.server.session.tracking-modes= # Session tracking modes (one or more of the following: &quot;cookie&quot;, &quot;url&quot;, &quot;ssl&quot;).server.ssl.ciphers= # Supported SSL ciphers.server.ssl.client-auth= # Whether client authentication is wanted (&quot;want&quot;) or needed (&quot;need&quot;). Requires a trust store.server.ssl.enabled= # Enable SSL support.server.ssl.enabled-protocols= # Enabled SSL protocols.server.ssl.key-alias= # Alias that identifies the key in the key store.server.ssl.key-password= # Password used to access the key in the key store.server.ssl.key-store= # Path to the key store that holds the SSL certificate (typically a jks file).server.ssl.key-store-password= # Password used to access the key store.server.ssl.key-store-provider= # Provider for the key store.server.ssl.key-store-type= # Type of the key store.server.ssl.protocol=TLS # SSL protocol to use.server.ssl.trust-store= # Trust store that holds SSL certificates.server.ssl.trust-store-password= # Password used to access the trust store.server.ssl.trust-store-provider= # Provider for the trust store.server.ssl.trust-store-type= # Type of the trust store.server.tomcat.accept-count= # Maximum queue length for incoming connection requests when all possible request processing threads are in use.server.tomcat.accesslog.buffered=true # Buffer output such that it is only flushed periodically.server.tomcat.accesslog.directory=logs # Directory in which log files are created. Can be relative to the tomcat base dir or absolute.server.tomcat.accesslog.enabled=false # Enable access log.server.tomcat.accesslog.file-date-format=.yyyy-MM-dd # Date format to place in log file name.server.tomcat.accesslog.pattern=common # Format pattern for access logs.server.tomcat.accesslog.prefix=access_log # Log file name prefix.server.tomcat.accesslog.rename-on-rotate=false # Defer inclusion of the date stamp in the file name until rotate time.server.tomcat.accesslog.request-attributes-enabled=false # Set request attributes for IP address, Hostname, protocol and port used for the request.server.tomcat.accesslog.rotate=true # Enable access log rotation.server.tomcat.accesslog.suffix=.log # Log file name suffix.server.tomcat.additional-tld-skip-patterns= # Comma-separated list of additional patterns that match jars to ignore for TLD scanning.server.tomcat.background-processor-delay=30 # Delay in seconds between the invocation of backgroundProcess methods.server.tomcat.basedir= # Tomcat base directory. If not specified a temporary directory will be used.server.tomcat.internal-proxies=10\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 192\\.168\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 169\\.254\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 127\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 172\\.1[6-9]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 172\\.2[0-9]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 172\\.3[0-1]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125; # regular expression matching trusted IP addresses.server.tomcat.max-connections= # Maximum number of connections that the server will accept and process at any given time.server.tomcat.max-http-post-size=0 # Maximum size in bytes of the HTTP post content.server.tomcat.max-threads=0 # Maximum amount of worker threads.server.tomcat.min-spare-threads=0 # Minimum amount of worker threads.server.tomcat.port-header=X-Forwarded-Port # Name of the HTTP header used to override the original port value.server.tomcat.protocol-header= # Header that holds the incoming protocol, usually named &quot;X-Forwarded-Proto&quot;.server.tomcat.protocol-header-https-value=https # Value of the protocol header that indicates that the incoming request uses SSL.server.tomcat.redirect-context-root= # Whether requests to the context root should be redirected by appending a / to the path.server.tomcat.remote-ip-header= # Name of the http header from which the remote ip is extracted. For instance `X-FORWARDED-FOR`server.tomcat.uri-encoding=UTF-8 # Character encoding to use to decode the URI.server.undertow.accesslog.dir= # Undertow access log directory.server.undertow.accesslog.enabled=false # Enable access log.server.undertow.accesslog.pattern=common # Format pattern for access logs.server.undertow.accesslog.prefix=access_log. # Log file name prefix.server.undertow.accesslog.rotate=true # Enable access log rotation.server.undertow.accesslog.suffix=log # Log file name suffix.server.undertow.buffer-size= # Size of each buffer in bytes.server.undertow.direct-buffers= # Allocate buffers outside the Java heap.server.undertow.io-threads= # Number of I/O threads to create for the worker.server.undertow.max-http-post-size=0 # Maximum size in bytes of the HTTP post content.server.undertow.worker-threads= # Number of worker threads.# FREEMARKER (FreeMarkerAutoConfiguration)spring.freemarker.allow-request-override=false # Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.freemarker.allow-session-override=false # Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.freemarker.cache=false # Enable template caching.spring.freemarker.charset=UTF-8 # Template encoding.spring.freemarker.check-template-location=true # Check that the templates location exists.spring.freemarker.content-type=text/html # Content-Type value.spring.freemarker.enabled=true # Enable MVC view resolution for this technology.spring.freemarker.expose-request-attributes=false # Set whether all request attributes should be added to the model prior to merging with the template.spring.freemarker.expose-session-attributes=false # Set whether all HttpSession attributes should be added to the model prior to merging with the template.spring.freemarker.expose-spring-macro-helpers=true # Set whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.spring.freemarker.prefer-file-system-access=true # Prefer file system access for template loading. File system access enables hot detection of template changes.spring.freemarker.prefix= # Prefix that gets prepended to view names when building a URL.spring.freemarker.request-context-attribute= # Name of the RequestContext attribute for all views.spring.freemarker.settings.*= # Well-known FreeMarker keys which will be passed to FreeMarker&apos;s Configuration.spring.freemarker.suffix=.ftl # Suffix that gets appended to view names when building a URL.spring.freemarker.template-loader-path=classpath:/templates/ # Comma-separated list of template paths.spring.freemarker.view-names= # White list of view names that can be resolved.# GROOVY TEMPLATES (GroovyTemplateAutoConfiguration)spring.groovy.template.allow-request-override=false # Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.groovy.template.allow-session-override=false # Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.groovy.template.cache= # Enable template caching.spring.groovy.template.charset=UTF-8 # Template encoding.spring.groovy.template.check-template-location=true # Check that the templates location exists.spring.groovy.template.configuration.*= # See GroovyMarkupConfigurerspring.groovy.template.content-type=test/html # Content-Type value.spring.groovy.template.enabled=true # Enable MVC view resolution for this technology.spring.groovy.template.expose-request-attributes=false # Set whether all request attributes should be added to the model prior to merging with the template.spring.groovy.template.expose-session-attributes=false # Set whether all HttpSession attributes should be added to the model prior to merging with the template.spring.groovy.template.expose-spring-macro-helpers=true # Set whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.spring.groovy.template.prefix= # Prefix that gets prepended to view names when building a URL.spring.groovy.template.request-context-attribute= # Name of the RequestContext attribute for all views.spring.groovy.template.resource-loader-path=classpath:/templates/ # Template path.spring.groovy.template.suffix=.tpl # Suffix that gets appended to view names when building a URL.spring.groovy.template.view-names= # White list of view names that can be resolved.# SPRING HATEOAS (HateoasProperties)spring.hateoas.use-hal-as-default-json-media-type=true # Specify if application/hal+json responses should be sent to requests that accept application/json.# HTTP message conversionspring.http.converters.preferred-json-mapper=jackson # Preferred JSON mapper to use for HTTP message conversion. Set to &quot;gson&quot; to force the use of Gson when both it and Jackson are on the classpath.# HTTP encoding (HttpEncodingProperties)spring.http.encoding.charset=UTF-8 # Charset of HTTP requests and responses. Added to the &quot;Content-Type&quot; header if not set explicitly.spring.http.encoding.enabled=true # Enable http encoding support.spring.http.encoding.force= # Force the encoding to the configured charset on HTTP requests and responses.spring.http.encoding.force-request= # Force the encoding to the configured charset on HTTP requests. Defaults to true when &quot;force&quot; has not been specified.spring.http.encoding.force-response= # Force the encoding to the configured charset on HTTP responses.spring.http.encoding.mapping= # Locale to Encoding mapping.# MULTIPART (MultipartProperties)spring.http.multipart.enabled=true # Enable support of multi-part uploads.spring.http.multipart.file-size-threshold=0 # Threshold after which files will be written to disk. Values can use the suffixed &quot;MB&quot; or &quot;KB&quot; to indicate a Megabyte or Kilobyte size.spring.http.multipart.location= # Intermediate location of uploaded files.spring.http.multipart.max-file-size=1MB # Max file size. Values can use the suffixed &quot;MB&quot; or &quot;KB&quot; to indicate a Megabyte or Kilobyte size.spring.http.multipart.max-request-size=10MB # Max request size. Values can use the suffixed &quot;MB&quot; or &quot;KB&quot; to indicate a Megabyte or Kilobyte size.spring.http.multipart.resolve-lazily=false # Whether to resolve the multipart request lazily at the time of file or parameter access.# JACKSON (JacksonProperties)spring.jackson.date-format= # Date format string or a fully-qualified date format class name. For instance `yyyy-MM-dd HH:mm:ss`.spring.jackson.default-property-inclusion= # Controls the inclusion of properties during serialization.spring.jackson.deserialization.*= # Jackson on/off features that affect the way Java objects are deserialized.spring.jackson.generator.*= # Jackson on/off features for generators.spring.jackson.joda-date-time-format= # Joda date time format string. If not configured, &quot;date-format&quot; will be used as a fallback if it is configured with a format string.spring.jackson.locale= # Locale used for formatting.spring.jackson.mapper.*= # Jackson general purpose on/off features.spring.jackson.parser.*= # Jackson on/off features for parsers.spring.jackson.property-naming-strategy= # One of the constants on Jackson&apos;s PropertyNamingStrategy. Can also be a fully-qualified class name of a PropertyNamingStrategy subclass.spring.jackson.serialization.*= # Jackson on/off features that affect the way Java objects are serialized.spring.jackson.time-zone= # Time zone used when formatting dates. For instance `America/Los_Angeles`# JERSEY (JerseyProperties)spring.jersey.application-path= # Path that serves as the base URI for the application. Overrides the value of &quot;@ApplicationPath&quot; if specified.spring.jersey.filter.order=0 # Jersey filter chain order.spring.jersey.init.*= # Init parameters to pass to Jersey via the servlet or filter.spring.jersey.servlet.load-on-startup=-1 # Load on startup priority of the Jersey servlet.spring.jersey.type=servlet # Jersey integration type.# SPRING LDAP (LdapProperties)spring.ldap.urls= # LDAP URLs of the server.spring.ldap.base= # Base suffix from which all operations should originate.spring.ldap.username= # Login user of the server.spring.ldap.password= # Login password of the server.spring.ldap.base-environment.*= # LDAP specification settings.# EMBEDDED LDAP (EmbeddedLdapProperties)spring.ldap.embedded.base-dn= # The base DNspring.ldap.embedded.credential.username= # Embedded LDAP username.spring.ldap.embedded.credential.password= # Embedded LDAP password.spring.ldap.embedded.ldif=classpath:schema.ldif # Schema (LDIF) script resource reference.spring.ldap.embedded.port= # Embedded LDAP port.spring.ldap.embedded.validation.enabled=true # Enable LDAP schema validation.spring.ldap.embedded.validation.schema= # Path to the custom schema.# SPRING MOBILE DEVICE VIEWS (DeviceDelegatingViewResolverAutoConfiguration)spring.mobile.devicedelegatingviewresolver.enable-fallback=false # Enable support for fallback resolution.spring.mobile.devicedelegatingviewresolver.enabled=false # Enable device view resolver.spring.mobile.devicedelegatingviewresolver.mobile-prefix=mobile/ # Prefix that gets prepended to view names for mobile devices.spring.mobile.devicedelegatingviewresolver.mobile-suffix= # Suffix that gets appended to view names for mobile devices.spring.mobile.devicedelegatingviewresolver.normal-prefix= # Prefix that gets prepended to view names for normal devices.spring.mobile.devicedelegatingviewresolver.normal-suffix= # Suffix that gets appended to view names for normal devices.spring.mobile.devicedelegatingviewresolver.tablet-prefix=tablet/ # Prefix that gets prepended to view names for tablet devices.spring.mobile.devicedelegatingviewresolver.tablet-suffix= # Suffix that gets appended to view names for tablet devices.# SPRING MOBILE SITE PREFERENCE (SitePreferenceAutoConfiguration)spring.mobile.sitepreference.enabled=true # Enable SitePreferenceHandler.# MUSTACHE TEMPLATES (MustacheAutoConfiguration)spring.mustache.allow-request-override= # Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.spring.mustache.allow-session-override= # Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.spring.mustache.cache= # Enable template caching.spring.mustache.charset= # Template encoding.spring.mustache.check-template-location= # Check that the templates location exists.spring.mustache.content-type= # Content-Type value.spring.mustache.enabled= # Enable MVC view resolution for this technology.spring.mustache.expose-request-attributes= # Set whether all request attributes should be added to the model prior to merging with the template.spring.mustache.expose-session-attributes= # Set whether all HttpSession attributes should be added to the model prior to merging with the template.spring.mustache.expose-spring-macro-helpers= # Set whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.spring.mustache.prefix=classpath:/templates/ # Prefix to apply to template names.spring.mustache.request-context-attribute= # Name of the RequestContext attribute for all views.spring.mustache.suffix=.html # Suffix to apply to template names.spring.mustache.view-names= # White list of view names that can be resolved.# SPRING MVC (WebMvcProperties)spring.mvc.async.request-timeout= # Amount of time (in milliseconds) before asynchronous request handling times out.spring.mvc.date-format= # Date format to use. For instance `dd/MM/yyyy`.spring.mvc.dispatch-trace-request=false # Dispatch TRACE requests to the FrameworkServlet doService method.spring.mvc.dispatch-options-request=true # Dispatch OPTIONS requests to the FrameworkServlet doService method.spring.mvc.favicon.enabled=true # Enable resolution of favicon.ico.spring.mvc.formcontent.putfilter.enabled=true # Enable Spring&apos;s HttpPutFormContentFilter.spring.mvc.ignore-default-model-on-redirect=true # If the content of the &quot;default&quot; model should be ignored during redirect scenarios.spring.mvc.locale= # Locale to use. By default, this locale is overridden by the &quot;Accept-Language&quot; header.spring.mvc.locale-resolver=accept-header # Define how the locale should be resolved.spring.mvc.log-resolved-exception=false # Enable warn logging of exceptions resolved by a &quot;HandlerExceptionResolver&quot;.spring.mvc.media-types.*= # Maps file extensions to media types for content negotiation.spring.mvc.message-codes-resolver-format= # Formatting strategy for message codes. For instance `PREFIX_ERROR_CODE`.spring.mvc.servlet.load-on-startup=-1 # Load on startup priority of the Spring Web Services servlet.spring.mvc.static-path-pattern=/** # Path pattern used for static resources.spring.mvc.throw-exception-if-no-handler-found=false # If a &quot;NoHandlerFoundException&quot; should be thrown if no Handler was found to process a request.spring.mvc.view.prefix= # Spring MVC view prefix.spring.mvc.view.suffix= # Spring MVC view suffix.# SPRING RESOURCES HANDLING (ResourceProperties)spring.resources.add-mappings=true # Enable default resource handling.spring.resources.cache-period= # Cache period for the resources served by the resource handler, in seconds.spring.resources.chain.cache=true # Enable caching in the Resource chain.spring.resources.chain.enabled= # Enable the Spring Resource Handling chain. Disabled by default unless at least one strategy has been enabled.spring.resources.chain.gzipped=false # Enable resolution of already gzipped resources.spring.resources.chain.html-application-cache=false # Enable HTML5 application cache manifest rewriting.spring.resources.chain.strategy.content.enabled=false # Enable the content Version Strategy.spring.resources.chain.strategy.content.paths=/** # Comma-separated list of patterns to apply to the Version Strategy.spring.resources.chain.strategy.fixed.enabled=false # Enable the fixed Version Strategy.spring.resources.chain.strategy.fixed.paths=/** # Comma-separated list of patterns to apply to the Version Strategy.spring.resources.chain.strategy.fixed.version= # Version string to use for the Version Strategy.spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/ # Locations of static resources.# SPRING SESSION (SessionProperties)spring.session.hazelcast.flush-mode=on-save # Sessions flush mode.spring.session.hazelcast.map-name=spring:session:sessions # Name of the map used to store sessions.spring.session.jdbc.initializer.enabled= # Create the required session tables on startup if necessary. Enabled automatically if the default table name is set or a custom schema is configured.spring.session.jdbc.schema=classpath:org/springframework/session/jdbc/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema.spring.session.jdbc.table-name=SPRING_SESSION # Name of database table used to store sessions.spring.session.mongo.collection-name=sessions # Collection name used to store sessions.spring.session.redis.flush-mode=on-save # Sessions flush mode.spring.session.redis.namespace= # Namespace for keys used to store sessions.spring.session.store-type= # Session store type.# SPRING SOCIAL (SocialWebAutoConfiguration)spring.social.auto-connection-views=false # Enable the connection status view for supported providers.# SPRING SOCIAL FACEBOOK (FacebookAutoConfiguration)spring.social.facebook.app-id= # your application&apos;s Facebook App IDspring.social.facebook.app-secret= # your application&apos;s Facebook App Secret# SPRING SOCIAL LINKEDIN (LinkedInAutoConfiguration)spring.social.linkedin.app-id= # your application&apos;s LinkedIn App IDspring.social.linkedin.app-secret= # your application&apos;s LinkedIn App Secret# SPRING SOCIAL TWITTER (TwitterAutoConfiguration)spring.social.twitter.app-id= # your application&apos;s Twitter App IDspring.social.twitter.app-secret= # your application&apos;s Twitter App Secret# THYMELEAF (ThymeleafAutoConfiguration)spring.thymeleaf.cache=true # Enable template caching.spring.thymeleaf.check-template=true # Check that the template exists before rendering it.spring.thymeleaf.check-template-location=true # Check that the templates location exists.spring.thymeleaf.content-type=text/html # Content-Type value.spring.thymeleaf.enabled=true # Enable MVC Thymeleaf view resolution.spring.thymeleaf.encoding=UTF-8 # Template encoding.spring.thymeleaf.excluded-view-names= # Comma-separated list of view names that should be excluded from resolution.spring.thymeleaf.mode=HTML5 # Template mode to be applied to templates. See also StandardTemplateModeHandlers.spring.thymeleaf.prefix=classpath:/templates/ # Prefix that gets prepended to view names when building a URL.spring.thymeleaf.suffix=.html # Suffix that gets appended to view names when building a URL.spring.thymeleaf.template-resolver-order= # Order of the template resolver in the chain.spring.thymeleaf.view-names= # Comma-separated list of view names that can be resolved.# SPRING WEB SERVICES (WebServicesProperties)spring.webservices.path=/services # Path that serves as the base URI for the services.spring.webservices.servlet.init= # Servlet init parameters to pass to Spring Web Services.spring.webservices.servlet.load-on-startup=-1 # Load on startup priority of the Spring Web Services servlet.# ----------------------------------------# SECURITY PROPERTIES# ----------------------------------------# SECURITY (SecurityProperties)security.basic.authorize-mode=role # Security authorize mode to apply.security.basic.enabled=true # Enable basic authentication.security.basic.path=/** # Comma-separated list of paths to secure.security.basic.realm=Spring # HTTP basic realm name.security.enable-csrf=false # Enable Cross Site Request Forgery support.security.filter-order=0 # Security filter chain order.security.filter-dispatcher-types=ASYNC, FORWARD, INCLUDE, REQUEST # Security filter chain dispatcher types.security.headers.cache=true # Enable cache control HTTP headers.security.headers.content-security-policy= # Value for content security policy header.security.headers.content-security-policy-mode=default # Content security policy mode.security.headers.content-type=true # Enable &quot;X-Content-Type-Options&quot; header.security.headers.frame=true # Enable &quot;X-Frame-Options&quot; header.security.headers.hsts=all # HTTP Strict Transport Security (HSTS) mode (none, domain, all).security.headers.xss=true # Enable cross site scripting (XSS) protection.security.ignored= # Comma-separated list of paths to exclude from the default secured paths.security.require-ssl=false # Enable secure channel for all requests.security.sessions=stateless # Session creation policy (always, never, if_required, stateless).security.user.name=user # Default user name.security.user.password= # Password for the default user name. A random password is logged on startup by default.security.user.role=USER # Granted roles for the default user name.# SECURITY OAUTH2 CLIENT (OAuth2ClientProperties)security.oauth2.client.client-id= # OAuth2 client id.security.oauth2.client.client-secret= # OAuth2 client secret. A random secret is generated by default# SECURITY OAUTH2 RESOURCES (ResourceServerProperties)security.oauth2.resource.filter-order= # The order of the filter chain used to authenticate tokens.security.oauth2.resource.id= # Identifier of the resource.security.oauth2.resource.jwt.key-uri= # The URI of the JWT token. Can be set if the value is not available and the key is public.security.oauth2.resource.jwt.key-value= # The verification key of the JWT token. Can either be a symmetric secret or PEM-encoded RSA public key.security.oauth2.resource.jwk.key-set-uri= # The URI for getting the set of keys that can be used to validate the token.security.oauth2.resource.prefer-token-info=true # Use the token info, can be set to false to use the user info.security.oauth2.resource.service-id=resource #security.oauth2.resource.token-info-uri= # URI of the token decoding endpoint.security.oauth2.resource.token-type= # The token type to send when using the userInfoUri.security.oauth2.resource.user-info-uri= # URI of the user endpoint.# SECURITY OAUTH2 SSO (OAuth2SsoProperties)security.oauth2.sso.filter-order= # Filter order to apply if not providing an explicit WebSecurityConfigurerAdaptersecurity.oauth2.sso.login-path=/login # Path to the login page, i.e. the one that triggers the redirect to the OAuth2 Authorization Server# ----------------------------------------# DATA PROPERTIES# ----------------------------------------# FLYWAY (FlywayProperties)flyway.baseline-description= #flyway.baseline-version=1 # version to start migrationflyway.baseline-on-migrate= #flyway.check-location=false # Check that migration scripts location exists.flyway.clean-on-validation-error= #flyway.enabled=true # Enable flyway.flyway.encoding= #flyway.ignore-failed-future-migration= #flyway.init-sqls= # SQL statements to execute to initialize a connection immediately after obtaining it.flyway.locations=classpath:db/migration # locations of migrations scriptsflyway.out-of-order= #flyway.password= # JDBC password if you want Flyway to create its own DataSourceflyway.placeholder-prefix= #flyway.placeholder-replacement= #flyway.placeholder-suffix= #flyway.placeholders.*= #flyway.schemas= # schemas to updateflyway.sql-migration-prefix=V #flyway.sql-migration-separator= #flyway.sql-migration-suffix=.sql #flyway.table= #flyway.url= # JDBC url of the database to migrate. If not set, the primary configured data source is used.flyway.user= # Login user of the database to migrate.flyway.validate-on-migrate= ## LIQUIBASE (LiquibaseProperties)liquibase.change-log=classpath:/db/changelog/db.changelog-master.yaml # Change log configuration path.liquibase.check-change-log-location=true # Check the change log location exists.liquibase.contexts= # Comma-separated list of runtime contexts to use.liquibase.default-schema= # Default database schema.liquibase.drop-first=false # Drop the database schema first.liquibase.enabled=true # Enable liquibase support.liquibase.labels= # Comma-separated list of runtime labels to use.liquibase.parameters.*= # Change log parameters.liquibase.password= # Login password of the database to migrate.liquibase.rollback-file= # File to which rollback SQL will be written when an update is performed.liquibase.url= # JDBC url of the database to migrate. If not set, the primary configured data source is used.liquibase.user= # Login user of the database to migrate.# COUCHBASE (CouchbaseProperties)spring.couchbase.bootstrap-hosts= # Couchbase nodes (host or IP address) to bootstrap from.spring.couchbase.bucket.name=default # Name of the bucket to connect to.spring.couchbase.bucket.password= # Password of the bucket.spring.couchbase.env.endpoints.key-value=1 # Number of sockets per node against the Key/value service.spring.couchbase.env.endpoints.query=1 # Number of sockets per node against the Query (N1QL) service.spring.couchbase.env.endpoints.view=1 # Number of sockets per node against the view service.spring.couchbase.env.ssl.enabled= # Enable SSL support. Enabled automatically if a &quot;keyStore&quot; is provided unless specified otherwise.spring.couchbase.env.ssl.key-store= # Path to the JVM key store that holds the certificates.spring.couchbase.env.ssl.key-store-password= # Password used to access the key store.spring.couchbase.env.timeouts.connect=5000 # Bucket connections timeout in milliseconds.spring.couchbase.env.timeouts.key-value=2500 # Blocking operations performed on a specific key timeout in milliseconds.spring.couchbase.env.timeouts.query=7500 # N1QL query operations timeout in milliseconds.spring.couchbase.env.timeouts.socket-connect=1000 # Socket connect connections timeout in milliseconds.spring.couchbase.env.timeouts.view=7500 # Regular and geospatial view operations timeout in milliseconds.# DAO (PersistenceExceptionTranslationAutoConfiguration)spring.dao.exceptiontranslation.enabled=true # Enable the PersistenceExceptionTranslationPostProcessor.# CASSANDRA (CassandraProperties)spring.data.cassandra.cluster-name= # Name of the Cassandra cluster.spring.data.cassandra.compression=none # Compression supported by the Cassandra binary protocol.spring.data.cassandra.connect-timeout-millis= # Socket option: connection time out.spring.data.cassandra.consistency-level= # Queries consistency level.spring.data.cassandra.contact-points=localhost # Comma-separated list of cluster node addresses.spring.data.cassandra.fetch-size= # Queries default fetch size.spring.data.cassandra.keyspace-name= # Keyspace name to use.spring.data.cassandra.load-balancing-policy= # Class name of the load balancing policy.spring.data.cassandra.port= # Port of the Cassandra server.spring.data.cassandra.password= # Login password of the server.spring.data.cassandra.read-timeout-millis= # Socket option: read time out.spring.data.cassandra.reconnection-policy= # Reconnection policy class.spring.data.cassandra.repositories.enabled= # Enable Cassandra repositories.spring.data.cassandra.retry-policy= # Class name of the retry policy.spring.data.cassandra.serial-consistency-level= # Queries serial consistency level.spring.data.cassandra.schema-action=none # Schema action to take at startup.spring.data.cassandra.ssl=false # Enable SSL support.spring.data.cassandra.username= # Login user of the server.# DATA COUCHBASE (CouchbaseDataProperties)spring.data.couchbase.auto-index=false # Automatically create views and indexes.spring.data.couchbase.consistency=read-your-own-writes # Consistency to apply by default on generated queries.spring.data.couchbase.repositories.enabled=true # Enable Couchbase repositories.# ELASTICSEARCH (ElasticsearchProperties)spring.data.elasticsearch.cluster-name=elasticsearch # Elasticsearch cluster name.spring.data.elasticsearch.cluster-nodes= # Comma-separated list of cluster node addresses. If not specified, starts a client node.spring.data.elasticsearch.properties.*= # Additional properties used to configure the client.spring.data.elasticsearch.repositories.enabled=true # Enable Elasticsearch repositories.# DATA LDAPspring.data.ldap.repositories.enabled=true # Enable LDAP repositories.# MONGODB (MongoProperties)spring.data.mongodb.authentication-database= # Authentication database name.spring.data.mongodb.database=test # Database name.spring.data.mongodb.field-naming-strategy= # Fully qualified name of the FieldNamingStrategy to use.spring.data.mongodb.grid-fs-database= # GridFS database name.spring.data.mongodb.host=localhost # Mongo server host. Cannot be set with uri.spring.data.mongodb.password= # Login password of the mongo server. Cannot be set with uri.spring.data.mongodb.port=27017 # Mongo server port. Cannot be set with uri.spring.data.mongodb.repositories.enabled=true # Enable Mongo repositories.spring.data.mongodb.uri=mongodb://localhost/test # Mongo database URI. Cannot be set with host, port and credentials.spring.data.mongodb.username= # Login user of the mongo server. Cannot be set with uri.# DATA REDISspring.data.redis.repositories.enabled=true # Enable Redis repositories.# NEO4J (Neo4jProperties)spring.data.neo4j.compiler= # Compiler to use.spring.data.neo4j.embedded.enabled=true # Enable embedded mode if the embedded driver is available.spring.data.neo4j.open-in-view=true # Register OpenSessionInViewInterceptor. Binds a Neo4j Session to the thread for the entire processing of the request.spring.data.neo4j.password= # Login password of the server.spring.data.neo4j.repositories.enabled=true # Enable Neo4j repositories.spring.data.neo4j.uri= # URI used by the driver. Auto-detected by default.spring.data.neo4j.username= # Login user of the server.# DATA REST (RepositoryRestProperties)spring.data.rest.base-path= # Base path to be used by Spring Data REST to expose repository resources.spring.data.rest.default-page-size= # Default size of pages.spring.data.rest.detection-strategy=default # Strategy to use to determine which repositories get exposed.spring.data.rest.enable-enum-translation= # Enable enum value translation via the Spring Data REST default resource bundle.spring.data.rest.limit-param-name= # Name of the URL query string parameter that indicates how many results to return at once.spring.data.rest.max-page-size= # Maximum size of pages.spring.data.rest.page-param-name= # Name of the URL query string parameter that indicates what page to return.spring.data.rest.return-body-on-create= # Return a response body after creating an entity.spring.data.rest.return-body-on-update= # Return a response body after updating an entity.spring.data.rest.sort-param-name= # Name of the URL query string parameter that indicates what direction to sort results.# SOLR (SolrProperties)spring.data.solr.host=http://127.0.0.1:8983/solr # Solr host. Ignored if &quot;zk-host&quot; is set.spring.data.solr.repositories.enabled=true # Enable Solr repositories.spring.data.solr.zk-host= # ZooKeeper host address in the form HOST:PORT.# DATASOURCE (DataSourceAutoConfiguration &amp; DataSourceProperties)spring.datasource.continue-on-error=false # Do not stop if an error occurs while initializing the database.spring.datasource.data= # Data (DML) script resource references.spring.datasource.data-username= # User of the database to execute DML scripts (if different).spring.datasource.data-password= # Password of the database to execute DML scripts (if different).spring.datasource.dbcp2.*= # Commons DBCP2 specific settingsspring.datasource.driver-class-name= # Fully qualified name of the JDBC driver. Auto-detected based on the URL by default.spring.datasource.generate-unique-name=false # Generate a random datasource name.spring.datasource.hikari.*= # Hikari specific settingsspring.datasource.initialize=true # Populate the database using &apos;data.sql&apos;.spring.datasource.jmx-enabled=false # Enable JMX support (if provided by the underlying pool).spring.datasource.jndi-name= # JNDI location of the datasource. Class, url, username &amp; password are ignored when set.spring.datasource.name=testdb # Name of the datasource.spring.datasource.password= # Login password of the database.spring.datasource.platform=all # Platform to use in the DDL or DML scripts (e.g. schema-$&#123;platform&#125;.sql or data-$&#123;platform&#125;.sql).spring.datasource.schema= # Schema (DDL) script resource references.spring.datasource.schema-username= # User of the database to execute DDL scripts (if different).spring.datasource.schema-password= # Password of the database to execute DDL scripts (if different).spring.datasource.separator=; # Statement separator in SQL initialization scripts.spring.datasource.sql-script-encoding= # SQL scripts encoding.spring.datasource.tomcat.*= # Tomcat datasource specific settingsspring.datasource.type= # Fully qualified name of the connection pool implementation to use. By default, it is auto-detected from the classpath.spring.datasource.url= # JDBC url of the database.spring.datasource.username= # Login user of the database.spring.datasource.xa.data-source-class-name= # XA datasource fully qualified name.spring.datasource.xa.properties= # Properties to pass to the XA data source.# JEST (Elasticsearch HTTP client) (JestProperties)spring.elasticsearch.jest.connection-timeout=3000 # Connection timeout in milliseconds.spring.elasticsearch.jest.multi-threaded=true # Enable connection requests from multiple execution threads.spring.elasticsearch.jest.password= # Login password.spring.elasticsearch.jest.proxy.host= # Proxy host the HTTP client should use.spring.elasticsearch.jest.proxy.port= # Proxy port the HTTP client should use.spring.elasticsearch.jest.read-timeout=3000 # Read timeout in milliseconds.spring.elasticsearch.jest.uris=http://localhost:9200 # Comma-separated list of the Elasticsearch instances to use.spring.elasticsearch.jest.username= # Login user.# H2 Web Console (H2ConsoleProperties)spring.h2.console.enabled=false # Enable the console.spring.h2.console.path=/h2-console # Path at which the console will be available.spring.h2.console.settings.trace=false # Enable trace output.spring.h2.console.settings.web-allow-others=false # Enable remote access.# JOOQ (JooqAutoConfiguration)spring.jooq.sql-dialect= # SQLDialect JOOQ used when communicating with the configured datasource. For instance `POSTGRES`# JPA (JpaBaseConfiguration, HibernateJpaAutoConfiguration)spring.data.jpa.repositories.enabled=true # Enable JPA repositories.spring.jpa.database= # Target database to operate on, auto-detected by default. Can be alternatively set using the &quot;databasePlatform&quot; property.spring.jpa.database-platform= # Name of the target database to operate on, auto-detected by default. Can be alternatively set using the &quot;Database&quot; enum.spring.jpa.generate-ddl=false # Initialize the schema on startup.spring.jpa.hibernate.ddl-auto= # DDL mode. This is actually a shortcut for the &quot;hibernate.hbm2ddl.auto&quot; property. Default to &quot;create-drop&quot; when using an embedded database, &quot;none&quot; otherwise.spring.jpa.hibernate.naming.implicit-strategy= # Hibernate 5 implicit naming strategy fully qualified name.spring.jpa.hibernate.naming.physical-strategy= # Hibernate 5 physical naming strategy fully qualified name.spring.jpa.hibernate.naming.strategy= # Hibernate 4 naming strategy fully qualified name. Not supported with Hibernate 5.spring.jpa.hibernate.use-new-id-generator-mappings= # Use Hibernate&apos;s newer IdentifierGenerator for AUTO, TABLE and SEQUENCE.spring.jpa.open-in-view=true # Register OpenEntityManagerInViewInterceptor. Binds a JPA EntityManager to the thread for the entire processing of the request.spring.jpa.properties.*= # Additional native properties to set on the JPA provider.spring.jpa.show-sql=false # Enable logging of SQL statements.# JTA (JtaAutoConfiguration)spring.jta.enabled=true # Enable JTA support.spring.jta.log-dir= # Transaction logs directory.spring.jta.transaction-manager-id= # Transaction manager unique identifier.# ATOMIKOS (AtomikosProperties)spring.jta.atomikos.connectionfactory.borrow-connection-timeout=30 # Timeout, in seconds, for borrowing connections from the pool.spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag=true # Whether or not to ignore the transacted flag when creating session.spring.jta.atomikos.connectionfactory.local-transaction-mode=false # Whether or not local transactions are desired.spring.jta.atomikos.connectionfactory.maintenance-interval=60 # The time, in seconds, between runs of the pool&apos;s maintenance thread.spring.jta.atomikos.connectionfactory.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.atomikos.connectionfactory.max-lifetime=0 # The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit.spring.jta.atomikos.connectionfactory.max-pool-size=1 # The maximum size of the pool.spring.jta.atomikos.connectionfactory.min-pool-size=1 # The minimum size of the pool.spring.jta.atomikos.connectionfactory.reap-timeout=0 # The reap timeout, in seconds, for borrowed connections. 0 denotes no limit.spring.jta.atomikos.connectionfactory.unique-resource-name=jmsConnectionFactory # The unique name used to identify the resource during recovery.spring.jta.atomikos.datasource.borrow-connection-timeout=30 # Timeout, in seconds, for borrowing connections from the pool.spring.jta.atomikos.datasource.default-isolation-level= # Default isolation level of connections provided by the pool.spring.jta.atomikos.datasource.login-timeout= # Timeout, in seconds, for establishing a database connection.spring.jta.atomikos.datasource.maintenance-interval=60 # The time, in seconds, between runs of the pool&apos;s maintenance thread.spring.jta.atomikos.datasource.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.atomikos.datasource.max-lifetime=0 # The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit.spring.jta.atomikos.datasource.max-pool-size=1 # The maximum size of the pool.spring.jta.atomikos.datasource.min-pool-size=1 # The minimum size of the pool.spring.jta.atomikos.datasource.reap-timeout=0 # The reap timeout, in seconds, for borrowed connections. 0 denotes no limit.spring.jta.atomikos.datasource.test-query= # SQL query or statement used to validate a connection before returning it.spring.jta.atomikos.datasource.unique-resource-name=dataSource # The unique name used to identify the resource during recovery.spring.jta.atomikos.properties.checkpoint-interval=500 # Interval between checkpoints.spring.jta.atomikos.properties.default-jta-timeout=10000 # Default timeout for JTA transactions.spring.jta.atomikos.properties.enable-logging=true # Enable disk logging.spring.jta.atomikos.properties.force-shutdown-on-vm-exit=false # Specify if a VM shutdown should trigger forced shutdown of the transaction core.spring.jta.atomikos.properties.log-base-dir= # Directory in which the log files should be stored.spring.jta.atomikos.properties.log-base-name=tmlog # Transactions log file base name.spring.jta.atomikos.properties.max-actives=50 # Maximum number of active transactions.spring.jta.atomikos.properties.max-timeout=300000 # Maximum timeout (in milliseconds) that can be allowed for transactions.spring.jta.atomikos.properties.serial-jta-transactions=true # Specify if sub-transactions should be joined when possible.spring.jta.atomikos.properties.service= # Transaction manager implementation that should be started.spring.jta.atomikos.properties.threaded-two-phase-commit=false # Use different (and concurrent) threads for two-phase commit on the participating resources.spring.jta.atomikos.properties.transaction-manager-unique-name= # Transaction manager&apos;s unique name.# BITRONIXspring.jta.bitronix.connectionfactory.acquire-increment=1 # Number of connections to create when growing the pool.spring.jta.bitronix.connectionfactory.acquisition-interval=1 # Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired.spring.jta.bitronix.connectionfactory.acquisition-timeout=30 # Timeout, in seconds, for acquiring connections from the pool.spring.jta.bitronix.connectionfactory.allow-local-transactions=true # Whether or not the transaction manager should allow mixing XA and non-XA transactions.spring.jta.bitronix.connectionfactory.apply-transaction-timeout=false # Whether or not the transaction timeout should be set on the XAResource when it is enlisted.spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled=true # Whether or not resources should be enlisted and delisted automatically.spring.jta.bitronix.connectionfactory.cache-producers-consumers=true # Whether or not produces and consumers should be cached.spring.jta.bitronix.connectionfactory.defer-connection-release=true # Whether or not the provider can run many transactions on the same connection and supports transaction interleaving.spring.jta.bitronix.connectionfactory.ignore-recovery-failures=false # Whether or not recovery failures should be ignored.spring.jta.bitronix.connectionfactory.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.bitronix.connectionfactory.max-pool-size=10 # The maximum size of the pool. 0 denotes no limit.spring.jta.bitronix.connectionfactory.min-pool-size=0 # The minimum size of the pool.spring.jta.bitronix.connectionfactory.password= # The password to use to connect to the JMS provider.spring.jta.bitronix.connectionfactory.share-transaction-connections=false # Whether or not connections in the ACCESSIBLE state can be shared within the context of a transaction.spring.jta.bitronix.connectionfactory.test-connections=true # Whether or not connections should be tested when acquired from the pool.spring.jta.bitronix.connectionfactory.two-pc-ordering-position=1 # The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, always last is Integer.MAX_VALUE).spring.jta.bitronix.connectionfactory.unique-name=jmsConnectionFactory # The unique name used to identify the resource during recovery.spring.jta.bitronix.connectionfactory.use-tm-join=true Whether or not TMJOIN should be used when starting XAResources.spring.jta.bitronix.connectionfactory.user= # The user to use to connect to the JMS provider.spring.jta.bitronix.datasource.acquire-increment=1 # Number of connections to create when growing the pool.spring.jta.bitronix.datasource.acquisition-interval=1 # Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired.spring.jta.bitronix.datasource.acquisition-timeout=30 # Timeout, in seconds, for acquiring connections from the pool.spring.jta.bitronix.datasource.allow-local-transactions=true # Whether or not the transaction manager should allow mixing XA and non-XA transactions.spring.jta.bitronix.datasource.apply-transaction-timeout=false # Whether or not the transaction timeout should be set on the XAResource when it is enlisted.spring.jta.bitronix.datasource.automatic-enlisting-enabled=true # Whether or not resources should be enlisted and delisted automatically.spring.jta.bitronix.datasource.cursor-holdability= # The default cursor holdability for connections.spring.jta.bitronix.datasource.defer-connection-release=true # Whether or not the database can run many transactions on the same connection and supports transaction interleaving.spring.jta.bitronix.datasource.enable-jdbc4-connection-test= # Whether or not Connection.isValid() is called when acquiring a connection from the pool.spring.jta.bitronix.datasource.ignore-recovery-failures=false # Whether or not recovery failures should be ignored.spring.jta.bitronix.datasource.isolation-level= # The default isolation level for connections.spring.jta.bitronix.datasource.local-auto-commit= # The default auto-commit mode for local transactions.spring.jta.bitronix.datasource.login-timeout= # Timeout, in seconds, for establishing a database connection.spring.jta.bitronix.datasource.max-idle-time=60 # The time, in seconds, after which connections are cleaned up from the pool.spring.jta.bitronix.datasource.max-pool-size=10 # The maximum size of the pool. 0 denotes no limit.spring.jta.bitronix.datasource.min-pool-size=0 # The minimum size of the pool.spring.jta.bitronix.datasource.prepared-statement-cache-size=0 # The target size of the prepared statement cache. 0 disables the cache.spring.jta.bitronix.datasource.share-transaction-connections=false # Whether or not connections in the ACCESSIBLE state can be shared within the context of a transaction.spring.jta.bitronix.datasource.test-query= # SQL query or statement used to validate a connection before returning it.spring.jta.bitronix.datasource.two-pc-ordering-position=1 # The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, always last is Integer.MAX_VALUE).spring.jta.bitronix.datasource.unique-name=dataSource # The unique name used to identify the resource during recovery.spring.jta.bitronix.datasource.use-tm-join=true Whether or not TMJOIN should be used when starting XAResources.spring.jta.bitronix.properties.allow-multiple-lrc=false # Allow multiple LRC resources to be enlisted into the same transaction.spring.jta.bitronix.properties.asynchronous2-pc=false # Enable asynchronously execution of two phase commit.spring.jta.bitronix.properties.background-recovery-interval-seconds=60 # Interval in seconds at which to run the recovery process in the background.spring.jta.bitronix.properties.current-node-only-recovery=true # Recover only the current node.spring.jta.bitronix.properties.debug-zero-resource-transaction=false # Log the creation and commit call stacks of transactions executed without a single enlisted resource.spring.jta.bitronix.properties.default-transaction-timeout=60 # Default transaction timeout in seconds.spring.jta.bitronix.properties.disable-jmx=false # Enable JMX support.spring.jta.bitronix.properties.exception-analyzer= # Set the fully qualified name of the exception analyzer implementation to use.spring.jta.bitronix.properties.filter-log-status=false # Enable filtering of logs so that only mandatory logs are written.spring.jta.bitronix.properties.force-batching-enabled=true # Set if disk forces are batched.spring.jta.bitronix.properties.forced-write-enabled=true # Set if logs are forced to disk.spring.jta.bitronix.properties.graceful-shutdown-interval=60 # Maximum amount of seconds the TM will wait for transactions to get done before aborting them at shutdown time.spring.jta.bitronix.properties.jndi-transaction-synchronization-registry-name= # JNDI name of the TransactionSynchronizationRegistry.spring.jta.bitronix.properties.jndi-user-transaction-name= # JNDI name of the UserTransaction.spring.jta.bitronix.properties.journal=disk # Name of the journal. Can be &apos;disk&apos;, &apos;null&apos; or a class name.spring.jta.bitronix.properties.log-part1-filename=btm1.tlog # Name of the first fragment of the journal.spring.jta.bitronix.properties.log-part2-filename=btm2.tlog # Name of the second fragment of the journal.spring.jta.bitronix.properties.max-log-size-in-mb=2 # Maximum size in megabytes of the journal fragments.spring.jta.bitronix.properties.resource-configuration-filename= # ResourceLoader configuration file name.spring.jta.bitronix.properties.server-id= # ASCII ID that must uniquely identify this TM instance. Default to the machine&apos;s IP address.spring.jta.bitronix.properties.skip-corrupted-logs=false # Skip corrupted transactions log entries.spring.jta.bitronix.properties.warn-about-zero-resource-transaction=true # Log a warning for transactions executed without a single enlisted resource.# NARAYANA (NarayanaProperties)spring.jta.narayana.default-timeout=60 # Transaction timeout in seconds.spring.jta.narayana.expiry-scanners=com.arjuna.ats.internal.arjuna.recovery.ExpiredTransactionStatusManagerScanner # Comma-separated list of expiry scanners.spring.jta.narayana.log-dir= # Transaction object store directory.spring.jta.narayana.one-phase-commit=true # Enable one phase commit optimisation.spring.jta.narayana.periodic-recovery-period=120 # Interval in which periodic recovery scans are performed in seconds.spring.jta.narayana.recovery-backoff-period=10 # Back off period between first and second phases of the recovery scan in seconds.spring.jta.narayana.recovery-db-pass= # Database password to be used by recovery manager.spring.jta.narayana.recovery-db-user= # Database username to be used by recovery manager.spring.jta.narayana.recovery-jms-pass= # JMS password to be used by recovery manager.spring.jta.narayana.recovery-jms-user= # JMS username to be used by recovery manager.spring.jta.narayana.recovery-modules= # Comma-separated list of recovery modules.spring.jta.narayana.transaction-manager-id=1 # Unique transaction manager id.spring.jta.narayana.xa-resource-orphan-filters= # Comma-separated list of orphan filters.# EMBEDDED MONGODB (EmbeddedMongoProperties)spring.mongodb.embedded.features=SYNC_DELAY # Comma-separated list of features to enable.spring.mongodb.embedded.storage.database-dir= # Directory used for data storage.spring.mongodb.embedded.storage.oplog-size= # Maximum size of the oplog in megabytes.spring.mongodb.embedded.storage.repl-set-name= # Name of the replica set.spring.mongodb.embedded.version=2.6.10 # Version of Mongo to use.# REDIS (RedisProperties)spring.redis.cluster.max-redirects= # Maximum number of redirects to follow when executing commands across the cluster.spring.redis.cluster.nodes= # Comma-separated list of &quot;host:port&quot; pairs to bootstrap from.spring.redis.database=0 # Database index used by the connection factory.spring.redis.url= # Connection URL, will override host, port and password (user will be ignored), e.g. redis://user:password@example.com:6379spring.redis.host=localhost # Redis server host.spring.redis.password= # Login password of the redis server.spring.redis.ssl=false # Enable SSL support.spring.redis.pool.max-active=8 # Max number of connections that can be allocated by the pool at a given time. Use a negative value for no limit.spring.redis.pool.max-idle=8 # Max number of &quot;idle&quot; connections in the pool. Use a negative value to indicate an unlimited number of idle connections.spring.redis.pool.max-wait=-1 # Maximum amount of time (in milliseconds) a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely.spring.redis.pool.min-idle=0 # Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive.spring.redis.port=6379 # Redis server port.spring.redis.sentinel.master= # Name of Redis server.spring.redis.sentinel.nodes= # Comma-separated list of host:port pairs.spring.redis.timeout=0 # Connection timeout in milliseconds.# TRANSACTION (TransactionProperties)spring.transaction.default-timeout= # Default transaction timeout in seconds.spring.transaction.rollback-on-commit-failure= # Perform the rollback on commit failures.# ----------------------------------------# INTEGRATION PROPERTIES# ----------------------------------------# ACTIVEMQ (ActiveMQProperties)spring.activemq.broker-url= # URL of the ActiveMQ broker. Auto-generated by default.spring.activemq.close-timeout=15000 # Time to wait, in milliseconds, before considering a close complete.spring.activemq.in-memory=true # Specify if the default broker URL should be in memory. Ignored if an explicit broker has been specified.spring.activemq.non-blocking-redelivery=false # Do not stop message delivery before re-delivering messages from a rolled back transaction. This implies that message order will not be preserved when this is enabled.spring.activemq.password= # Login password of the broker.spring.activemq.send-timeout=0 # Time to wait, in milliseconds, on Message sends for a response. Set it to 0 to indicate to wait forever.spring.activemq.user= # Login user of the broker.spring.activemq.packages.trust-all= # Trust all packages.spring.activemq.packages.trusted= # Comma-separated list of specific packages to trust (when not trusting all packages).spring.activemq.pool.block-if-full=true # Block when a connection is requested and the pool is full. Set it to false to throw a &quot;JMSException&quot; instead.spring.activemq.pool.block-if-full-timeout=-1 # Blocking period, in milliseconds, before throwing an exception if the pool is still full.spring.activemq.pool.create-connection-on-startup=true # Create a connection on startup. Can be used to warm-up the pool on startup.spring.activemq.pool.enabled=false # Whether a PooledConnectionFactory should be created instead of a regular ConnectionFactory.spring.activemq.pool.expiry-timeout=0 # Connection expiration timeout in milliseconds.spring.activemq.pool.idle-timeout=30000 # Connection idle timeout in milliseconds.spring.activemq.pool.max-connections=1 # Maximum number of pooled connections.spring.activemq.pool.maximum-active-session-per-connection=500 # Maximum number of active sessions per connection.spring.activemq.pool.reconnect-on-exception=true # Reset the connection when a &quot;JMXException&quot; occurs.spring.activemq.pool.time-between-expiration-check=-1 # Time to sleep, in milliseconds, between runs of the idle connection eviction thread. When negative, no idle connection eviction thread runs.spring.activemq.pool.use-anonymous-producers=true # Use only one anonymous &quot;MessageProducer&quot; instance. Set it to false to create one &quot;MessageProducer&quot; every time one is required.# ARTEMIS (ArtemisProperties)spring.artemis.embedded.cluster-password= # Cluster password. Randomly generated on startup by default.spring.artemis.embedded.data-directory= # Journal file directory. Not necessary if persistence is turned off.spring.artemis.embedded.enabled=true # Enable embedded mode if the Artemis server APIs are available.spring.artemis.embedded.persistent=false # Enable persistent store.spring.artemis.embedded.queues= # Comma-separated list of queues to create on startup.spring.artemis.embedded.server-id= # Server id. By default, an auto-incremented counter is used.spring.artemis.embedded.topics= # Comma-separated list of topics to create on startup.spring.artemis.host=localhost # Artemis broker host.spring.artemis.mode= # Artemis deployment mode, auto-detected by default.spring.artemis.password= # Login password of the broker.spring.artemis.port=61616 # Artemis broker port.spring.artemis.user= # Login user of the broker.# SPRING BATCH (BatchProperties)spring.batch.initializer.enabled= # Create the required batch tables on startup if necessary. Enabled automatically if no custom table prefix is set or if a custom schema is configured.spring.batch.job.enabled=true # Execute all Spring Batch jobs in the context on startup.spring.batch.job.names= # Comma-separated list of job names to execute on startup (For instance `job1,job2`). By default, all Jobs found in the context are executed.spring.batch.schema=classpath:org/springframework/batch/core/schema-@@platform@@.sql # Path to the SQL file to use to initialize the database schema.spring.batch.table-prefix= # Table prefix for all the batch meta-data tables.# JMS (JmsProperties)spring.jms.jndi-name= # Connection factory JNDI name. When set, takes precedence to others connection factory auto-configurations.spring.jms.listener.acknowledge-mode= # Acknowledge mode of the container. By default, the listener is transacted with automatic acknowledgment.spring.jms.listener.auto-startup=true # Start the container automatically on startup.spring.jms.listener.concurrency= # Minimum number of concurrent consumers.spring.jms.listener.max-concurrency= # Maximum number of concurrent consumers.spring.jms.pub-sub-domain=false # Specify if the default destination type is topic.spring.jms.template.default-destination= # Default destination to use on send/receive operations that do not have a destination parameter.spring.jms.template.delivery-delay= # Delivery delay to use for send calls in milliseconds.spring.jms.template.delivery-mode= # Delivery mode. Enable QoS when set.spring.jms.template.priority= # Priority of a message when sending. Enable QoS when set.spring.jms.template.qos-enabled= # Enable explicit QoS when sending a message.spring.jms.template.receive-timeout= # Timeout to use for receive calls in milliseconds.spring.jms.template.time-to-live= # Time-to-live of a message when sending in milliseconds. Enable QoS when set.# APACHE KAFKA (KafkaProperties)spring.kafka.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.client-id= # Id to pass to the server when making requests; used for server-side logging.spring.kafka.consumer.auto-commit-interval= # Frequency in milliseconds that the consumer offsets are auto-committed to Kafka if &apos;enable.auto.commit&apos; true.spring.kafka.consumer.auto-offset-reset= # What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server.spring.kafka.consumer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.consumer.client-id= # Id to pass to the server when making requests; used for server-side logging.spring.kafka.consumer.enable-auto-commit= # If true the consumer&apos;s offset will be periodically committed in the background.spring.kafka.consumer.fetch-max-wait= # Maximum amount of time in milliseconds the server will block before answering the fetch request if there isn&apos;t sufficient data to immediately satisfy the requirement given by &quot;fetch.min.bytes&quot;.spring.kafka.consumer.fetch-min-size= # Minimum amount of data the server should return for a fetch request in bytes.spring.kafka.consumer.group-id= # Unique string that identifies the consumer group this consumer belongs to.spring.kafka.consumer.heartbeat-interval= # Expected time in milliseconds between heartbeats to the consumer coordinator.spring.kafka.consumer.key-deserializer= # Deserializer class for keys.spring.kafka.consumer.max-poll-records= # Maximum number of records returned in a single call to poll().spring.kafka.consumer.value-deserializer= # Deserializer class for values.spring.kafka.listener.ack-count= # Number of records between offset commits when ackMode is &quot;COUNT&quot; or &quot;COUNT_TIME&quot;.spring.kafka.listener.ack-mode= # Listener AckMode; see the spring-kafka documentation.spring.kafka.listener.ack-time= # Time in milliseconds between offset commits when ackMode is &quot;TIME&quot; or &quot;COUNT_TIME&quot;.spring.kafka.listener.concurrency= # Number of threads to run in the listener containers.spring.kafka.listener.poll-timeout= # Timeout in milliseconds to use when polling the consumer.spring.kafka.producer.acks= # Number of acknowledgments the producer requires the leader to have received before considering a request complete.spring.kafka.producer.batch-size= # Number of records to batch before sending.spring.kafka.producer.bootstrap-servers= # Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.spring.kafka.producer.buffer-memory= # Total bytes of memory the producer can use to buffer records waiting to be sent to the server.spring.kafka.producer.client-id= # Id to pass to the server when making requests; used for server-side logging.spring.kafka.producer.compression-type= # Compression type for all data generated by the producer.spring.kafka.producer.key-serializer= # Serializer class for keys.spring.kafka.producer.retries= # When greater than zero, enables retrying of failed sends.spring.kafka.producer.value-serializer= # Serializer class for values.spring.kafka.properties.*= # Additional properties used to configure the client.spring.kafka.ssl.key-password= # Password of the private key in the key store file.spring.kafka.ssl.keystore-location= # Location of the key store file.spring.kafka.ssl.keystore-password= # Store password for the key store file.spring.kafka.ssl.truststore-location= # Location of the trust store file.spring.kafka.ssl.truststore-password= # Store password for the trust store file.spring.kafka.template.default-topic= # Default topic to which messages will be sent.# RABBIT (RabbitProperties)spring.rabbitmq.addresses= # Comma-separated list of addresses to which the client should connect.spring.rabbitmq.cache.channel.checkout-timeout= # Number of milliseconds to wait to obtain a channel if the cache size has been reached.spring.rabbitmq.cache.channel.size= # Number of channels to retain in the cache.spring.rabbitmq.cache.connection.mode=channel # Connection factory cache mode.spring.rabbitmq.cache.connection.size= # Number of connections to cache.spring.rabbitmq.connection-timeout= # Connection timeout, in milliseconds; zero for infinite.spring.rabbitmq.dynamic=true # Create an AmqpAdmin bean.spring.rabbitmq.host=localhost # RabbitMQ host.spring.rabbitmq.listener.simple.acknowledge-mode= # Acknowledge mode of container.spring.rabbitmq.listener.simple.auto-startup=true # Start the container automatically on startup.spring.rabbitmq.listener.simple.concurrency= # Minimum number of consumers.spring.rabbitmq.listener.simple.default-requeue-rejected= # Whether or not to requeue delivery failures; default `true`.spring.rabbitmq.listener.simple.idle-event-interval= # How often idle container events should be published in milliseconds.spring.rabbitmq.listener.simple.max-concurrency= # Maximum number of consumers.spring.rabbitmq.listener.simple.prefetch= # Number of messages to be handled in a single request. It should be greater than or equal to the transaction size (if used).spring.rabbitmq.listener.simple.retry.enabled=false # Whether or not publishing retries are enabled.spring.rabbitmq.listener.simple.retry.initial-interval=1000 # Interval between the first and second attempt to deliver a message.spring.rabbitmq.listener.simple.retry.max-attempts=3 # Maximum number of attempts to deliver a message.spring.rabbitmq.listener.simple.retry.max-interval=10000 # Maximum interval between attempts.spring.rabbitmq.listener.simple.retry.multiplier=1.0 # A multiplier to apply to the previous delivery retry interval.spring.rabbitmq.listener.simple.retry.stateless=true # Whether or not retry is stateless or stateful.spring.rabbitmq.listener.simple.transaction-size= # Number of messages to be processed in a transaction. For best results it should be less than or equal to the prefetch count.spring.rabbitmq.password= # Login to authenticate against the broker.spring.rabbitmq.port=5672 # RabbitMQ port.spring.rabbitmq.publisher-confirms=false # Enable publisher confirms.spring.rabbitmq.publisher-returns=false # Enable publisher returns.spring.rabbitmq.requested-heartbeat= # Requested heartbeat timeout, in seconds; zero for none.spring.rabbitmq.ssl.enabled=false # Enable SSL support.spring.rabbitmq.ssl.key-store= # Path to the key store that holds the SSL certificate.spring.rabbitmq.ssl.key-store-password= # Password used to access the key store.spring.rabbitmq.ssl.trust-store= # Trust store that holds SSL certificates.spring.rabbitmq.ssl.trust-store-password= # Password used to access the trust store.spring.rabbitmq.ssl.algorithm= # SSL algorithm to use. By default configure by the rabbit client library.spring.rabbitmq.template.mandatory=false # Enable mandatory messages.spring.rabbitmq.template.receive-timeout=0 # Timeout for `receive()` methods.spring.rabbitmq.template.reply-timeout=5000 # Timeout for `sendAndReceive()` methods.spring.rabbitmq.template.retry.enabled=false # Set to true to enable retries in the `RabbitTemplate`.spring.rabbitmq.template.retry.initial-interval=1000 # Interval between the first and second attempt to publish a message.spring.rabbitmq.template.retry.max-attempts=3 # Maximum number of attempts to publish a message.spring.rabbitmq.template.retry.max-interval=10000 # Maximum number of attempts to publish a message.spring.rabbitmq.template.retry.multiplier=1.0 # A multiplier to apply to the previous publishing retry interval.spring.rabbitmq.username= # Login user to authenticate to the broker.spring.rabbitmq.virtual-host= # Virtual host to use when connecting to the broker.# ----------------------------------------# ACTUATOR PROPERTIES# ----------------------------------------# ENDPOINTS (AbstractEndpoint subclasses)endpoints.enabled=true # Enable endpoints.endpoints.sensitive= # Default endpoint sensitive setting.endpoints.actuator.enabled=true # Enable the endpoint.endpoints.actuator.path= # Endpoint URL path.endpoints.actuator.sensitive=false # Enable security on the endpoint.endpoints.auditevents.enabled= # Enable the endpoint.endpoints.auditevents.path= # Endpoint path.endpoints.auditevents.sensitive=false # Enable security on the endpoint.endpoints.autoconfig.enabled= # Enable the endpoint.endpoints.autoconfig.id= # Endpoint identifier.endpoints.autoconfig.path= # Endpoint path.endpoints.autoconfig.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.beans.enabled= # Enable the endpoint.endpoints.beans.id= # Endpoint identifier.endpoints.beans.path= # Endpoint path.endpoints.beans.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.configprops.enabled= # Enable the endpoint.endpoints.configprops.id= # Endpoint identifier.endpoints.configprops.keys-to-sanitize=password,secret,key,token,.*credentials.*,vcap_services # Keys that should be sanitized. Keys can be simple strings that the property ends with or regex expressions.endpoints.configprops.path= # Endpoint path.endpoints.configprops.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.docs.curies.enabled=false # Enable the curie generation.endpoints.docs.enabled=true # Enable actuator docs endpoint.endpoints.docs.path=/docs #endpoints.docs.sensitive=false #endpoints.dump.enabled= # Enable the endpoint.endpoints.dump.id= # Endpoint identifier.endpoints.dump.path= # Endpoint path.endpoints.dump.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.env.enabled= # Enable the endpoint.endpoints.env.id= # Endpoint identifier.endpoints.env.keys-to-sanitize=password,secret,key,token,.*credentials.*,vcap_services # Keys that should be sanitized. Keys can be simple strings that the property ends with or regex expressions.endpoints.env.path= # Endpoint path.endpoints.env.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.flyway.enabled= # Enable the endpoint.endpoints.flyway.id= # Endpoint identifier.endpoints.flyway.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.health.enabled= # Enable the endpoint.endpoints.health.id= # Endpoint identifier.endpoints.health.mapping.*= # Mapping of health statuses to HTTP status codes. By default, registered health statuses map to sensible defaults (i.e. UP maps to 200).endpoints.health.path= # Endpoint path.endpoints.health.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.health.time-to-live=1000 # Time to live for cached result, in milliseconds.endpoints.heapdump.enabled= # Enable the endpoint.endpoints.heapdump.path= # Endpoint path.endpoints.heapdump.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.hypermedia.enabled=false # Enable hypermedia support for endpoints.endpoints.info.enabled= # Enable the endpoint.endpoints.info.id= # Endpoint identifier.endpoints.info.path= # Endpoint path.endpoints.info.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.jolokia.enabled=true # Enable Jolokia endpoint.endpoints.jolokia.path=/jolokia # Endpoint URL path.endpoints.jolokia.sensitive=true # Enable security on the endpoint.endpoints.liquibase.enabled= # Enable the endpoint.endpoints.liquibase.id= # Endpoint identifier.endpoints.liquibase.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.logfile.enabled=true # Enable the endpoint.endpoints.logfile.external-file= # External Logfile to be accessed.endpoints.logfile.path=/logfile # Endpoint URL path.endpoints.logfile.sensitive=true # Enable security on the endpoint.endpoints.loggers.enabled=true # Enable the endpoint.endpoints.loggers.id= # Endpoint identifier.endpoints.loggers.path=/logfile # Endpoint path.endpoints.loggers.sensitive=true # Mark if the endpoint exposes sensitive information.endpoints.mappings.enabled= # Enable the endpoint.endpoints.mappings.id= # Endpoint identifier.endpoints.mappings.path= # Endpoint path.endpoints.mappings.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.metrics.enabled= # Enable the endpoint.endpoints.metrics.filter.enabled=true # Enable the metrics servlet filter.endpoints.metrics.filter.gauge-submissions=merged # Http filter gauge submissions (merged, per-http-method)endpoints.metrics.filter.counter-submissions=merged # Http filter counter submissions (merged, per-http-method)endpoints.metrics.id= # Endpoint identifier.endpoints.metrics.path= # Endpoint path.endpoints.metrics.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.shutdown.enabled= # Enable the endpoint.endpoints.shutdown.id= # Endpoint identifier.endpoints.shutdown.path= # Endpoint path.endpoints.shutdown.sensitive= # Mark if the endpoint exposes sensitive information.endpoints.trace.enabled= # Enable the endpoint.endpoints.trace.filter.enabled=true # Enable the trace servlet filter.endpoints.trace.id= # Endpoint identifier.endpoints.trace.path= # Endpoint path.endpoints.trace.sensitive= # Mark if the endpoint exposes sensitive information.# ENDPOINTS CORS CONFIGURATION (EndpointCorsProperties)endpoints.cors.allow-credentials= # Set whether credentials are supported. When not set, credentials are not supported.endpoints.cors.allowed-headers= # Comma-separated list of headers to allow in a request. &apos;*&apos; allows all headers.endpoints.cors.allowed-methods=GET # Comma-separated list of methods to allow. &apos;*&apos; allows all methods.endpoints.cors.allowed-origins= # Comma-separated list of origins to allow. &apos;*&apos; allows all origins. When not set, CORS support is disabled.endpoints.cors.exposed-headers= # Comma-separated list of headers to include in a response.endpoints.cors.max-age=1800 # How long, in seconds, the response from a pre-flight request can be cached by clients.# JMX ENDPOINT (EndpointMBeanExportProperties)endpoints.jmx.domain= # JMX domain name. Initialized with the value of &apos;spring.jmx.default-domain&apos; if set.endpoints.jmx.enabled=true # Enable JMX export of all endpoints.endpoints.jmx.static-names= # Additional static properties to append to all ObjectNames of MBeans representing Endpoints.endpoints.jmx.unique-names=false # Ensure that ObjectNames are modified in case of conflict.# JOLOKIA (JolokiaProperties)jolokia.config.*= # See Jolokia manual# MANAGEMENT HTTP SERVER (ManagementServerProperties)management.add-application-context-header=true # Add the &quot;X-Application-Context&quot; HTTP header in each response.management.address= # Network address that the management endpoints should bind to.management.context-path= # Management endpoint context-path. For instance `/actuator`management.cloudfoundry.enabled= # Enable extended Cloud Foundry actuator endpointsmanagement.cloudfoundry.skip-ssl-validation= # Skip SSL verification for Cloud Foundry actuator endpoint security callsmanagement.port= # Management endpoint HTTP port. Uses the same port as the application by default. Configure a different port to use management-specific SSL.management.security.enabled=true # Enable security.management.security.roles=ACTUATOR # Comma-separated list of roles that can access the management endpoint.management.security.sessions=stateless # Session creating policy to use (always, never, if_required, stateless).management.ssl.ciphers= # Supported SSL ciphers. Requires a custom management.port.management.ssl.client-auth= # Whether client authentication is wanted (&quot;want&quot;) or needed (&quot;need&quot;). Requires a trust store. Requires a custom management.port.management.ssl.enabled= # Enable SSL support. Requires a custom management.port.management.ssl.enabled-protocols= # Enabled SSL protocols. Requires a custom management.port.management.ssl.key-alias= # Alias that identifies the key in the key store. Requires a custom management.port.management.ssl.key-password= # Password used to access the key in the key store. Requires a custom management.port.management.ssl.key-store= # Path to the key store that holds the SSL certificate (typically a jks file). Requires a custom management.port.management.ssl.key-store-password= # Password used to access the key store. Requires a custom management.port.management.ssl.key-store-provider= # Provider for the key store. Requires a custom management.port.management.ssl.key-store-type= # Type of the key store. Requires a custom management.port.management.ssl.protocol=TLS # SSL protocol to use. Requires a custom management.port.management.ssl.trust-store= # Trust store that holds SSL certificates. Requires a custom management.port.management.ssl.trust-store-password= # Password used to access the trust store. Requires a custom management.port.management.ssl.trust-store-provider= # Provider for the trust store. Requires a custom management.port.management.ssl.trust-store-type= # Type of the trust store. Requires a custom management.port.# HEALTH INDICATORSmanagement.health.db.enabled=true # Enable database health check.management.health.cassandra.enabled=true # Enable cassandra health check.management.health.couchbase.enabled=true # Enable couchbase health check.management.health.defaults.enabled=true # Enable default health indicators.management.health.diskspace.enabled=true # Enable disk space health check.management.health.diskspace.path= # Path used to compute the available disk space.management.health.diskspace.threshold=0 # Minimum disk space that should be available, in bytes.management.health.elasticsearch.enabled=true # Enable elasticsearch health check.management.health.elasticsearch.indices= # Comma-separated index names.management.health.elasticsearch.response-timeout=100 # The time, in milliseconds, to wait for a response from the cluster.management.health.jms.enabled=true # Enable JMS health check.management.health.ldap.enabled=true # Enable LDAP health check.management.health.mail.enabled=true # Enable Mail health check.management.health.mongo.enabled=true # Enable MongoDB health check.management.health.rabbit.enabled=true # Enable RabbitMQ health check.management.health.redis.enabled=true # Enable Redis health check.management.health.solr.enabled=true # Enable Solr health check.management.health.status.order=DOWN, OUT_OF_SERVICE, UP, UNKNOWN # Comma-separated list of health statuses in order of severity.# INFO CONTRIBUTORS (InfoContributorProperties)management.info.build.enabled=true # Enable build info.management.info.defaults.enabled=true # Enable default info contributors.management.info.env.enabled=true # Enable environment info.management.info.git.enabled=true # Enable git info.management.info.git.mode=simple # Mode to use to expose git information.# REMOTE SHELL (ShellProperties)management.shell.auth.type=simple # Authentication type. Auto-detected according to the environment.management.shell.auth.jaas.domain=my-domain # JAAS domain.management.shell.auth.key.path= # Path to the authentication key. This should point to a valid &quot;.pem&quot; file.management.shell.auth.simple.user.name=user # Login user.management.shell.auth.simple.user.password= # Login password.management.shell.auth.spring.roles=ACTUATOR # Comma-separated list of required roles to login to the CRaSH console.management.shell.command-path-patterns=classpath*:/commands/**,classpath*:/crash/commands/** # Patterns to use to look for commands.management.shell.command-refresh-interval=-1 # Scan for changes and update the command if necessary (in seconds).management.shell.config-path-patterns=classpath*:/crash/* # Patterns to use to look for configurations.management.shell.disabled-commands=jpa*,jdbc*,jndi* # Comma-separated list of commands to disable.management.shell.disabled-plugins= # Comma-separated list of plugins to disable. Certain plugins are disabled by default based on the environment.management.shell.ssh.auth-timeout = # Number of milliseconds after user will be prompted to login again.management.shell.ssh.enabled=true # Enable CRaSH SSH support.management.shell.ssh.idle-timeout = # Number of milliseconds after which unused connections are closed.management.shell.ssh.key-path= # Path to the SSH server key.management.shell.ssh.port=2000 # SSH port.management.shell.telnet.enabled=false # Enable CRaSH telnet support. Enabled by default if the TelnetPlugin is available.management.shell.telnet.port=5000 # Telnet port.# TRACING (TraceProperties)management.trace.include=request-headers,response-headers,cookies,errors # Items to be included in the trace.# METRICS EXPORT (MetricExportProperties)spring.metrics.export.aggregate.key-pattern= # Pattern that tells the aggregator what to do with the keys from the source repository.spring.metrics.export.aggregate.prefix= # Prefix for global repository if active.spring.metrics.export.delay-millis=5000 # Delay in milliseconds between export ticks. Metrics are exported to external sources on a schedule with this delay.spring.metrics.export.enabled=true # Flag to enable metric export (assuming a MetricWriter is available).spring.metrics.export.excludes= # List of patterns for metric names to exclude. Applied after the includes.spring.metrics.export.includes= # List of patterns for metric names to include.spring.metrics.export.redis.key=keys.spring.metrics # Key for redis repository export (if active).spring.metrics.export.redis.prefix=spring.metrics # Prefix for redis repository if active.spring.metrics.export.send-latest= # Flag to switch off any available optimizations based on not exporting unchanged metric values.spring.metrics.export.statsd.host= # Host of a statsd server to receive exported metrics.spring.metrics.export.statsd.port=8125 # Port of a statsd server to receive exported metrics.spring.metrics.export.statsd.prefix= # Prefix for statsd exported metrics.spring.metrics.export.triggers.*= # Specific trigger properties per MetricWriter bean name.# ----------------------------------------# DEVTOOLS PROPERTIES# ----------------------------------------# DEVTOOLS (DevToolsProperties)spring.devtools.livereload.enabled=true # Enable a livereload.com compatible server.spring.devtools.livereload.port=35729 # Server port.spring.devtools.restart.additional-exclude= # Additional patterns that should be excluded from triggering a full restart.spring.devtools.restart.additional-paths= # Additional paths to watch for changes.spring.devtools.restart.enabled=true # Enable automatic restart.spring.devtools.restart.exclude=META-INF/maven/**,META-INF/resources/**,resources/**,static/**,public/**,templates/**,**/*Test.class,**/*Tests.class,git.properties # Patterns that should be excluded from triggering a full restart.spring.devtools.restart.poll-interval=1000 # Amount of time (in milliseconds) to wait between polling for classpath changes.spring.devtools.restart.quiet-period=400 # Amount of quiet time (in milliseconds) required without any classpath changes before a restart is triggered.spring.devtools.restart.trigger-file= # Name of a specific file that when changed will trigger the restart check. If not specified any classpath file change will trigger the restart.# REMOTE DEVTOOLS (RemoteDevToolsProperties)spring.devtools.remote.context-path=/.~~spring-boot!~ # Context path used to handle the remote connection.spring.devtools.remote.debug.enabled=true # Enable remote debug support.spring.devtools.remote.debug.local-port=8000 # Local remote debug server port.spring.devtools.remote.proxy.host= # The host of the proxy to use to connect to the remote application.spring.devtools.remote.proxy.port= # The port of the proxy to use to connect to the remote application.spring.devtools.remote.restart.enabled=true # Enable remote restart.spring.devtools.remote.secret= # A shared secret required to establish a connection (required to enable remote support).spring.devtools.remote.secret-header-name=X-AUTH-TOKEN # HTTP header used to transfer the shared secret.# ----------------------------------------# TESTING PROPERTIES# ----------------------------------------spring.test.database.replace=any # Type of existing DataSource to replace.spring.test.mockmvc.print=default # MVC Print option.]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea常用快捷键]]></title>
    <url>%2F2019%2F06%2F11%2Fidea%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2Fidea%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[Idea必备快捷键 查看方法的具体实现 Ctrl + Alt + 鼠标 查看类的继承实现图 Ctrl + Alt + u 生成构造方法、getter等 Alt + insert 对选中的代码弹出环绕选项弹出层 Ctrl + Alt + t]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nio之零拷贝]]></title>
    <url>%2F2019%2F06%2F04%2FNio%E4%B9%8B%E9%9B%B6%E6%8B%B7%E8%B4%9D%2FNio%E4%B9%8B%E9%9B%B6%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[Linux中的内核态与用户态 如上图所示，Unix/Linux的体系架构分为内核空间（kernal space）与用户空间(application space)，内核控制着计算机的硬件资源，为上层应用程序提供运行环境。用户空间就是应用程序的活动空间，而内核为应用程序的执行提供着必要的cpu、存储、IO资源等。为了使应用程序访问使用到这些资源，内核就提供了资源访问的接口：系统调用。 传统IO的拷贝 数据先从硬件资源被拷贝到内核空间的缓冲区中(kernel buffer)。 然后再从内核空间的缓冲区中拷贝到用户空间的缓冲区（application buffer）中。 接着从用户空间再拷贝到内核空间中的Socket buffer/Write buffer中。 最后再从Socket buffer中拷贝到网卡缓冲区/硬件资源中。 这个过程经过了4次的数据拷贝，其中有2次（1和4）是DMA拷贝（直接内存拷贝，不需要cpu的参与），2和3是cpu拷贝。 应用程序发起了read和write系统调用，会经过4次的上下文切换。 Nio中的零拷贝sendFile零拷贝在Java的Nio中有个transferTo()方法，可以将一个channel里面的字节直接复制到另一个可以写入字节的channel中，此方法比从通道读取并写入目标通道的简单循环更有效。操作系统可以直接从文件系统缓存向目标通道传输字节，而无需实际复制它们。transferTo()最后内部封装的是sendFile这个系统调用。 基本代码如下： 12345678910111213public class NewClient &#123; public static void main(String[] args) throws Exception&#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress("localhost",8898)); String fileName = "/home/Desktop/pycharm-professional-2019.1.2.tar.gz"; FileInputStream fileInputStream = new FileInputStream(fileName); FileChannel channel = fileInputStream.getChannel(); long transfer = channel.transferTo(0, channel.size(), socketChannel); &#125;&#125; 它的流程如下： 应用程序调用transferTo方法，即JVM发起sendFile系统调用，从用户态切换到内核态（第一次上下文切换）。 内核将数据从硬件资源里DMA拷贝到内核空间的缓冲区中。 然后经过CPU拷贝到Socket buffer中。 接着sendFile系统调用返回，将数据DMA拷贝到网卡缓冲区/硬件资源中（第二次上下文切换）。 虽然在内核态时，经过了一次cpu拷贝，但并没有从内核态切换到用户态，对于操作系统来说，这已经是零拷贝了（DMA拷贝需要连续的内存空间，所以需要缓冲区）。如果底层操作系统支持分散与收集（scatter and gather）的话，就可以实现真正意义上的零拷贝。 收集拷贝功能的零拷贝 应用程序调用transferTo方法，即JVM发起sendFile系统调用，从用户态切换到内核态（第一次上下文切换）。 内核将数据从硬件资源里DMA拷贝到内核空间的缓冲区中。 现在并没有数据会拷贝到Socket buffer，而是Read buffer中数据的相关描述信息（Read buffer缓冲区的内存地址以及偏移量，即长度）会被拷贝到Socket buffer中（即图中的Descriptor）。 接着sendFile系统调用返回，DMA gather copy根据Socket buffer中的描述信息（第二次上下文切换）直接将数据从内核空间拷贝网卡缓冲区/硬件资源中。 直接内存零拷贝提升了文件读写的速度，但是因为没有经过用户态，用户程序无法对文件进行操作，所以零拷贝应应用于不需要对文件进行操作的读写场景，但又想提高速度，但又需要对数据进行操作怎么办？那就应该使用NIO的直接内存。它的具体实现是通过mmap内存映射系统调用完成的，它是一个优于传统IO但比sendFile昂贵的IO方法。 应用程序调发起mmap系统调用，从用户态切换到内核态（第一次上下文切换）。 通过DMA引擎将数据从硬件拷贝到内核空间缓冲区。 mmap系统调用返回，内核态切换为用户态（第二次上下文切换）。用户空间和内核空间就共享这一片缓冲区，而不需要将数据从内核空间拷贝到用户空间。因为用户空间和内核空间共享了这个缓冲区数据，所以用户空间就可以像在操作自己缓冲区中数据一般操作这个由内核空间共享的缓冲区数据。 应用程序发起write系统调用，用户态切换到内核态（第三次上下文切换）。 数据经过CPU拷贝到Socket buffer中。 write系统调用返回，内核态切换为用户态（第四次上下文切换）。 数据通过DMA引擎拷贝到网卡缓冲区/硬件资源中。 NIO中的直接内存123456789FileChannel channel = new FileInputStream("").getChannel();//map方法接受3个参数//FileChannel.MapMode mode： //Read-only:只读 //Read_write:对结果缓冲区所做的更改最终会传播到文件中;它们可能会或可能不会被映射到同一文件的其他程序 看到。 //privarte:对结果缓冲区所做的更改不会传播到文件，并且对于映射了同一文件的其他程序不可见;相反，它将导 致被修改部分缓冲区独自拷贝一份到用户空间。//position:映射区域的起始位置。//size:要映射区域的大小。MappedByteBuffer map = channel.map(FileChanne.MapMode.READ_ONLY, 0, 2); NIO的直接内存是由MappedByteBuffer实现的。核心即是map()方法，该方法把文件映射到内存中，获得内存地址addr，然后通过这个addr构造MappedByteBuffer类，以暴露各种文件操作API。 由于MappedByteBuffer申请的是堆外内存，因此不受Minor GC控制，只能在发生Full GC时才能被回收。而DirectByteBuffer改善了这一情况，它是MappedByteBuffer类的子类，同时它实现了DirectBuffer接口，维护一个Cleaner对象来完成内存回收。因此它既可以通过Full GC来回收内存，也可以调用clean()方法来进行回收。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>nio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Gradle、Maven项目buildg后没有mybatis的mapper.xml文件问题]]></title>
    <url>%2F2019%2F05%2F31%2F%E8%A7%A3%E5%86%B3Gradle%E5%92%8CMaven%E9%A1%B9%E7%9B%AEbuildg%E5%90%8E%E6%B2%A1%E6%9C%89mybatis%E7%9A%84mapper-xml%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98%2F%E8%A7%A3%E5%86%B3Gradle%E5%92%8CMaven%E9%A1%B9%E7%9B%AEbuildg%E5%90%8E%E6%B2%A1%E6%9C%89mybatis%E7%9A%84mapper-xml%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Gradle、Maven都默认只把resources目录当作资源目录，所以在编译时就不会把java目录下的mapper.xml文件编译到输出目录，所以需要在相关文件中修改默认资源目录。 Maven 在pom文件中加入 1234567891011121314151617181920&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; Gradle 在build.gradle文件中加入 1sourceSets.main.resources.srcDirs = ["src/main/java","src/main/resources"]]]></content>
  </entry>
  <entry>
    <title><![CDATA[nio：Selector示例解析]]></title>
    <url>%2F2019%2F05%2F30%2Fnio%EF%BC%9ASelector%E7%A4%BA%E4%BE%8B%E8%A7%A3%E6%9E%90%2Fnio%EF%BC%9ASelector%E7%A4%BA%E4%BE%8B%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Nio三大核心概念Nio中有三大核心概念：Buffer、Channel、Selector。 Buffer本身是一块内存，底层实现上，是一个数组。数据的读写都是通过Buffer实现的。所有的数据的读写都是通过Buffer来进行的，永远不会出现直接向Channel读写的情况。 具体原理与API：https://www.cnblogs.com/chenpi/p/6475510.html Channel指的是可以向其读写数据的对象，类似于java.io中的Stream。Stream只能是InputStream或者OutputStream，Channel所不同的是，Channel是双向的，Channel打开后，则可以进行读取、写入。 Selector可以管理着多条Channel通道，并且可以知晓这些通道是否为Accept、Connect、Read、Write做好了准备。通过Selector可以管理多个网络连接，也就是说，在一个线程中就可以管理多个Channel，这也是跟传统io的区别，这样单线程的话，减少了线程上下文切换的开销。 示例服务端程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class NioServer &#123; //保存通道的map，以通道的地址作为key private static Map&lt;String,SocketChannel&gt; map = new HashMap&lt;&gt;(); public static void main(String[] args) throws Exception&#123; //创建ServerSocketChannel实例，并绑定端口 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); //使用Selector，必须处于非阻塞模式 serverSocketChannel.configureBlocking(false); ServerSocket serverSocket = serverSocketChannel.socket(); serverSocket.bind(new InetSocketAddress(8899)); //创建一个Selector Selector selector = Selector.open(); //将channel注册到selector上，并绑定selector对于此通道的感兴趣的事件，当此通道`接受就绪`时，selector就可以知道此通道`接受就绪`。这样就实现了通道和Selector的关联关系。共有四种常量状态 //SelectionKey.OP_CONNECT //SelectionKey.OP_ACCEPT //SelectionKey.OP_READ //SelectionKey.OP_WRITE serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); // while (true)&#123; //返回keys的数量，若没有，在阻塞一段时间后，返回0 int select = selector.select(); if (select == 0) continue; //获取SelectionKey集合，通过这些SelectionKey可以获取到相应的就绪通道 Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); //这个循环遍历已选择键集中的每个键，并检测各个键所对应的通道的就绪事件。 selectionKeys.forEach(selectionKey -&gt; &#123; final SocketChannel client; try &#123; if(selectionKey.isAcceptable()) &#123; //如果有客户端连接服务，触发accept事件 ServerSocketChannel channel = (ServerSocketChannel) selectionKey.channel(); client = channel.accept(); client.configureBlocking(false); String s = client.getRemoteAddress().toString(); System.out.println(s); //在selector上注册socketChannel的OP_READ事件。 client.register(selector,SelectionKey.OP_READ); //将通道放入map中保存 map.put(s,client); //从 selectionKeys删除掉已处理的selectionKey，不然会一直循环 selectionKeys.remove(selectionKey); &#125;else if(selectionKey.isReadable())&#123; //如果有客户端发送数据，触发read事件 SocketChannel socketChannel = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); //将数据读到Buffer中 int write = socketChannel.read(byteBuffer); if (write &gt; 0) &#123; //将position移到0处 byteBuffer.flip(); Charset charset = Charset.forName("utf-8"); //解码出字符串 String valueOf = String.valueOf(charset.decode(byteBuffer)); System.out.println(valueOf); SocketAddress remoteAddress = socketChannel.getRemoteAddress(); //将服务端接收到的数据，发送给其他的客户端，通过保存在map中CHannel //比较 for (Map.Entry&lt;String,SocketChannel&gt; entry: map.entrySet()) &#123; SocketChannel value = entry.getValue(); //如果map中的Channel等于当前Channel，就不发送给这个Channel，这样就只有别的客户端嫩收到消息 if (value != socketChannel) &#123; byteBuffer.clear(); byteBuffer.put( valueOf.getBytes()); byteBuffer.flip(); value.write(byteBuffer); &#125; &#125; &#125; selectionKeys.remove(selectionKey); &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;); &#125; &#125;&#125; 客户端程序： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class NioClient &#123; public static void main(String[] args) throws IOException &#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); socketChannel.connect(new InetSocketAddress("localhost",8899)); Selector selector = Selector.open(); //将channel注册到selector上，并绑定selector对于此通道的感兴趣的事件，当此通道`接收连接`时，selector就可以知道此通道`接受连接`。这样就实现了通道和Selector的关联关系。 socketChannel.register(selector, SelectionKey.OP_CONNECT); while (true)&#123; int select = selector.select(); if(select == 0) continue; Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); selectionKeys.forEach(selectionKey -&gt; if(selectionKey.isConnectable())&#123; SocketChannel channel = (SocketChannel) selectionKey.channel(); //判断连接是否完成 if(channel.isConnectionPending())&#123; try &#123; channel.finishConnect(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byteBuffer.put((LocalDateTime.now() + " connect successed!").getBytes()); byteBuffer.flip(); channel.write(byteBuffer); //通过单线程池创建获取键盘输入的线程 ExecutorService executorService = Executors.newSingleThreadExecutor(Executors.defaultThreadFactory()); executorService.submit(() -&gt; &#123; while (true)&#123; byteBuffer.clear(); InputStreamReader inputStreamReader = new InputStreamReader(System.in); BufferedReader bufferedReader = new BufferedReader(inputStreamReader); String s = bufferedReader.readLine(); byteBuffer.put((channel.getLocalAddress().toString() + " : "+ s).getBytes()); byteBuffer.flip(); channel.write(byteBuffer); &#125; &#125;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; //将通道绑定为读事件 channel.register(selector,SelectionKey.OP_READ); &#125; catch (ClosedChannelException e) &#123; e.printStackTrace(); &#125; &#125;else if(selectionKey.isReadable())&#123; SocketChannel channel = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while (true)&#123; byteBuffer.clear(); try &#123; int read = channel.read(byteBuffer); if(read &lt;= 0) break; String s = new String(byteBuffer.array(), 0, read); System.out.println(s); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; selectionKeys.remove(selectionKey); &#125; &#125;); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>nio</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下安装thrift填坑记]]></title>
    <url>%2F2019%2F05%2F22%2Flinux%E4%B8%8B%E5%AE%89%E8%A3%85thrift%E5%A1%AB%E5%9D%91%E8%AE%B0%2Flinux%E4%B8%8B%E5%AE%89%E8%A3%85thrift%E5%A1%AB%E5%9D%91%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[引言（基于centos6）最近想安装个thrift来玩玩，看了网上的一些安装教程，报了一大堆的错，查了无数的资料，搞了一天，终于安装好了。。。 安装123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146#依赖安装yum -y updateyum install wgetyum install gityum install gcc gcc-c++yum install libevent-devel zlib-devel openssl-develyum install m4yum install glibc-devel glibc glib2 glib2-devel#autoconfyum install autoconf-2.69#libtoolwget http://mirrors.ustc.edu.cn/gnu/libtool/libtool-2.4.6.tar.gztar -xvf libtool-2.4.6.tar.gzcd libtool-2.4.6./bootstrap./configuremake &amp;make installcd ..#bisonwget http://ftp.gnu.org/gnu/bison/bison-3.0.4.tar.gztar -xvf bison-3.0.4.tar.gzcd bison-3.0.4./configure --prefix=/usr/soft/bisonmake &amp;make installcd ..#bootstrapwget http://sourceforge.net/projects/boost/files/boost/1.64.0/boost_1_64_0.tar.gztar -xvf boost_1_64_0.tar.gzcd boost_1_64_0./bootstrap.sh./b2 installcd ..#thrift，若时间很久，直接去官网下载吧 #http://www.apache.org/dyn/closer.cgi?path=/thrift/0.12.0/thrift-0.12.0.tar.gzgit clone https://github.com/apache/thrift.gitcd thrift./bootstrap.sh./configure --prefix=/usr/soft/thrift --with-boost=/usr/soft/bootstrap/#若出现如下错误，NO.1--------------------------------------------------------------------1./configure: line 3802: PKG_PROG_PKG_CONFIG: command not found./configure: line 18272: syntax error near unexpected token `QT,'./configure: line 18272: ` PKG_CHECK_MODULES(QT, QtCore &gt;= 4.3, QtNetwork &gt;= 4.3, have_qt=yes, have_qt=no)'#运行如下命令find /usr -name "pkg.m4" 返回 /usr/share/aclocal/pkg.m4aclocal --print-ac-dir 返回 /usr/local/share/aclocal#这两个地址不一样，再加上 bootstrap.sh 里面定义了 aclocal -I ./aclocal#这导致定义在 pkg.m4里全局变量 PKG_PROG_PKG_CONFIG 与 PKG_CHECK_MODULES 找不到，所以报错#做如下修改解决这个问题, 在bootstrap.sh 里面修改 aclocal -I ./aclocal -I /usr/share/aclocal/#保存 重新从 ./bootstrap.sh 就可以了！#然后继续make &amp;make install#若出现如下错误，NO.2-------------------------------------------------------------------2#搞忘了，反正错误就是你的gcc版本太低了，需要升级#下载gcc-4.8wget http://ftp.gnu.org/gnu/gcc/gcc-4.8.0/gcc-4.8.0.tar.bz2tar jxvf gcc-4.8.0.tar.bz2#下载编译所需依赖库cd gcc-4.8.0./contrib/download_prerequisitescd ..#编译安装mkdir gcc-build-4.8.0cd gcc-build-4.8.0../gcc-4.8.0/configure --enable-checking=release --enable-languages=c,c++ --disable-multilibmake -j 8make installgcc -v#若出现如下错误，NO.3-------------------------------------------------------------------3./src/thrift/server/TNonblockingServer.h:41:33: error: event2/event_compat.h: No such file or directory#找不到event2的头文件#直接去官网下载#https://github.com/libevent/libevent/releases/download/release-2.1.8-stable/libevent-2.1.8-stable.tar.gz#安装编译./configure --prefix=/usr/localmakemake install#若出现如下错误，NO.4-------------------------------------------------------------------4/usr/lib/libstdc++.so.6: version `GLIBCXX_3.4.18' not found #这是因为升级gcc时，生成的动态库没有替换老版本gcc的动态库，将gcc最新版本的动态库替换掉老版本的动态库即可#查看GLBCXX版本strings /usr/lib/libstdc++.so.6 | grep GLIBCXX#输出GLIBCXX_3.4GLIBCXX_3.4.1...GLIBCXX_3.4.11GLIBCXX_3.4.12GLIBCXX_3.4.13GLIBCXX_FORCE_NEWGLIBCXX_DEBUG_MESSAGE_LENGTH#可以看到，最高版本为3.4.13，没有对应的3.4.18#查看libstdc++.so.6链接的库ll /usr/lib/libstdc++.so.6#输出，这是libstdc++.so.6现在链接的库/usr/lib/libstdc++.so.6 -&gt; libstdc++.so.6.0.13 #查看系统更高版本的lib库find / -name libstdc++.so.6*#输出，这里有一个6.0.18版本，比libstdc++.so.6.0.13版本更高 /usr/lib64/libstdc++.so.6.bak/usr/lib64/libstdc++.so.6.0.13/usr/lib64/libstdc++.so.6/usr/lib64/libstdc++.so.6.0.20/usr/local/lib64/libstdc++.so.6/usr/local/lib64/libstdc++.so.6.0.18-gdb.py/usr/local/lib64/libstdc++.so.6.0.18 #查看lib库的信息strings /usr/local/lib/libstdc++.so.6.0.18 | grep GLIBCXX#输出，18这个版本满足我们的需求GLIBCXX_3.4GLIBCXX_3.4.1GLIBCXX_3.4.2...GLIBCXX_3.4.17GLIBCXX_3.4.18 GLIBCXX_FORCE_NEWGLIBCXX_DEBUG_MESSAGE_LENGTH#重新链接cp /usr/local/lib/libstdc++.so.6.0.20 /usr/lib64/libstdc++.so.6.0.18rm -f /usr/lib/libstdc++.so.6ln -s /usr/lib/libstdc++.so.6.0.20 /usr/lib64/libstdc++.so.6#若出现如下错误，NO.5-------------------------------------------------------------------5g++: error: /usr/lib/libboost_unit_test_framework.a: No such file or directory#查找文件find / -name libboost_unit_test_framework.a#输出/usr/local/lib/libboost_unit_test_framework.a#解决sudo ln -s /usr/local/lib/libboost_unit_test_framework.a /usr/lib/libboost_unit_test_framework.a#编译make &amp;make install成功]]></content>
      <categories>
        <category>thrift</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[protobuf集成netty实现多协议消息传递]]></title>
    <url>%2F2019%2F05%2F21%2Fprotobuf%E9%9B%86%E6%88%90netty%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%8D%8F%E8%AE%AE%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%2Fprotobuf%E9%9B%86%E6%88%90netty%E5%AE%9E%E7%8E%B0%E5%A4%9A%E5%8D%8F%E8%AE%AE%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%2F</url>
    <content type="text"><![CDATA[介绍当使用socket传输数据时，客户端服务端进行交互时，必须要知道数据类型，才能将数据序列化，在使用protobuf进行序列化时，可以使用官方推荐的方式实现多数据类型的传输。 proto文件123456789101112131415161718192021222324252627282930313233343536message MyMessage&#123; enum DataType&#123; StudentType = 1; DogType = 2; TeacherType =3; &#125; required DataType data_type = 1; oneof dataBody&#123; Student student = 2; Teacher teacher = 3; Dog dog = 4; &#125;&#125;message Student &#123; required string name = 1; optional int32 id = 2; optional string email = 3;&#125;message Dog &#123; required string name = 1; optional string type = 2;&#125;message Teacher &#123; required string name = 1; optional string address = 2;&#125; 在.proto文件中定义一个“外部”的类来进行包装所想要传递的一些数据类型，用枚举类型来表示包装在其中的数据类型是什么，data_type就来指明数据类型，dataBody就是所要传输的数据。 oneof官方解释：如果有一个包含许多字段的消息，并且最多只能同时设置一个字段，则可以使用oneof功能强制执行此行为并节省内存。 oneof里面可以包含许多数据类型，但是只会被设置一个数据类型，且设置了一个oneof字段后会清空掉前面所设置的其他oneof成员，所有这样可以节省许多内存。 集成nettyInitializer123456789101112131415161718public class MyProtoInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ChannelPipeline pipeline = ch.pipeline(); //解码器，通过Google Protocol Buffers序列化框架动态的切割接收到的ByteBuf pipeline.addLast(new ProtobufVarint32FrameDecoder()); //服务端\客户端接收的是DataInfo对象，所以这边将接收对象进行解码生产实列 pipeline.addLast(new ProtobufDecoder(DataInfo.MyMessage.getDefaultInstance())); //Google Protocol Buffers编码器 pipeline.addLast(new ProtobufVarint32LengthFieldPrepender()); //Google Protocol Buffers编码器 pipeline.addLast(new ProtobufEncoder()); pipeline.addLast(new MyProtoServerHandler()); //pipeline.addLast(new MyProtoClientHandler()); &#125;&#125; Serverhandler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class MyProtoServerHandler extends SimpleChannelInboundHandler&lt;DataInfo.MyMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, DataInfo.MyMessage msg) throws Exception &#123; //服务端随机的发送Student、Teacher、Dog到客户端 int v = new Random().nextInt(3); DataInfo.MyMessage myMessage = null; if(v == 0)&#123; //创建一个包装了Student的MyMessage的实例 myMessage = DataInfo.MyMessage.newBuilder(). setDataType(DataInfo.MyMessage.DataType.StudentType) .setStudent(DataInfo.Student.newBuilder(). setName("student").setEmail("qq@qqq").build()). build(); &#125;else if(v == 1)&#123; //创建一个包装了Teacher的MyMessage的实例 myMessage = DataInfo.MyMessage.newBuilder(). setDataType(DataInfo.MyMessage.DataType.TeacherType) .setTeacher(DataInfo.Teacher.newBuilder(). setName("teacher").setAddress("chengdu").build()). build(); &#125;else &#123; //创建一个包装了Dog的MyMessage的实例 myMessage = DataInfo.MyMessage.newBuilder(). setDataType(DataInfo.MyMessage.DataType.DogType) .setDog(DataInfo.Dog.newBuilder(). setName("dog").setType("erha").build()). build(); &#125; ctx.channel().writeAndFlush(myMessage); //打印出客户端发送到服务端的数据 DataInfo.MyMessage.DataType dataType = msg.getDataType(); if (dataType == DataInfo.MyMessage.DataType.StudentType)&#123; DataInfo.Student student = msg.getStudent(); System.out.println(student.getName()); System.out.println(student.getEmail()); &#125;else if(dataType == DataInfo.MyMessage.DataType.TeacherType)&#123; DataInfo.Teacher teacher = msg.getTeacher(); System.out.println(teacher.getName()); System.out.println(teacher.getAddress()); &#125;else &#123; DataInfo.Dog dog = msg.getDog(); System.out.println(dog.getName()); System.out.println(dog.getType()); &#125; &#125;&#125; ClientHandler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class MyProtoClientHandler extends SimpleChannelInboundHandler&lt;DataInfo.MyMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, DataInfo.MyMessage msg) throws Exception &#123; //打印服务端传输过来的数据 DataInfo.MyMessage.DataType dataType = msg.getDataType(); if (dataType == DataInfo.MyMessage.DataType.StudentType)&#123; DataInfo.Student student = msg.getStudent(); System.out.println(student.getName()); System.out.println(student.getEmail()); &#125;else if(dataType == DataInfo.MyMessage.DataType.TeacherType)&#123; DataInfo.Teacher teacher = msg.getTeacher(); System.out.println(teacher.getName()); System.out.println(teacher.getAddress()); &#125;else &#123; DataInfo.Dog dog = msg.getDog(); System.out.println(dog.getName()); System.out.println(dog.getType()); &#125; &#125; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; //先服务端发送数据 int v = new Random().nextInt(3); DataInfo.MyMessage myMessage = null; if(v == 0)&#123; myMessage = DataInfo.MyMessage.newBuilder(). setDataType(DataInfo.MyMessage.DataType.StudentType) .setStudent(DataInfo.Student.newBuilder(). setName("student").setEmail("qq@qqq").build()). build(); &#125;else if(v == 1)&#123; myMessage = DataInfo.MyMessage.newBuilder(). setDataType(DataInfo.MyMessage.DataType.TeacherType) .setTeacher(DataInfo.Teacher.newBuilder(). setName("teacher").setAddress("chengdu").build()). build(); &#125;else &#123; myMessage = DataInfo.MyMessage.newBuilder(). setDataType(DataInfo.MyMessage.DataType.DogType) .setDog(DataInfo.Dog.newBuilder(). setName("dog").setType("erha").build()). build(); &#125; ctx.channel().writeAndFlush(myMessage); &#125;&#125;]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>protobuf集成netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins自动化构建部署到多个服务器]]></title>
    <url>%2F2019%2F05%2F12%2Fjenkins%E8%87%AA%E5%8A%A8%E5%8C%96%E6%9E%84%E5%BB%BA%E9%83%A8%E7%BD%B2%E5%88%B0%E5%A4%9A%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%2Fjenkins%E8%87%AA%E5%8A%A8%E5%8C%96%E6%9E%84%E5%BB%BA%E9%83%A8%E7%BD%B2%E5%88%B0%E5%A4%9A%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[jenkins下载与安装jenkins是一款持续集成的软件，最开始想用这个软件进行项目的自动化构建部署，是由实验室的项目有三个版本，本地需要一套，测试要一套，交付维护需要一套，每次修改了代码后，都需要打成war包，然后通过一些ftp工具传过去，这样一次还好，次数多了就受不了了，所以就花了一天，学习了下jenkins，以后就方便多了。 引言与建议如果要先集群服务器部署，不免每台有些配置信息不一样，比如数据库连接、rest接口、检索地址、文件服务器地址等，此时最好，将配置文件从jar包里抽取出来，放置在一个固定的目录下，且命名都相同，比如，我是使用/usr/test.properties等。然后写代码读取、或者直接Spring读取就行。 Spring读取外部文件的配置。 123456&lt;bean id="ConfigurerProperty" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="order" value="1"/&gt; &lt;property name="ignoreResourceNotFound" value="true"/&gt; &lt;property name="ignoreUnresolvablePlaceholders" value="true" /&gt; &lt;property name="location" value="file:/usr/resources.properties"/&gt; &lt;/bean&gt; 下载地址https://jenkins.io/ 安装下载安装好后，找到jenkins的war包jenkins.war，因为它是自带Jetty服务器的，所以直接命令运行就行。 1java -jar jenkins.war windows下在jenkins目录下打开命令窗口执行就好了。 也可以，把这个war包放置在一个Web容器中。 然后，就可以通过http://localhost:8080访问。 按提示，注册账号，按提示登陆，默认安装插件就OK。 配置 点击左侧的系统管理 主要对系统设置、全局工具配置、插件管理来进行配置 插件管理 点击可选插件，搜索安装： Publish Over SSH用于连接远程服务器。 Deploy to container插件用于把打包的应用发布到远程服务器。 全局工具设置 不要使用自动安装 JDK配置，JAVA_HOME就是自己的jdk目录。 Maven配置，MAVEN_HOME就是自己的Maven目录。 git，默认就行。 系统设置，设置远程服务器 可设置多个节点，点击add。 构建与部署配置好后，就可以进行新建任务了。 新建任务 配置 仓库配置 若仓库地址有错，会报错。 触发器构建 选择了定时构建和轮询SCM，就可以实现我们的自动化构建了。 一、定时构建：不管SVN或Git中数据有无变化，均执行定时化的构建任务 ； 二、轮询SCM：只要SVN或Git中数据有更新，则执行构建任务； 三、构建语法说明： 首先格式为： *（五个星）； 第一个表示分钟，取值0~59 第二个表示小时，取值0~23 第三个表示一个月的第几天，取值1~31 第四个表示第几月，取值1~12 第五个*表示一周中的第几天，取值0~7，其中0和7代表的都是周日 使用举例： 每隔10分钟构建一次：H/5 每隔1小时构建一次： H H/1 每月30号构建一次： H H 30 每两小时一次，每个工作日上午9点到下午5点(也许是上午10:38，下午12:38，下午2:38，下午4:38) H H(9-16)/2 * 1-5 四、定时构建和轮询SCM使用互不冲突，具体如何组合，需要根据项目情况合理配置； 部署 在构建后操作处添加要部署的远程服务器，我这里添加了两个节点。 Name : 在系统设置里配置的服务器，直接选择就行。 Source files：项目构建后的目录 Remove prefix ： 去前缀 Remote directoty ： 发布的目录，这个目录是接着你在远程服务器中配置的目录 Exec command ： 发布完执行的命令，一般会写个重启Tomcat的脚本，这里是直接执行这个脚本 构建部署 点击立即构建测试，点击控制台输出，可以查看日志输出。 以下为三台服务器都部署成功，且成功执行脚本。 restart.sh脚本： 12345678910111213141516171819202122232425#! /bin/bashexport JAVA_HOME=/usr/jdk1.8.0_191 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jartomcat_home=/home/admin/apache-tomcat-8.5.35SHUTDOWN=$tomcat_home/bin/shutdown.shSTARTTOMCAT=$tomcat_home/bin/startup.shecho "关闭$tomcat_home"$SHUTDOWN#杀死tomcat进程ps -ef|grep tomcat|grep -v grep|awk '&#123;print $2&#125;'|xargs kill -9#删除日志文件，如果你不先删除可以不要下面一行rm $tomcat_home/logs/* -rf#删除tomcat的临时目录rm $tomcat_home/work/* -rfsleep 5echo "启动$tomcat_home"$STARTTOMCAT#看启动日志#tail -f $tomcat_home/logs/catalina.out]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度分析ConcurrentLinkedQueue原理]]></title>
    <url>%2F2019%2F04%2F23%2F%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90ConcurrentLinkedQueue%E5%8E%9F%E7%90%86%2F%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90ConcurrentLinkedQueue%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[引言在JUC包中提供了许多线程安全的并发容器，使用这些容器，无需我们再去手动的设置锁，就能实现线程安全。在这些并发容器中，又分为阻塞与非阻塞（简单来说线程进行元素的放置与取出操作时，可以将线程阻塞）。ConcurrentLinkedQueue就是以非阻塞方式来实现的，这个并发容器类通过循环CAS操作来实现线程安全队列，它不会导致当前线程被暂停，因此也避免了线程上下文切换的开销。 阻塞容器可以通过锁来实现线程安全的，而非阻塞则通过CAS来实现。 CAS的原理CAS(Compare and Swap)：比较并交换。它是对一种处理器指令的称呼，在Java中，CAS通过调用JNI的代码实现的。CAS操作顾名思义，先比较再交换（或者说更新），通过一段伪代码来看： 1234567891011121314for(;;)&#123; ... public boolean cas(V a, V b ,V c)&#123; //a为想要修改的变量，b为当前线程调用CAS操作时a的值（即a的旧值），c为新值 if(b == a)&#123; //检查其他线程是否已经对a进行了修改 b = c; //更新 return true; //更新成功 &#125; return false; //更新操作 &#125; ...&#125; 当某个线程要执行CAS操作时，如果想要修改的值与调用CAS操作的线程所提供的旧值相同时，说明其他线程并未对其进行修改，则这个线程可以对其进行修改。而其他的线程则更新失败，然后继续进行尝试，直至成功。 ConcurrentLinkedQueue原理简单来说，ConcurrentLinkedQueue就相当于LinkedList的线程安全版，即是一个单向链表，在其内部有个私有静态类Node&lt;E&gt;，通过这个类，将元素封装在其中，并保存下一个节点（next）,Node&lt;E&gt;内部通过一个UNSAFE类来完成CAS操作。 Node类的主要代码： 123456789101112131415161718192021222324252627282930313233343536373839404142private static class Node&lt;E&gt; &#123; volatile E item; // volatile声明 volatile Node&lt;E&gt; next; // volatile声明 // 构造方法 在地址itemOffset处， 值替换为item Node(E item) &#123; UNSAFE.putObject(this, itemOffset, item); &#125; // CAS操作：比较并交换，原子的更改itemOffset地址的变量。如果变量的值为cmp，并成功替换为val 返回true boolean casItem(E cmp, E val) &#123; return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); &#125; // 将nextOffset地址的值替换为x void lazySetNext(Node&lt;E&gt; val) &#123; UNSAFE.putOrderedObject(this, nextOffset, val); &#125; // CAS操作：比较并交换，原子的更改nextOffset地址的变量。如果变量的值为cmp，并成功替换为val 返回true boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); &#125; // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long itemOffset; private static final long nextOffset; /** * 静态代码块，获取itemOffset和nextOffset */ static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class k = Node.class; itemOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("item")); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("next")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; &#125; tail节点与head节点的CAS操作： 12345678 // CAS操作：比较并交换，原子的更改tailOffset地址的变量。如果变量的值为cmp，并成功替换为val 返回trueprivate boolean casTail(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, tailOffset, cmp, val); &#125; // CAS操作：比较并交换，原子的更改headOffset地址的变量。如果变量的值为cmp，并成功替换为val 返回true private boolean casHead(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, headOffset, cmp, val); &#125; 用到的UNSAFE类方法： 1234567891011121314// 获取f在堆内存的偏移地址public native long objectFieldOffset(Field f);// 获取静态f在堆内存的偏移地址public native long staticFieldOffset(Field f);// 原子的更改offset地址的变量。如果变量的值为expected，并成功替换为x 返回true CAS操作public final native boolean compareAndSwapObject(Object o, long offset, Object expected,Object x);// 将offset地址的值替换为x，并且通知其他线程。因为有Volatile，与putObject类似public native void putObjectVolatile(Object o, long offset, Object x);// 获取地址为offset 的值public native Object getObjectVolatile(Object o, long offset) 在ConcurrentLinkedQueue中维护了两个变量tail和head，并且在创建ConcurrentLinkedQueue实例时，创建一个空节点，并将其赋值于tail和head。 1234567private transient volatile Node&lt;E&gt; head;private transient volatile Node&lt;E&gt; tail;public ConcurrentLinkedQueue() &#123; head = tail = new Node&lt;E&gt;(null);&#125; 入队列(add)入队列就是将新创建的Node节点添加到队列尾部，它的添加过程如下（图片来自www.ifeve.com）。 第一步，将元素1节点添加到head节点后面，即head节点的next节点为元素1，因为初始化ConcurrentLinkedQueue时，tail节点和head节点是同一个节点。 第二步，将元素2节点设置为元素1节点的next节点，将tail节点设置为元素2节点。 ~~ 1234567891011121314151617181920212223242526272829303132public boolean offer(E e) &#123; checkNotNull(e); //创建一个新的入队节点 final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); //创建一个指向尾节点的引用t，相当于一个中间变量，用于和p比较的 //p表示尾节点 //死循环，一直进行CAS操作的尝试，值至成功，返回true for (Node&lt;E&gt; t = tail, p = t;;) &#123; //获取p节点的下一节点 Node&lt;E&gt; q = p.next; //如果q为空，则p为尾节点 if (q == null) &#123; //p为尾节点，将新节点添加到p节点之后，CAS操作：比较并交换，如果nextOffset的值等于 null的话，说明别的线程还未对其进行修改，则此次CAS操作成功，则跳出循环 if (p.casNext(null, newNode)) &#123; //如果p不等于t，相当于tail不是尾节点，则通过CAS操作将新节点设置为尾节点，如果失败 了，则说明其他线程已将其进行了修改 if (p != t) //如果tailOffset的值为t，则尝试将新节点设置为尾节点 casTail(t, newNode); return true; &#125; &#125; //如果，p等于q，说明p和q都为空，即ConcurrentLinkedQueue刚刚初始化 else if (p == q) p = (t != (t = tail)) ? t : head; //p有next节点，表示p的next节点是尾节点，则需要重新更新p后将它指向next节点 else p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125; &#125; 首先获取尾节点。 然后判断尾节点的next节点是否为空。 如果为空，就尝试使用CAS操作添加节点 如果成功，返回true。 如果失败，表示其他线程已经添加了新节点，则需要重新获取尾节点。 如果不为空，表明其他线程已经添加了新节点进来。 刚初始化。 更新尾节点。 通过分析可知，每次入队时，都会先定位尾节点，定位成功后，通过p.casNext(null, newNode)这个CAS操作来进行入队操作，因为p和t不是每次都相同，即不是每次入队都会重新设置tail节点，这样减少了casTail(t, newNode)这个设置尾节点的CAS操作的数量，减少了开销，提高了入队的效率。 出队列（poll）出队列就是从队列中弹出head节点，将其引用清空，并返回节点中的元素。 出队列同入队列一样，不是每次进行出队列操作，都会更新head节点，只有当head节点的元素为空时，才会进行更新head节点的操作。 123456789101112131415161718192021222324252627282930public E poll() &#123; //死循环，进行出队列操作，直到成功，才返回，要么返回一个item，要么返回null。 restartFromHead: for (;;) &#123; //创建一个指向头节点的引用h，相当于一个中间变量，用于和p比较的 //p表示头节点 for (Node&lt;E&gt; h = head, p = h, q;;) &#123; //item为头节点的元素 E item = p.item;//如果p节点元素不为空，则使用CAS操作：如果当前线程的item地址的值等于itemOffset地址的 值，就将p节点的元素值设置为空，并返回item if (item != null &amp;&amp; p.casItem(item, null)) &#123; //如果p不等于h，即head不是头节点，将p的next节点设置为头节点 if (p != h) updateHead(h, ((q = p.next) != null) ? q : p); return item; &#125; //表明已是最后一个节点，跳出循环 else if ((q = p.next) == null) &#123; updateHead(h, p); return null; &#125; //p与q相同，q和p都为空，跳到外层循环，重新开始 else if (p == q) continue restartFromHead; //p有next节点，设置p指向它的next节点 else p = q; &#125; &#125;&#125; 首先获取头节点的元素。 然后判断头节点元素是否为空。 如果为空，表示另外一个线程已经进行了一次出队操作将该节点的元素取走。 如果非空，则使用CAS操作将头节点的引用设置成null。 如果CAS成功，则直接返回头节点的元素。 如果不成功，表示另外一个线程已经进行了一次出队操作更新了head节点，导致元素发生了变化，需要重新获取头节点。]]></content>
      <categories>
        <category>Java并发</category>
      </categories>
      <tags>
        <tag>并发容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下搭建shdowsocks服务端]]></title>
    <url>%2F2019%2F04%2F18%2Flinux%E4%B8%8B%E6%90%AD%E5%BB%BAshdowsocks%E6%9C%8D%E5%8A%A1%E7%AB%AF%2Flinux%E4%B8%8B%E6%90%AD%E5%BB%BAshdowsocks%E6%9C%8D%E5%8A%A1%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[作为中国的IT从业人员，有时需要翻越长城，浏览一下国外的网站，这时就可以购买一台位于国外节点的云服务器搭建shdowsocks服务端，然后自己的多终端设备都可以连接这个服务端，跨过长城。 连接云服务器 首先，购买一台云服务器，任意平台的云服务器都可以，AWS、阿里云、腾讯云皆可，不过国内的相对便宜些，有些会有学生优惠，这里以阿里云为例。 按需购买好云服务器后，会有一个密钥对文件，阿里云可以创建实例时绑定密钥，也可以创建好后再绑定。 然后，使用这个.pem文件连接云服务器，此处以Xshell连接为例。 用户名默认为root，密码选择Public Key导入你的密钥文件，即可连接。 安装Shadowsocks服务端安装pip使用包管理工具pip安装python版本的Shadowsocks，先安装pip 12[root@iZt4n2suiu81ljhwj0y8ppZ ~]# curl "https://bootstrap.pypa.io/get-pip.py" -o "get-pip.py"[root@iZt4n2suiu81ljhwj0y8ppZ ~]# python get-pip.py 安装配置Shadowsocks服务端安装Shadowsocks，此版本的 shadowsocks 已发布到pip上，直接使用pip安装。 12[root@iZt4n2suiu81ljhwj0y8ppZ ~]# pip install --upgrade pip[root@iZt4n2suiu81ljhwj0y8ppZ ~]# pip install shadowsocks 安装完成后，再创建一个shadowsocks.json文件，通过读取这个文件的配置来启动，就不用每次启动都输入所有的配置信息。 多端口配置 123456789101112[root@iZt4n2suiu81ljhwj0y8ppZ ~]# vim /etc/shadowsocks.json&#123; "server": "0.0.0.0", "local_address": "127.0.0.1", "local_port": 1080, "port_password": &#123; "123456": "填写密码", "123457": "填写密码" &#125;, "timeout": 600, "method": "rc4-md5"&#125; 其中server为你的云服务器的私有地址、私有地址、私有地址(说三遍) method为加密方法，有多种选择，推荐使用rc4-md5，这种方式，加密开销小些。 单端口配置 12345678910&#123; "server": "0.0.0.0", "server_port": 12345, "local_address": "127.0.0.1", "local_port": 1080, "password": "cowbeer", "timeout": 300, "method": "rc4-md5", "fast_open": false&#125; 配置自启动编辑shadowsocks服务的启动脚本文件，内容如下： 12345678910[root@iZt4n2suiu81ljhwj0y8ppZ ~]# vim /etc/systemd/system/shadowsocks.service[Unit]Description=Shadowsocks[Service]TimeoutStartSec=0ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json[Install]WantedBy=multi-user.target 执行以下命令启动 shadowsocks服务： 12[root@iZt4n2suiu81ljhwj0y8ppZ ~]# systemctl enable shadowsocks[root@iZt4n2suiu81ljhwj0y8ppZ ~]# systemctl start shadowsocks 检查 shadowsocks 服务是否已成功启动，可以执行以下命令查看服务的状态： 1[root@iZt4n2suiu81ljhwj0y8ppZ ~]# systemctl status shadowsocks -l ### 检查防火墙安装无误后，若开启了防火墙，配置防火墙规则，开放你配置的端口：123[root@iZt4n2suiu81ljhwj0y8ppZ ~]# firewall-cmd --zone=public --add-port=123456/tcp --permanent[root@iZt4n2suiu81ljhwj0y8ppZ ~]# firewall-cmd --zone=public --add-port=123457/tcp --permanent[root@iZt4n2suiu81ljhwj0y8ppZ ~]# firewall-cmd --reload以下为未开启防火墙的输出结果： 云服务器配置安全组shdowsocks安装配置完后，还需要配置安全组。 安全组是一种虚拟防火墙，具备状态检测和数据包过滤功能，用于在云端划分安全域。可以通过配置安全组规则，允许或禁止安全组内的ECS实例对公网或私网的访问。 点开相应实例的左侧的网络与安全的安全组，配置安全组规则： 安全组出方向默认允许所有访问，即从安全组内ECS访问外部都是放行的。 端口范围：刚刚配置的shdowsocks的端口，1/12345表示1到12345. 授权对象：0.0.0.0/0，本机就行。 配置客户端安装配置完后，就可以用shdowsocks客户端进行连接了。 Windows版本的客户端下载地址： https://github.com/shadowsocks/shadowsocks-windows/releases 无需安装，点开后，添加一个你刚刚配置的服务端的信息，就可以使用了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>shdowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署Web应用到Tomcat根目录]]></title>
    <url>%2F2019%2F04%2F15%2F%E9%83%A8%E7%BD%B2Web%E5%BA%94%E7%94%A8%E5%88%B0Tomcat%E6%A0%B9%E7%9B%AE%E5%BD%95%2F%E9%83%A8%E7%BD%B2Web%E5%BA%94%E7%94%A8%E5%88%B0Tomcat%E6%A0%B9%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[引言Tomcat安装后，默认目录是/webapps/ROOT，我们自己的Web应用就需要以localhost:8080/test这种方式来访问，有时需要将Web应用部署到Tomcat根目录下，就可以localhost:8080这种方式访问。 配置 首先，进入Tomcat的conf文件夹 1[root@node1 conf]# cd /home/apache-tomcat-8.5.35/conf 然后，打开server.xml配置文件 1[root@node1 conf]# vi server.xml 在&lt;Host&gt;&lt;/Host&gt;区域的末尾添加 docBase中为在webapps中的Web应用的地址。 使用/pattern：从光标开始处向文件尾搜索pattern /&lt;Host 在浏览器键入Tomcat地址加端口，即可访问。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Tomcat#</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea配置jvm参数]]></title>
    <url>%2F2019%2F04%2F12%2Fidea%E9%85%8D%E7%BD%AEjvm%E5%8F%82%E6%95%B0%2Fidea%E9%85%8D%E7%BD%AEjvm%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[常用JVM配置参数]]></title>
    <url>%2F2019%2F04%2F08%2F%E5%B8%B8%E7%94%A8JVM%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%2F%E5%B8%B8%E7%94%A8JVM%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Trace跟踪参数 -verbose:gc -XX:+printGC 可以打印GC的简要信息 -XX:+PrintGCDetails 打印GC详细信息 -XX:+PrintGCTimeStamps 打印CG发生的时间戳 -Xloggc:log/gc.log 指定GC log的位置，以文件输出 帮助开发人员分析问题 -XX:+PrintHeapAtGC 每次一次GC后，都打印堆信息 -XX:+TraceClassLoading 监控类的加载 堆的分配参数 -Xmx –Xms 指定最大堆和最小堆 -Xmn 设置新生代大小 -XX:NewRatio 新生代（eden+2*s）和老年代（不包含永久区）的比值 =4 表示 新生代:老年代=1:4，即年轻代占堆的1/5 -XX:SurvivorRatio 设置两个Survivor区和eden的比 =8表示 两个Survivor :eden=2:8，即一个Survivor占年轻代的1/10 在HotSpot虚拟机中，默认Eden区与一个Survivor区比例为8：1 -XX:+HeapDumpOnOutOfMemoryError OOM时导出堆到文件 -XX:+HeapDumpPath 导出OOM的路径 1-Xmx20m -Xms5m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=d:/a.dump -XX:OnOutOfMemoryError 在OOM时，执行一个脚本 “-XX:OnOutOfMemoryError=D:/tools/jdk1.7_40/bin/printstack.bat %p“ 当程序OOM时，在D:/a.txt中将会生成线程的dump 可以在OOM时，发送邮件，甚至是重启程序 永久区分配参数 -XX:PermSize -XX:MaxPermSize 设置永久区的初始空间和最大空间 栈大小分配 -Xss -Xss256k 通常只有几百K 决定了函数调用的深度 每个线程都有独立的栈空间 局部变量、参数 分配在栈上]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>JVM参数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下Apache服务器的安装与配置]]></title>
    <url>%2F2019%2F04%2F07%2FLinux%E4%B8%8BApache%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2FLinux%E4%B8%8BApache%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装在linux中，Apache服务器叫做httpd。 准备首先下载httpd与httpd的依赖软件。 Apache HTTP Server http://httpd.apache.org/download.cgi#apache24 APR和APR-Util http://apr.apache.org/download.cgi PCRE https://sourceforge.net/projects/pcre/files/pcre/ 没有gcc/gcc-c++的话，先安装gcc/gcc-c++ 1[root@localhost /]# yum install gcc-c++ 基于centos，其余系统相应变化。 先确定服务器是否联网，若安装过程出现错误，可能是缺某些依赖包，谷歌百度下，会有结果的。 安装解压1234tar -zxf apr-1.6.5.tar.gztar -zxf apr-util-1.6.1.tar.gztar -zxf pcre-8.38.tar.gztar -zxf httpd-2.4.37.tar.gz 默认解压到当前目录 安装直接复制粘贴，修改成刚刚解压的相应目录。 apr的安装 1234567cd apr-1.6.5./configure --prefix=/home/apr-1.6.5makemake install apr-util的安装 1234567cd ../apr-util-1.6.1./configure --prefix=/home/apr-util --with-apr=/home/apr-1.6.5/bin/apr-1-configmakemake install pcre的安装 1234567cd ../pcre-8.38./configure --prefix=/home/pcre-8.38 --with-apr=/home/apr-1.6.5/bin/apr-1-configmakemake install httpd的安装 1234567cd ../httpd-2.4.18./configure --prefix=/home/httpd-2.4.37 --with-pcre=/home/pcre-8.38 --with-apr=/home/apr-1.6.5 --with-apr-util=/home/apr-util-1.6.1makemake install 检查 安装成功。 配置想要将httpd作为文件服务器，需要更改一些配置。 进入httpd的conf文件夹。 1/home/httpd-2.4.37/conf 打开httpd.conf配置文件。 1vi httpd.conf 更改端口号 更改主机号 更改文件目录 启动 123[root@hmaster bin]# ./apachectl start[root@hmaster bin]# ./apachectl stop[root@hmaster bin]# ./apachectl restart 检查 出现此页面，则安装成功。 问题遇到的问题： 启动时遇到的问题 1httpd: Could not open configuration file /xxx/conf/httpd.conf: No such file or directory 解决办法： 1./apachectl -f /xxx/httpd/conf/httpd.conf -k start 以httpd.conf配置文件启动。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[虚拟机字节码执行引擎]]></title>
    <url>%2F2019%2F03%2F29%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[概述将Java源文件编译成字节码之后，就可以通过Java虚拟机的核心组件——执行引擎来进行执行。现代JVM在执行Java代码的时候，通常都会将解释执行与编译执行二者结合起来进行。执行过程一般都是输入字节码，解析字节码，输出执行结果。 解释执行：由Java解释器执行，将字节码从头开始进行读取，读取到相应的指令就去执行该指令。 编译执行：不要与源代码的编译混为一谈。就是将字节码由即时编译器（Just In Time ,JIT）产生本地代码，就是相应的机器码，然后去执行。现代JVM会根据热点代码（经常调用的代码）来生成相应的本地机器码。转换为机器码，就不具有可移植性了，各个平台的机器码各不相同。 栈帧栈帧，简单来说就是——用于帮助虚拟机执行方法调用与方法执行的数据结构。它是jvm运行时数据区中的虚拟机栈中的栈元素。栈帧本身是一种数据结构，封装了方法的局部变量表、动态连接、方法的返回地址以及操作数栈。在上文中Java字节码（一）：深度分析Class类文件中，我们知道了在Class文件中每个方法的操作数栈深度以及局部变量表都已经在编译期确定了，被写入到Code属性中了。对于执行引擎来讲，活动线程中，只有虚拟机栈顶的栈帧才是有效的，称为当前栈帧，这个栈帧所关联的方法称为当前方法。执行引用所运行的所有字节码指令都只针对当前栈帧进行操作。 局部变量表局部变量表是用以存储方法参数、方法内部定义的局部变量以及代表当前对象的this。Slot是虚拟机为局部变量分配内存所使用的最小单位。不超过32位的数据类型占1个Slot，64位的数据类型则使用两个Slot，在编译期，就已经确定好局部变量表的所需的存储空间了。另外，并不是在方法中用到了多少了局部变量，就把这些Slot之和作为max_locals的值，原因是局部变量表中的Slot可以重用，在局部变量表中通过这个变量的偏移量可以得到这个变量的作用域，当代码执行超出一个局部变量的作用域时，这个局部变量所占的Slot就可以被其他局部变量所使用，编译器会根据变量的作用域来分配Slot给各个变量使用，然后计算出max_loacals的大小。 操作数栈操作数栈，即是一个先入后出的栈。同局部变量表一样，在编译期，Javac编译器也将所需的操作数栈的深度计算出来放到Code属性中的max_stacks中。当一个方法刚刚执行的时候，这个方法的操作数栈是空的，在方法执行的过程中，会有各种字节码指向操作数栈中写入和提取值，也就是入栈与出栈操作。例如，在做算术运算的时候就是通过操作数栈来进行的，又或者调用其它方法的时候是通过操作数栈来行参数传递的。另外，在概念模型中，两个栈帧作为虚拟机栈的元素，相互之间是完全独立的，但是大多数虚拟机的实现里都会作一些优化处理，令两个栈帧出现一部分重叠。让下栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起，这样在进行方法调用返回时就可以共用一部分数据，而无须进行额外的参数复制传递了。 动态连接每个栈帧都包含一个指向运行时常量池中该栈帧所属性方法的引用，持有这个引用是为了支持方法调用过程中的动态连接。在Class文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用，这种转化称为静态解析。另外一部分将在每一次的运行期期间转化为直接引用，这部分称为动态连接。 方法的返回地址方法的返回地址就是在栈帧中保存的一些信息，用以在当方法调用完成后，就可以会返回到调用方法处，继续执行代码，有了这个地址，就可以回到这个调用处，继续执行下面的代码。方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值(如果有的话)压入调用都栈帧的操作数栈中，调用PC计数器的值以指向方法调用指令后面的一条指令等。 方法的调用方法的调用指的是确定被调用方法的版本，即确定调用哪一个方法。 解析在程序运行之前，就确定好执行哪个方法，即在在编译期间，就可以确定下来，然后在类加载的解析阶段，就将常量池中，与此方法有关的符号引用转换为直接引用。因此，想要在类加载阶段就完成解析工作，首先这个方法是可以确定唯一的版本的，比如静态方法、私有方法、构造方法、父类方法，称为非虚方法，与之相对应的字节码助记符： invokestatic:调用静态方法 invokespecial：调用构造方法、私有方法和父类方法 解析一定是一个静态过程，在编译期间就可以确定其要调用哪个方法，在类加载的解析阶段，就可以将涉及的符号引用，即invokestatic和invokespecial指令的参数在常量池中相对应的符号引用转换为直接引用。 分派静态分派静态分派，简单来说，可以理解为在编译期间根据静态类型确定方法执行版本的分派过程。静态分派与方法的重载是密切相关的。 静态类型： Grandpa g1 = new Father();以上代码，g1的静态类型是Grandpa，而g1的实际类型（真正指向的类型）是Father。 12345678910111213141516171819202122232425262728293031323334public class MyTest6 &#123; public void test(Grandpa grandpa)&#123; System.out.println("grandpa"); &#125; public void test(Father father)&#123; System.out.println("father"); //方法的重载，是一种静态行为，在编译期就可以确定 &#125; public void test(Son son)&#123; System.out.println("son"); &#125; public void test(int a)&#123; System.out.println("son"); &#125; public static void main(String[] args) &#123; MyTest6 myTest6 = new MyTest6(); Grandpa g1 = new Father(); Grandpa g2 = new Son(); Father father = new Father(); myTest6.test(father); myTest6.test(g1); myTest6.test(g2); &#125;&#125;class Grandpa&#123;&#125;class Father extends Grandpa&#123;&#125;class Son extends Father&#123;&#125; 输出结果： 123fathergrandpagrandpa 在方法接收者已经确定的前提下，使用哪个重载版本，取决于传入的参数的数量和数据类型。编译器在重载时通过参数的静态类型来确定重载方法的版本。并且静态类型是在编译期可知的，意思是对于重载来说，在编译阶段，就已经确定了要执行的重载方法的版本。 常量池中生成对应重载方法的符号引用（没用到的重载方法版本是不会在常量池中生成符号引用的）。 对于没有显示静态类型的字面量来说，它的静态类型只能通过语言上的规则来理解和推断。 静态分派与解析的区别解析与静态分派不是一个层面上的东西，它们是在不同的层次上去筛选、确定方法的过程。解析针对的是，在类加载的解析阶段，能够确定的唯一方法，针对的是invokestatic和invokespecial。而静态分派则是，在编译阶段方法的接收者确定的情况下，根据参数的静态类型确定重载方法的版本。 动态分派动态分派，简单来说，可以理解为在运行期间根据实际类型确定方法执行版本的分派过程。针对的是方法的重写。 123456789101112131415161718192021222324252627282930313233343536public class MyTest7 &#123; public static void main(String[] args) &#123; Fruit apple = new Apple(); Fruit orange = new Orange(); apple.test(); orange.test(); apple = new Orange(); apple.test(); &#125;&#125;class Fruit&#123; public void test()&#123; System.out.println("Fruit"); &#125;&#125;class Apple extends Fruit&#123; @Override public void test() &#123; System.out.println("Apple"); &#125;&#125;class Orange extends Fruit&#123; @Override public void test() &#123; System.out.println("Orange"); &#125;&#125; 输出结果： 123AppleOrangeOrange 输出结果显示，方法的确定是通过变量的实际类型来确定的。 来看看这个方法的Code属性。 可以看出，在编译阶段，生成的字节码文件中invokevirtual指令的参数都是父类Fruit的test方法，但实际在运行时，这几个相同的指令最终执行的目标方法并不相同，这是依赖于invokevirtual的多态查找过程。 动态分派的多态查找过程： 1. 找到操作数栈顶的第一个元素所指向的对象的实际类型。 2. 如果在这个类型中找到与常量池中符号引用相同的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用。 3. 否则，按照继承关系从下往上依次对这个对象类型的父类进行搜索和验证。 invokevirtual指令执行的第一步就是在运行期确定方法接收者的实际类型，所以这几次调用invokevirtual指令就将常量池中的类符号引用解析到了不同的直接引用上，这个过程就是Java语言中方法重写的本质。这种在运行期根据实际类型确定方法执行版本的分派过程就叫动态分派。 示例分析12345678910111213141516171819202122232425262728public class MyTest8 &#123; public static void main(String[] args) &#123; Animal animal = new Animal(); Animal cat = new Cat(); animal.test(1); cat.test("1"); &#125;&#125;class Animal&#123; public void test(int a)&#123; System.out.println("animal int"); &#125; public void test(String a)&#123; System.out.println("animal str"); &#125;&#125;class Cat extends Animal&#123; @Override public void test(int a)&#123; System.out.println("cat int"); &#125; @Override public void test(String a)&#123; System.out.println("cat str"); &#125;&#125; 输出结果： 12animal intcat str 结果不重要，看看Code属性： 在编译阶段，编译器的选择过程，也就是静态分派的过程： 这时候的判断依据有两点：静态类型是Cat还是Animal，以及传入的参数是int还是String，这次选择产生了两条invokevirtual指令，这两条指令分别指向常量池中的Animal.test(int)以及Animal.test(String)。 然后到了运行阶段，也就是动态分派过程： 执行到了invokevitual指令，由于在编译阶段，已经确定好方法的参数，此时就只需确定方法的接收者的实际类型。根据invokevirtual的多态查找过程，找出正确的重写方法去执行。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>虚拟机字节码执行引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java字节码（一）：深度分析Class类文件]]></title>
    <url>%2F2019%2F03%2F27%2FJava%E5%AD%97%E8%8A%82%E7%A0%81%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90Class%E7%B1%BB%E6%96%87%E4%BB%B6%2FJava%E5%AD%97%E8%8A%82%E7%A0%81%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%88%86%E6%9E%90Class%E7%B1%BB%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[引言我们知道，java是一个跟平台无关性的编程语言，而平台无关性的基础就是虚拟机与字节码存储格式。Java虚拟机不和包括java语言在内的任何语言绑定，它只认Class文件（kotlin、scala等皆可在jvm上运行）。Class文件中包含了一个Java程序的指令集和符号集以及其他信息，编译器严格按照规范来将Java程序编译为字节码。在这儿，我们分析下Class文件的数据结构。 Class类文件结构Class文件是以8位字节为基础的二进制流文件，其中没有间隔，在文件中只保留了必要的数据，节省了大量的空间。在Class字节码中有两种数据类型： 字节数据直接量：这是基本的数据类型。共细分为u1、u2、u4、u8四种，分别代表连续的1个字节、4个字节、8个字节组成的整体数据。 表（数组）：表是由多个基本数据或其他表，按照既定顺序组成的大的数据集合。表是有结构的，它的结构体现在：组成表的成分所在的位置和顺序都是已经严格定义好的。 如下图所示，Class文件中字节码按一下顺序进行排列。 我们通过最简单的一个程序，来示例讲解Class文件结构。 1234567891011121314public class MyTest1 &#123; private int a = 1; public int getA() &#123; return a; &#125; public void setA(int a) &#123; this.a = a; &#125;&#125; 使用16进制工具(winHex)打开MyTest1.class文件，16进制字节码中，一个数字或字母占4位，两个数字或字母代表一个字节。 使用javap -verbose命令分析一个字节码文件时，将会分析该字节码文件的魔数、版本号、常量池、类信息、类的构造方法、类中的构造方法、类中的方法信息、类变量与成员变量等信息。 魔数(4个字节)所有的.class字节码文件的前4个字节都是魔数，魔数值是一固定值：0xCAFEBABE。 是用以Java虚拟机确定class文件的标志。很多文件格式都采用了魔数来进行文件的身份标识，比如jpg。选择在文件内容头部使用魔数而不用扩展名来进行文件的身份标识，主要是考虑了安全问题，因为扩展名易被修改。而魔数则可以由文件格式的制定者随意的指定，只要选择的魔数没有被广泛采用且不与其他魔数重复引起混淆就行。 版本号（2+2个字节）.魔数之后的4个字节为版本信息，前两个字节表示minor version（次版本号），后两个字节表示major version（主版本号）。这里00 00 00 34，换算成十进制，表示次版本号为0，主版本号52。表示java版本1.8.0，1.8表示主版本号，0表示次版本号。可以使用java -version查看。JDK是向下兼容的，高版本的JDK能运行低于此版本的Class文件，低版本的JDK无法运行高于它本身的Class文件，即使文件格式未出错，虚拟机也拒绝执行高于其版本的Class文件。若进行运行，会报错java.lang.UnsupportedClassVersionError。 常量池（2+n个字节）常量池（constant pool）：紧接着主版本号之后的就是常量池入口。一个Java类中定义的很多信息都是由常量池来维护和描述的，可以将常量池看作是Class文件的资源仓库，比如说Java类中定义的方法与变量信息，都是存储在常量池中。 常量池中主要存储两类常量：字面量和符号引用。 字面量如文本字符串，Java中声明为final的常量值等。 符号引用如类和接口的全局限定名，字段的名称和描述符，方法的名称和描述符。 常量池的总体结构Java类所对应的常量池主要由常量池与常量池数组（常量表）这两部分共同构成。 常量池数量紧跟在主版本号后面，占据2个字节 常量池数组则紧跟在常量池数量之后。 常量池数组与一般的数组不同的是，常量池数组中不同的元素的类型、结构都是不同的，长度当然也就不同，这些元素是被称之为表的数据结构；但是，每一种元素的第一个数据都是一个u1类型，该字节是个标志位，占据一个字节。JVM在解析常量池时，会根据这个u1类型来获取元素的具体类型。 值得注意的是，常量池数组中元素的个数 = 常量池数量 - 1 （其中0位暂时不使用），根本原因在于，索引0也是一个常量（保留常量），只不过它不位于常量表中，这个常量就对应null值；所以，常量池的索引从1而非0开始。 常量池中的描述信息 在JVM规范中，每个变量/字段都有描述信息，描述信息主要的作用是描述字段的数据类型、方法的参数列表（包括数量、类型、顺序）与返回值。根据描述符规则，基本数据类型和代表无返回值的void类型都用一个大写字符来表示，对象类型则使用字符L加对象的全限定名称来表示，为了压缩字节码文件的体积，对于基本数据类型，JVM都只使用一个大写字母来表示，如：B - byte, C - char ,D - double , F - float, I - long , s - short,Z - boolean ,V - void,L - 对象类型，如Ljava/lang/String; 对于数组类型来说，每一个维度都使用一个[来表示，如int[]被记录为[I,String,String[][][]被记录为[[Ljava/lang/String; 用描述符描述方法时，按照先参数列表，后返回值的顺序来描述。参数列表按照参数的严格顺序放在一组()之内，如方法:String test(int a,String b)的描述为：（I，Ljava/lang/String）Ljava/lang/String; 示例代码的常量池​ 常量池数量： 第9、10个字节代表着常量池数量00 18，即24-1=23。 常量池数组： 第11个字节是0A（tag值）= 10 ，为CONSTANT_Meothdref_info，这个类型有两个index值，占4个字节00 04 00 14，即为常量池中第4个元素，和第20个元素。 java/lang/Object.”“:()V 表示无参数列表的返回值为void的方法，即虚拟机创建的构造方法。 第16个字节为09 = 9 ，为CONSTANT_Fieldref_info，后四个字节为两个索引00 03 00 15即第3个元素，第21个元素。 bytecode/MyTest1.a:I表示MyTest1类下的a属性的值为int类型 第21个字节为07，为CONSTANT_Class_info，后2个字节为指向全限定名常量项的索引，指向22 bytecode/MyTest1 表示此类的全限定名 第24字节为07，00 17指向#23。 java/lang/Object表示父类的全限定名 第27字节为01，为CONSTANT_utf8_info，后2位字节为UTF-8编码的字符串长度length 00 01，表示后面有一个字节来表示这个字符，即为61 = a 后面相同的类型，就简写了。 第31字节为01，00 01，字符串为49 = I 第35字节为01，00 06，字符串3C 69 6E 69 74 3E，表示为&lt;init&gt; 第43字节为01 ，00 03，28 29 56，表示为()V 第50字节为01，00 04，43 6F 64 65，表示为Code 第57字节为01，00 0F，表示为LineNumberTable 第75字节01 ，00 12，表示为LocalVariableTable 第95字节01， 00 04 ，this 第83字节01，00 12，Lbytecode/MyTest1; 第109字节01，00 04，getA 第131字节01，00 03，()I 第136字节01，00 04，setA 第143字节01， 00 04，(I)V 第151字节01，00 01，SourceFile 第163字节01，00 0C，MyTest1.java 第179字节0C,为CONSTANT_NameAndType_info，后四个字节指向方法名称#7；方法描述#8 ““:()V 第184字节0C,为CONSTANT_NameAndType_info,后四个字节指向字段名称#5；字段描述#6 a:I 第189字节01，00 10，bytecode/MyTest1 第207字节01，00 10，java/lang/Object 类的访问权限（2个字节）接下来是类的访问权限access_flag，第227、228字节00 21：是0x0020和0x0001的并集，表示ACC_PUBLIC与ACC_SUPER。 类名（2个字节）第229、230字节00 03为类名，是一个引用值，表示常量池中第三个常量。当前类的全限定名。 父类名（2个字节）第231、232字节00 04为父类名，是一个引用值，表示常量池中第四个常量。当前类的父类全限定名。 接口（2+n个字节）第233、234字节00 00为接口数，接口数为0，后面的接口名就不会出现了。 域（2+n个字节）域的个数第235、236字节00 01为成员变量数，为1个。 字段表集合字段表用于描述类和接口中声明的变量。这里的字段包含了类级别的变量以及实例变量，但是不包括方法内部声明的局部变量，下图为字段表的结构。 本例中只有一个字段。 第237、238字节00 02为这个成员变量的权限访问符，表示privat。 第239、240字节00 05为这个成员变量的名称描述符，指向常量池中的#5 =a。 第241、242字节00 06为这个成员变量的类型描述符，指向常量池中的#6 =I。 第243、244字节00 00为附加属性个数，为0，则附加属性表就不会出现。附加属性是有些编译器在编译阶段添加的值。 方法（2+n个字节）方法个数第245、246字节00 03为方法数，共3个方法。 方法表集合方法表描述了一个方法的信息。 属性表集合描述了这个方法的相关属性，执行码、异常表等，JVM预定义了部分属性，但是编译器自己也可以实现自己的属性写入class文件里，供运行时使用。 不用的属性通过attribute_name_index来区分。 NO.1 第247、248字节00 01为权限访问符，表示public。 第249、250字节00 07为这个方法的名称描述符，指向常量池中的#7 = &lt;init&gt; 第251、252字节00 08为这个方法的类型描述符，指向常量池中的#8 = ()V 第253、254字节00 01为附加属性个数。这些属性用以描述方法，由Java虚拟机根据方法的执行代码编译时计算出来的。 属性信息attribute_info: Code attribute的作用是保存改方法的结构，如下图。 attribute_length表示attribute所包含的字节数，不包含attribute_name_index和attribute_length字段。 max_stack表示这个方法运行的任何时刻所能达到的操作数栈的最大深度。 max_locals表示方法执行期间创建的局部变量的数目，包含用来表示传入的参数的局部变量。 code_length表示该方法所包含的字节码的字节数以及具体的指令码。 具体字节码即是该方法被调用时，虚拟机所执行的字节码。 exception_table，这里存放的是处理异常的信息。 每个exception_table表现由start_pc，end_pc，hander_pc，catch_type组成。 第255、256字节00 09为属性值的索引，#9 为Code，表示执行代码。 第257、258、259、260字节00 00 00 38为属性长度，为56字节。 第261、262字节00 02为操作数栈的最大深度，栈深度为2。 第263、264字节00 01为局部变量个数。 第265、266、267、268字节00 00 00 0A为这个方法包含的字节数与字节码，一共占10个字节，代表这个方法真正执行的内容（也就是助记符，在字节码中只是一些16进制的符号，转换为助记符，帮助我们记忆）。 第269字节2A，对应助记符aload_0，从局部变量表中位于0slot中的变量推到操作数栈中去。 对应助记符invokespecial，调用父类的方法。 第271、272字节00 01代表这个助记符的参数 ，指向常量池#1，java/lang/Object.&quot;&lt;init&gt;&quot;:()V，即代表调用Object类的这个方法，即父类的构造方法。 第273字节2A，对应助记符aload_0。 第274字节04 ，对应助记符iconst_1，将int类型的数1推送到操作数栈顶。 第275字节B5 ，对应助记符putfield。 第276、277字节00 02代表这个助记符的参数，指向常量池#2， bytecode/MyTest1.a:I，也就是说将刚刚推到操作数栈顶的1赋予MyTest1中的a。 第278字节B1，对应助记符return，返回void。 第279、280字节00 00，异常表长度为0，异常表就不会出现了。 第281、282字节00 02，表示附加属性个数。 首先是LineNumTable，行号信息，通过这个信息，可以确定，代码的所在的行数。 第283、284字节00 0A，代表附加属性索引，指向常量池#10，LineNumberTable 第285、286、287、288字节00 00 00 0A，代表这个附加属性的长度。 第289、290字节00 02，代表有两个映射。 第291、292字节00 00， 第293、294字节00 0F，表示code数组中偏移量为0的，映射到第10行，在第10行，编译器生成了一个构造方法。 第295、296字节00 04， 第297、298字节00 11，表示code数组中偏移量为4的，映射到第17行， 然后是LocalVariableTable，局部变量表。 第299、300字节00 0B，代表附加属性索引，指向常量池#11，LocalVariableTable 第301、302、303、304字节00 00 00 0C代表这个附加属性的长度。 第305、306字节00 01 ，代表只有一个变量。 第307、308字节00 00，代表局部变量从0开始。 第309、310字节00 0A，代表局部变量长度。 11和12决定了局部变量的作用范围是从哪一行到哪一行。 第311字节00，代表局部变量索引。 第312字节0C，代表常量池中的#10，this，代表当前对象。 第313、314字节00 0D，表示词局部变量的描述，代表常量池中的#13， Lbytecode/MyTest1; 第315、316字节00 00，做校验检查的。 在Java中，每个方法都可以访问this，对于非静态方法来说，至少有一个局部变量传入方法，即this。 ​ NO.2 第317、318字节00 01为权限访问符，表示public。 第319、320字节00 0E为这个方法的名称描述符，指向常量池中的#14 = getA。 第321、322字节00 0F为这个方法的类型描述符，指向常量池中的#15 =()I。 第323、324字节00 01为附加属性个数。这些属性用以描述方法，由Java虚拟机根据方法的执行代码编译时计算出来的。 属性信息attribute_info: 第325、326字节00 09为属性值的索引，#9 为Code，表示执行代码 第327、328、329、330字节00 00 00 2F为属性长度 第331、332字节00 01为操作数栈的最大深度 第333、334字节00 01为局部变量表最大长度 第335、336、337、338字节00 00 00 05为这个方法包含的字节数与字节码，一共占5个字节，代表这个方法真正执行的内容（助记符，在字节码中只是一些16进制的符号，转换为助记符，帮助我们记忆 第339字节2A，对应助记符aload_0， 第340字节B4，对应助记符getfiled，调用父类的方法 第341、342字节00 02代表这个助记符的参数 ，指向常量池#2， // bytecode/MyTest1.a:I表示从对象中获取字段 第343字节AC，对应助记符ireturn，表示返回一个int 第344、345字节00 00，异常表长度为0，异常表就不会出现了 第346、347字节00 02，表示附加属性个数: 首先是LineNumTable，行号信息 第348、349字节00 0A，代表附加属性索引，指向常量池#10，LineNumberTable 第350、351、352、353字节00 00 00 06，代表这个附加属性的长度 第353、354字节00 01，代表有1个映射 第355、356字节00 00， 第357、358字节14 00， 表示code数组中偏移量为0的，映射到第20行，在第20行，对应return a； 然后是LocalVariableTable，局部变量表 第359、360字节00 0B，代表附加属性索引，指向常量池#11，LocalVariableTable 第361、362、363、364字节00 00 00 0C代表这个附加属性的长度 第365、366字节00 01 ，代表只有一个变量 第367、368字节00 00，代表局部变量从0开始 第369、370字节00 05，代表局部变量长度 第371字节00，代表局部变量索引 第372字节0C，代表常量池中的#10，this，代表当前对象 第373、374字节00 0D，表示词局部变量的描述，代表常量池中的#13， Lbytecode/MyTest1; 第376、377字节00 00，做校验检查的 NO.3第三个方法就不再叙述了，与第二个方法差不多。 从上文看出，当一个Java程序中没有构造方法时，编译器会生成一个&lt;init&gt;方法，即构造方法。且非静态成员变量赋值是在构造方法中完成的。若有多个构造方法，每个构造方法都会完成非静态成员变量赋值。 字节属性 第456、457字节00 01，只有一个属性。 第458、459字节00 12，指向#18 ，SourceFile。 第460、461、462、463字节00 00 00 02，表示属性长度，占两个字节。 第464、465字节00 13，表示#13，MyTest1.java 。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>Java字节码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制（七）：线程上下文类加载器]]></title>
    <url>%2F2019%2F03%2F21%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%E7%BA%BF%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%E7%BA%BF%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[双亲委托机制的破坏我们知道，class文件的加载是按照双亲委托机制完成的，这个机制解决了各个类加载器的基础类的统一问题，因为上层类加载器加载的类对下层加载的类是可见的，所以这些基础类可以被Java程序所调用，但是如果这些基础类需要调用用户所写的类呢，可下层类加载器加载的类不是对上层类加载器加载的类是透明的吗？这种情况不是不可能的，比如JDBC，它位于rt.jar包下，是由启动类加载器加载，而它却需要classPath下的接口提供者（Service Provider Interface）的代码，但是启动类不可能去加载这些代码，那怎么办呢？ SPI(Service Provider Interface)：只提供了接口的声明，具体实现由厂商完成。某些SPI需要调用由厂商实现并部署在classPath下的接口实现代码。这些接口由启动类加载器去加载，但启动类加载器不认识classPath下的代码。 这时候就需要对双亲委托机制进行“破坏”了，Java设计者设计了一种叫做“线程上下文类加载器”的机制，当这些接口需要实现的代码时，就去使用这个线程上下文类加载器完成这些接口实现代码的加载。 线程上下文类加载器线程上下文类加载器contextClassLoader，其实，我们在分析Launcher类的源码时，已经遇到过了: Thread.currentThread().setContextClassLoader(this.loader); 在Launcher类的构造方法中，执行了这条语句，并将系统类加载器传进去，我们跟着去看看Thread的源码。 1private ClassLoader contextClassLoader; 内部维护了一个类加载器，也就是线程上下文类加载器。 1234if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; 在Thread的init方法中，线程继承其父线程的上下文类加载器。 1234567public void setContextClassLoader(ClassLoader cl) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; sm.checkPermission(new RuntimePermission("setContextClassLoader")); &#125; contextClassLoader = cl; &#125; 在Thread中，可以设置线程类加载器，也就是说，若如果没有通过setContextClassLoader进行设置的话，线程将继承其父线程的上下文类加载器。前面说过，在Launcher类中设置了线程上下文类加载为系统类加载器，即在Java程序中未设置线程上下文类加载器的话，线程上下文类加载器就为系统类加载器。 深入理解线程上下文类加载器线程上下文类加载器的一般使用模式1234567ClassLoader classLoader = Thread.currentThread().getContextClassLoader();try&#123; Thread.currentThread().setContextClassLoader(targetccl); doMethod();&#125;finally&#123; Thread.currentThread().setContextClassLoader(classLoader);&#125; 线程上下文类加载器的一般使用模式（获取-使用-还原） 在doMethod()里面调用了Thread.currentThread().setContextClassLoader()来获取当前线程的上下文类加载器做某些事情。 ServiceLoader类在双亲委托模型下，类加载是由下至上的，即下层的类加载器会委托上层进行加载。但是对于SPI来说。有些接口是Java核心库所提供的，而Java核心库是由启动类加载器来加载的，而这些接口的实现却是来自于不同的jar包（由各独立厂商实现），Java的启动类加载器是不会加载其他来源的jar包，这样就导致一些接口由启动类加载加载，实现由其他加载器加载，传统的双亲委托机制就会无法满足SPI的要求。而通过给当前线程设置上下文类加载器，就可以由设置的上下文类加载器来实现对于接口实现类的加载 。就比如JDBC驱动，如下图所示。 首先，在pom文件中添加了关于MySql的依赖，我们通过代码找到项目中的驱动。 123456789101112131415161718public class MyTest17 &#123; public static void main(String[] args)&#123; //通过ServiceLoader去加载驱动 ServiceLoader&lt;Driver&gt; drivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; iterator = drivers.iterator(); //打印出每个驱动以及驱动的类加载器 while (iterator.hasNext())&#123; Driver next = iterator.next(); System.out.println("driver:" + next.getClass()); System.out.println("loader:" + next.getClass().getClassLoader()); System.out.println("-------------"); &#125; //打印出当前线程上下文类加载器 System.out.println("当前线程上下文类加载器:" + Thread.currentThread().getContextClassLoader()); //打印出ServiceLoader的类加载器 System.out.println("ServiceLoader的类加载器:" + ServiceLoader.class.getClassLoader()); &#125;&#125; 输出结果： 12345678driver:class com.mysql.jdbc.Driverloader:sun.misc.Launcher$AppClassLoader@18b4aac2-------------driver:class com.mysql.fabric.jdbc.FabricMySQLDriverloader:sun.misc.Launcher$AppClassLoader@18b4aac2-------------当前线程上下文类加载器:sun.misc.Launcher$AppClassLoader@18b4aac2ServiceLoader的类加载器:null 从输出结果，我们可以看到，MySql的两个驱动都是由系统类加载器所加载的，按常理来说，这些驱动位于classPath下，也该由系统类记载器去加载；前面也说了，当前线程上下文类加载器默认是被设置为系统类加载器；而ServiceLoader位于java.util下，属于核心类库，是由启动类加载器加载的。 ServceLoader是对加载驱动很重要的一个类，那它是如何找到这些驱动的呢？ 详解ServiceLoaderServiceLoader是从JDK1.6才开始出现的，它的作用就是定位加载这些服务的具体实现。从JavaDoc中，我们可以看出ServiceLoader是从服务实现的jar包中的资源目录META-INF/services下去读取驱动名的，并且要求包含这些驱动的文件名必须是服务类型的完全限定的二进制名字，且文件中包含的也是服务实现类的完全限定二进制名，如下图所示。 META-INF/services下的java.sql.Driver文件里的内容。 12com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver ServiceLoader源码NO.1首先，看看ServiceLoader类内部维护的重要字段。 12private static final String PREFIX = "META-INF/services/";private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); 直接将资源目录META-INF/services/写死在类中，因为这个资源目录是定好了的，写死也无所谓的。 第二个字段是用做缓存的，ServiceLoader维护到目前为止加载的服务SPI的缓存 NO.2然后，从load方法说起。 1234public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125; 将服务类型与当前系统类加载器传给另一个load方法。 这里为什么要获取线程上下文类加载器呢？分析一下：ServiceLoader是在普通的Java程序中被引用到的，我们知道，在一个类X中引用另一个类Y，是使用X的类加载器去尝试加载类Y。 系统类加载器会去尝试加载ServiceLoader 最终启动类加载器将其加载 在ServiceLoader中引用到的类，会由启动类加载器去加载 但启动类加载器是无法加载到classPath下的类的，所以就通过线程上下文类加载器去加载 NO.3接着，调用私有的构造方法。 123456789101112131415 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, "Service interface cannot be null"); //要是传进来的线程类加载器为空，就将cl设置为系统类加载器 loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; //调用reload reload(); &#125;public void reload() &#123; //将上文提到的缓存清空 providers.clear(); //使用一个内部类进行懒加载 lookupIterator = new LazyIterator(service, loader); &#125; ServiceLoader内部加载这些服务实现类，是通过按需加载的方式。 NO.4只贴出这个内部类LazyIterator的主要代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private boolean hasNextService() &#123; if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; try &#123; String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); &#125; catch (IOException x) &#123; fail(service, "Error locating configuration files", x); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending = parse(service, configs.nextElement()); &#125; nextName = pending.next(); return true; &#125; private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; c = Class.forName(cn, false, loader); &#125; catch (ClassNotFoundException x) &#123; fail(service, "Provider " + cn + " not found"); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, "Provider " + cn + " not a subtype"); &#125; try &#123; S p = service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; catch (Throwable x) &#123; fail(service, "Provider " + cn + " could not be instantiated", x); &#125; throw new Error(); // This cannot happen &#125; 在这个内部类内部最重要的两个方法，hasNextService判断是否还有下一个服务实现类，nextService去加载服务实现类。 改变线程类加载器1234567891011121314public class MyTest17 &#123; public static void main(String[] args)&#123; Thread.currentThread().setContextClassLoader(MyTest17.class.getClassLoader().getParent()); ServiceLoader&lt;Driver&gt; drivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; iterator = drivers.iterator(); while (iterator.hasNext())&#123; Driver next = iterator.next(); System.out.println("driver:" + next.getClass()); System.out.println("loader:" + next.getClass().getClassLoader()); System.out.println("-------------"); &#125; System.out.println("当前线程上下文类加载器:" + Thread.currentThread().getContextClassLoader()); System.out.println("ServiceLoader的类加载器:" + ServiceLoader.class.getClassLoader()); &#125;&#125; 输出结果： 12当前线程上下文类加载器:sun.misc.Launcher$ExtClassLoader@1540e19dServiceLoader的类加载器:null 可以看到，我们将线程类加载器设置为扩展类加载器后，确实是无法将classPath下的服务实现类加载成功的。 我们将线程类加载器设置为我们的自定义类加载器。 1Thread.currentThread().setContextClassLoader(new MyClassLoader("loader")); 输出结果： 12345678driver:class com.mysql.jdbc.Driverloader:sun.misc.Launcher$AppClassLoader@18b4aac2-------------driver:class com.mysql.fabric.jdbc.FabricMySQLDriverloader:sun.misc.Launcher$AppClassLoader@18b4aac2-------------当前线程上下文类加载器:classLoader.MyClassLoader@6d6f6e28ServiceLoader的类加载器:null]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
        <tag>线程上下文类加载器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制（六）：getSystemClassLoader与Launcher]]></title>
    <url>%2F2019%2F03%2F19%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9A%E8%A7%A3%E6%9E%90Launcher%E7%B1%BB%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9A%E8%A7%A3%E6%9E%90Launcher%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[getSystemClassLoader在前文类加载机制（四）：解析ClassLoader，我们分析了ClassLoader类的基本源码，了解了一个class文件是如何被加载到内存中的，也知道了Java应用默认是由系统类加载器加载的，那系统类加载器是由谁加载的、是如何加载的？我们通过贯穿ClassLoader类的一个静态方法getSystemClassLoader来对这些过程进行分析。 内部维护的字段1234567// The class loader for the system// @GuardedBy("ClassLoader.class")private static ClassLoader scl;// Set to true once the system class loader has been set// @GuardedBy("ClassLoader.class")private static boolean sclSet; 在ClassLoader内部维护了两个与加载系统类加载器相关的静态变量，从注释中我们可以看出scl就是用来接收系统类加载器的，而sclSet则是一个布尔值，用来判断scl是否为空的，关于系统类加载器基本都是操作这两个值的。 getSystemClassLoader先来看看源码 1234567891011public static ClassLoader getSystemClassLoader() &#123; initSystemClassLoader(); if (scl == null) &#123; return null; &#125; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkClassLoaderPermission(scl, Reflection.getCallerClass()); &#125; return scl;&#125; 调用initSystemClassLoader()，并且做了一些安全检查，直接返回系统类加载器scl。 initSystemClassLoader通过这个方法来初始化系统类加载器，只贴了主要代码。 1234567891011121314151617181920212223private static synchronized void initSystemClassLoader() &#123; //若sclSet为真，则代表系统类加载已经被加载 if (!sclSet) &#123; if (scl != null) throw new IllegalStateException("recursive invocation"); //创建一个Launcher，后文会讲 sun.misc.Launcher l = sun.misc.Launcher.getLauncher(); if (l != null) &#123; Throwable oops = null; //通过Launcher类，获取系统类加载器 scl = l.getClassLoader(); try &#123; //判断是否有自定义类加载器 scl = AccessController.doPrivileged( new SystemClassLoaderAction(scl)); &#125; catch (PrivilegedActionException pae) &#123; &#125; &#125; //设置sclSet为真 sclSet = true; &#125; &#125; initSystemClassLoader主要就是初始化系统类加载器的，但是若用户自定义了类加载器，就会将scl初始化为用户自定义类加载器，这部分是通过ClassLoader的一个内部类来实现的。 SystemClassLoaderActionSystemClassLoaderAction是一个内部类，最后就是通过这个内部类来完成最后的类加载器初始化工作的。 1234567891011121314151617181920212223242526class SystemClassLoaderAction implements PrivilegedExceptionAction&lt;ClassLoader&gt; &#123; private ClassLoader parent; SystemClassLoaderAction(ClassLoader parent) &#123; this.parent = parent; &#125; public ClassLoader run() throws Exception &#123; //从系统属性中获取key，即用户自定义类加载器的二进制名 String cls = System.getProperty("java.system.class.loader"); //若cls为空，则返回parent，即传入的系统类加载器 if (cls == null) &#123; return parent; &#125; //通过这个自定义类加载器的二进制名，使用系统类加载器去将其加载，并将其初始化 Constructor&lt;?&gt; ctor = Class.forName(cls, true, parent) .getDeclaredConstructor(new Class&lt;?&gt;[] &#123; ClassLoader.class &#125;); //通过反射创建这个自定义类加载器的实例 ClassLoader sys = (ClassLoader) ctor.newInstance( new Object[] &#123; parent &#125;); //将线程上下文类加载器设置为这个自定义类加载器 Thread.currentThread().setContextClassLoader(sys); return sys; &#125;&#125; 这个内部类通过构造函数，传入通过Launcher创建的系统类加载器，然后再尝试去加载系统属性java.system.class.loader中保存的自定义类加载器的二进制类名。 Launcher刚刚在上文中说了initSystemClassLoader方法是通过创建一个Launcher类的实例，通过调用这个实例的getClassLoader()方法来获取到系统类加载器的。现在我们就来分析分析Launcher类，因为代码是由IDEA反编译出来的，所以参数名是由IDEA自己生成的。 首先，来看看Launcher类内部维护的重要的字段。 12private static String bootClassPath = System.getProperty("sun.boot.class.path");private ClassLoader loader; 首先，第一个是启动类加载器所要加载的jar包的路径。 第二个是一个类加载器字段，上文getClassLoader()所获取的一个类加载器就是这个字段。 再来来看看构造方法（没有安全管理部分的代码）。 1234567891011121314151617181920public Launcher() &#123; //声明一个扩展类加载器 Launcher.ExtClassLoader var1; try &#123; //创建一个扩展类加载器 var1 = Launcher.ExtClassLoader.getExtClassLoader(); &#125; catch (IOException var10) &#123; throw new InternalError("Could not create extension class loader", var10); &#125; try &#123; //将内部维护的一个ClassLoader赋值为系统类加载器 this.loader = Launcher.AppClassLoader.getAppClassLoader(var1); &#125; catch (IOException var9) &#123; throw new InternalError("Could not create application class loader", var9); &#125; //设置线程上下文类加载为系统类加载器 Thread.currentThread().setContextClassLoader(this.loader); &#125; 这里在构造方法中声明扩展类加载器，而不将其设置为全局变量的原因是，可以直接通过系统类加载器的getParent()来获取扩展类加载器。 AppClassLoader在Launcher的构造方法中，通过AppClassLoader.getAppClassLoader来获取系统类加载器，其实AppClassloader就是我们所说的系统类加载器，它是Launcher的一个内部类，它的最顶层父类也是ClassLoader 123456789101112131415public static ClassLoader getAppClassLoader(final ClassLoader var0) throws IOException &#123; //获取系统类加载器要加载的jar包路径以及当前Java程序classPath路径 final String var1 = System.getProperty("java.class.path"); //根据这些路径，创建一个文件数组 final File[] var2 = var1 == null ? new File[0] : Launcher.getClassPath(var1); //访问控制操作和决策 return (ClassLoader)AccessController.doPrivileged(new PrivilegedAction&lt;Launcher.AppClassLoader&gt;() &#123; public Launcher.AppClassLoader run() &#123; //将文件数组转换成一个URL数组 URL[] var1x = var1 == null ? new URL[0] : Launcher.pathToURLs(var2); //将当前的资源URL数组以及扩展类加载器传入这个内部类的构造方法 return new Launcher.AppClassLoader(var1x, var0); &#125; &#125;); &#125; 最后通过ClassLoader的构造方法，创建出当前的这个类加载器，即系统类加载器，且扩展类加载器被设置为它的父类加载器。 扩展类加载ExtClassLoader和系统类加载器是差不多的，也是Launcher类的一个内部类，它从系统属性java.ext.dirs中获取要加载的jar包的路径。 测试前面分析了Launcher类，我们来看看它是由哪个类加载器加载的。 12345678910public class MyTest15 &#123; public static void main(String[] args) &#123; System.out.println(System.getProperty("sun.boot.class.path")); System.out.println(System.getProperty("java.ext.dirs")); System.out.println(System.getProperty("java.class.path")); System.getProperty("java.system.class.loader"); System.out.println(ClassLoader.class.getClassLoader()); System.out.println(Launcher.class.getClassLoader()); &#125;&#125; 输出结果： 12345678910F:\Program Files\Java\jdk\jre\lib\resources.jar;F:\Program Files\Java\jdk\jre\lib\rt.jar;F:\Program Files\Java\jdk\jre\lib\sunrsasign.jar;F:\Program Files\Java\jdk\jre\lib\jsse.jar;F:\Program Files\Java\jdk\jre\lib\jce.jar;F:\Program Files\Java\jdk\jre\lib\charsets.jar;F:\Program Files\Java\jdk\jre\lib\jfr.jar;F:\Program Files\Java\jdk\jre\classes-------------F:\Program Files\Java\jdk\jre\lib\ext;C:\windows\Sun\Java\lib\ext-------------F:\Program Files\Java\jdk\jre\lib\charsets.jar;F:\Program Files\Java\jdk\jre\lib\deploy.jar;F:\Program Files\Java\jdk\jre\lib\ext\access-bridge-64.jar;F:\Program Files\Java\jdk\jre\lib\ext\cldrdata.jar;F:\Program Files\Java\jdk\jre\lib\ext\dnsns.jar;F:\Program Files\Java\jdk\jre\lib\ext\jaccess.jar;F:\Program Files\Java\jdk\jre\lib\ext\jfxrt.jar;F:\Program Files\Java\jdk\jre\lib\ext\localedata.jar;F:\Program Files\Java\jdk\jre\lib\ext\nashorn.jar;F:\Program Files\Java\jdk\jre\lib\ext\sunec.jar;F:\Program Files\Java\jdk\jre\lib\ext\sunjce_provider.jar;F:\Program Files\Java\jdk\jre\lib\ext\sunmscapi.jar;F:\Program Files\Java\jdk\jre\lib\ext\sunpkcs11.jar;F:\Program Files\Java\jdk\jre\lib\ext\zipfs.jar;F:\Program Files\Java\jdk\jre\lib\javaws.jar;F:\Program Files\Java\jdk\jre\lib\jce.jar;F:\Program Files\Java\jdk\jre\lib\jfr.jar;F:\Program Files\Java\jdk\jre\lib\jfxswt.jar;F:\Program Files\Java\jdk\jre\lib\jsse.jar;F:\Program Files\Java\jdk\jre\lib\management-agent.jar;F:\Program Files\Java\jdk\jre\lib\plugin.jar;F:\Program Files\Java\jdk\jre\lib\resources.jar;F:\Program Files\Java\jdk\jre\lib\rt.jar;D:\jvm\target\classes;C:\Users\Administrator\AppData\Local\JetBrains\Toolbox\apps\IDEA-U\ch-0\183.5429.30\lib\idea_rt.jar-------------null-------------nullnull 输出结果显示出了，这三个类加载器所要加载的一些jar包或者路径，因为我们没设置自定义类加载的加载路径，所以返回为空。ClassLoader和Launcher的类加载器，输出为null，其实并不是没有类加载器的意思，而是在Java虚拟机中，获取类加载器时，null就代表着启动类加载器，也就是说，ClassLoader和Launcher类都是由启动类加载器加载到内存中的。我们也可以验证一下，Launcher类属于sun.misc包，这个包属于charsets.jar包下，从上面的输出结果中，可以看到这个包是由启动类加载器加载的；而ClassLoader类是位于java.lang包下，位于resources.jar包下，同样也是由启动类加载器加载的。 在前面的文章中，我们说过，当加载一个内部有引用其他类的类时，就会使用当前类的类加载器去尝试加载这些引用的类，我们也可以测试下。 1234567891011121314public class MyTest0 &#123; public static void main(String[] args) &#123; Launcher launcher = new Launcher(); //获得系统类加载 ClassLoader classLoader = launcher.getClassLoader(); System.out.println(classLoader); System.out.println(classLoader.getClass().getClassLoader()); //获得扩展类加载器 System.out.println(classLoader.getParent()); System.out.println(classLoader.getParent().getClass().getClassLoader()); System.out.println(classLoader.getParent().getParent()); &#125;&#125; 输出结果： 12345sun.misc.Launcher$AppClassLoader@4554617cnullsun.misc.Launcher$ExtClassLoader@74a14482nullnull 输出结果验证了我们的说法，系统类加载器和扩展类加载器都是由启动类加载器加载的，当加载这两个加载器时，也就是对这两个类的主动使用，会首先加载它们的父类，也就导致了ClassLoader的加载。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
        <tag>Launcher类</tag>
        <tag>getSystemClassLoader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制（五）：自定义类加载器与深入双亲委托机制]]></title>
    <url>%2F2019%2F03%2F17%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E4%B8%8E%E6%B7%B1%E5%85%A5%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%89%98%E6%9C%BA%E5%88%B6%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E4%B8%8E%E6%B7%B1%E5%85%A5%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%89%98%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[引言我们知道类加载器共分为两大类型，Java虚拟机自带的类加载器和自定义类加载器。Java虚拟机自带的类加载器分别加载了不同路径下的class文件，而有时我们需要加载一些特殊的class文件，如这个class文件是被加密的，我们就需要自己定义类加载器去解密加载它，又比如我们需要从网络或者直接从数据库中读取class文件，我们也需要自己定义类加载。 上文（类加载机制（四）：解析ClassLoader）我们介绍分析了ClassLoader类，知道这个类是一个抽象类，除了Java虚拟机内建的启动类加载器以为，所有的类加载器都继承于它，并且要重载它的一个方法findClass去搜寻指定名字的class文件，并且如果在一个类中，又有其他类的引用，也是先通过调用类的类加载器先尝试去加载。在此篇文章，我们自定义一个类加载器去加载本地文件系统中的class文件来深入剖析双亲委托机制。 自定义类加载器首先来看看代码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class MyClassLoader extends ClassLoader&#123; //定义一个className，表示自定义类加载器的名字 private String className; //定义一个path，表示class文件所在目录 private String path; public void setPath(String path) &#123; this.path = path; &#125; //同其父类ClassLoader一样，有两个构造方法 public MyClassLoader(ClassLoader parent, String className) &#123; super(parent); this.className = className; &#125; public MyClassLoader(String className) &#123; super(); this.className = className; &#125; //重载的findClass方法 @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try &#123; //测试自定义类加载器是否执行成功 System.out.println("自定义class loader name: " + this.className); //调用MyLoadClass获取字节数组 byte[] bytes = this.MyLoadClass(name); //调用 return defineClass(null,bytes,0,bytes.length); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; private byte[] MyLoadClass(String className) throws IOException &#123; InputStream is = null; byte[] data = null; ByteArrayOutputStream bis = null; //将传入的类的二进制名转换为类的全限定名（包名+类名） String replace = className.replace(".", File.separator); try &#123; //将这个class文件转换成字节数组 is = new FileInputStream(this.path + replace + ".class"); bis = new ByteArrayOutputStream(); int ch = 0; while (-1 != (ch = is.read()))&#123; bis.write(ch); &#125; data = bis.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; is.close(); bis.close(); &#125; return data; &#125;&#125; 如上代码所示，这个简易的自定义类加载器同样有两个构造方法，没有父类加载器传入的构造方法会调用ClassLoader的无参的构造方法，将系统类加载器设置为这个自定义类加载器的父类加载器；有父类类加载器传入的构造函数，也会调用ClassLoader的构造方法，只不过调用的是有参的构造方法，将传入的这个类加载器设置为这个自定义类加载器的父类加载器。 测试具体的实现，在注释中，就不过多阐述了。我们在findClass中写了句测试语句System.out.println(&quot;自定义class loader name: &quot; + this.className);,来测试自定义类加载器是否执行成功。到这我们就可以在启动类中进行测试了。 123456789public static void executeLoad(MyClassLoader loader,String className) throws Exception&#123; loader.setPath(***********); Class&lt;?&gt; loadClass = loader.loadClass(className); //打印出Class对象的hash码 System.out.println(className + "的class对象的hashCode:" + loadClass.hashCode()); //创建一个示例 Object o = loadClass.newInstance(); System.out.println("--------------"); &#125; 写了一个执行方法，减少代码，并且在指定的path中放入MyTest1的class文件： 传入自定义类加载器的实例与要加载的类的二进制名字。 在方法体里面指定好要加载的class文件目录。 调用父类的loadClass方法进行加载（ClassLoader具体怎么加载，见类加载机制（四）：解析ClassLoader）。 1234public static void main(String[] args) throws Exception &#123; MyClassLoader loader1 = new MyClassLoader("loader1"); MyClassLoader.executeLoad(loader1,"classLoader.MyTest1");&#125; 输出结果： 12classLoader.MyTest1的class对象的hashCode:1163157884-------------- 竟然只输出了MyTest1的class对象的hashCode，意思是我们的自定义类加载未执行(System.out.println(&quot;自定义class loader name: &quot; + this.className);) (⊙o⊙)，怎么回事？ 结果分析我们知道关于类的加载也就是class文件的搜索与加载过程是由类加载器完成的，而类加载器又是遵循双亲委托机制的，关于这个机制就不多说了，见以前的文章。 类加载机制（三）：类的加载与类加载器 类加载机制（四）：解析ClassLoader 在MyClassLoader中我们首先调用ClassLoader的loadClass方法，在loadClass中，最终会调用我们重载的这个findClass方法，但现在我们重载的findClass并没有被调用，说明有其他的findClass调用了。那我们在executeLoad中打印下加载的这个class对象的类加载器。 1System.out.println("我就是它加载的：" + loadClass.getClassLoader()); 输出结果： 123我就是它加载的：sun.misc.Launcher$AppClassLoader@18b4aac2classLoader.MyTest1的class对象的hashCode:1163157884-------------- 结果显示MyTest1是由系统类加载器加载的。 现在水落石出了，原来我们想要加载的MyTest1被系统类加载器给加载了，那为什么呢，其实联想下双亲委托机制就明白了。MyClassLoader收到要加载某个类的请求，就往其父类加载器（系统类加载器）传递，然后，一层层传递，导启动类加载器后，又往下传回来，传到系统类加载器后，系统类加载器发现自己能加载这个类，然后就截胡了，MyTest1.class就被系统类加载器加载到内存中去了。 我们知道，系统类加载器是从classPath或者java.class.path系统属性中去加载class文件和jar包的，那我们把classPath中的MyTest1.class给删除掉，结果又会怎么样呢？ 输出结果： 1234自定义class loader name: loader1我就是它加载的：classLoader.MyClassLoader@4554617cclassLoader.MyTest1的class对象的hashCode:356573597-------------- 输出结果显示：我们的MyClassLoader起作用啦，注意这里hashCode不一样哦(⊙x⊙;)。 12345678910public static void main(String[] args) throws Exception &#123; MyClassLoader loader1 = new MyClassLoader("loader1"); MyClassLoader.executeLoad(loader1,"classLoader.MyTest1"); MyClassLoader loader2 = new MyClassLoader("loader2"); MyClassLoader.executeLoad(loader2,"classLoader.MyTest1"); //loader2是loader3的类加载器 MyClassLoader loader3 = new MyClassLoader(loader2,"loader3"); MyClassLoader.executeLoad(loader3,"classLoader.MyTest1"); &#125; 再创建两个MyClassLoader的实例。loader2–&gt;loader3 输出结果： 1234567891011自定义class loader name: loader1我就是它加载的：classLoader.MyClassLoader@4554617cclassLoader.MyTest1的class对象的hashCode:356573597--------------自定义class loader name: loader2我就是它加载的：classLoader.MyClassLoader@677327b6classLoader.MyTest1的class对象的hashCode:2133927002--------------我就是它加载的：classLoader.MyClassLoader@677327b6classLoader.MyTest1的class对象的hashCode:2133927002-------------- 输出结果显示：loader2加载获得的class对象和loader3加载获得的class是一样的。 这个结果其实ClassLoader类中的loadClass很清楚： 类只会被加载一次（findLoadedClass(String)），返回的class对象都一样。若没有class文件，则会调用当前加载器的findClass方法去查找class文件。 双亲委托机制是包含关系，实例化loader3时可以让loader2作为自己的父加载器，创建loader3去加载MyTest1时，因为loader2已经加载过了（findLoadedClass(String)），所以使用loader3加载时，loader3直接返回了已经加载过的MyTest1的class对象。 深入双亲委托机制我们通过一些示例代码来进行分析。 示例代码NO.11234567891011121314151617181920212223242526public class MyCat &#123; public MyCat()&#123; public MyCat()&#123; //打印出MyCat的类加载器器 System.out.println("MyCat is loaded by:" + this.getClass().getClassLoader()); &#125; &#125;&#125;--------------------------------------------------------public class MySample &#123; public MySample() &#123; //打印出MySample的类加载器器 System.out.println("MySample is loaded by:" + this.getClass().getClassLoader()); System.out.println("--------------"); //在MySample的构造方法中创建一个MyCat的实例 new MyCat(); &#125;&#125;--------------------------------------------------------public class MyTest13 &#123; public static void main(String[] args) throws Exception &#123; //加载MySample类 MyClassLoader loader1 = new MyClassLoader("loader1"); MyClassLoader.executeLoad(loader1,"refenLoad.MySample"); &#125;&#125; 输出结果： 12345refenLoad.MySample的class对象的hashCode:1956725890MySample is loaded by:sun.misc.Launcher$AppClassLoader@18b4aac2--------------MyCat is loaded by:sun.misc.Launcher$AppClassLoader@18b4aac2-------------- 具体过程如下： 调用MyClassLoader加载MySample类。 classPath中有MySample类的class文件，系统类加载器将其加载到内存中。 然后因为在executeLoad方法中创建了对象实例，MySample被首次主动使用，即进行初始化，调用构造函数完成初始化。 在MySample的构造函数中new MyCat()，即对MyCat的首次主动使用，经历加载连接初始化。 接着，复制一份MySample的class文件到我们设定的path中，删除到classPath中的那份，结果怎么样呢。 输出结果： 123456自定义class loader name: loader1refenLoad.MySample的class对象的hashCode:1735600054MySample is loaded by:classLoader.MyClassLoader@74a14482--------------MyCat is loaded by:sun.misc.Launcher$AppClassLoader@18b4aac2-------------- 为什么，两个类的类加载器又不一样呢？ 因为classPath中没有MySample的class文件，所以经过双亲委托机制，最终是通过MyClassLoader来加载我们自己的MySample文件。 创建MySample实例时，进行MySample的初始化，执行MySample的构造方法。 MySample的构造方法里创建MyCat实例，使用加载MySample的类加载器来加载MyCat。 MyClassLoader加载器委托系统加载器来加载MyCat.class，加载完成。 再接着，复制一份MyCat的class文件到我们设定的path中，删除到classPath中的那份，结果又怎么样呢。 输出结果： 1234567自定义class loader name: loader1refenLoad.MySample的class对象的hashCode:1735600054MySample is loaded by:classLoader.MyClassLoader@74a14482--------------自定义class loader name: loader1MyCat is loaded by:classLoader.MyClassLoader@74a14482-------------- 它们的类加载器又都是MyClassLoader了。 因为classPath中没有MySample的class文件，所以经过双亲委托机制，最终是通过MyClassLoader来加载我们自己的MySample文件。 创建MySample实例时，进行MySample的初始化，执行MySample的构造方法。 MySample的构造方法里创建MyCat实例，使用加载MySample的类加载器MyClassLoader来加载MyCat，加载成功。 如果只删除MyCat.class又会怎么样呢？ 系统加载器加载MySmple.class，加载MyCat时，同样使用系统加载器来加载MyCat，但classPath中没有MyCat.class文件，最后就会抛出java.lang.NoClassDefFoundError异常。 再再接着，reBuild项目，删除掉MySample的class文件，在MyCat的构造方法里打印MySample的class`。 123456public class MyCat &#123; public MyCat()&#123; System.out.println("MyCat is loaded by:" + this.getClass().getClassLoader()); System.out.println("from MyCat:" + MySample.class); &#125;&#125; 输出结果: 12345自定义class loader name: loader1refenLoad.MySample的class对象的hashCode:1735600054MySample is loaded by:classLoader.MyClassLoader@74a14482--------------MyCat is loaded by:sun.misc.Launcher$AppClassLoader@18b4aac2 我们想在MyCat中调用MySample，竟然报错了，找不到MySample类，这里涉及到类的命名空间问题。 最后，只删除classPath中的MySample的class文件，在MySample的构造方法中打印MyCat的class。 1234567891011121314public class MyCat &#123; public MyCat()&#123; System.out.println("MyCat is loaded by:" + this.getClass().getClassLoader()); &#125;&#125;-----------------------------------------------public class MySample &#123; public MySample() &#123; System.out.println("MySample is loaded by:" + this.getClass().getClassLoader()); System.out.println("from MyCat:" + MyCat.class); System.out.println("--------------"); new MyCat(); &#125;&#125; 输出结果： 123456refenLoad.MySample的class对象的hashCode:1956725890MySample is loaded by:sun.misc.Launcher$AppClassLoader@18b4aac2from MyCat:class refenLoad.MyCat--------------MyCat is loaded by:sun.misc.Launcher$AppClassLoader@18b4aac2-------------- 可以看到，这里就打印成功，也就是说，在MySample中调用MyCat成功，这里同样也是命名空间的问题。 命名空间每个类加载器都有自己的命名空间，命名空间由该加载器及所有父加载器所加载的类组成。 在同一个命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类 在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类 命名空间之间的关系同一个命名空间内的类是相互可见的。 子加载器的命名空间包含所有父加载器的命名空间。因此由只加载器加载的类能看见父加载器加载的类。例如系统类加载器可以看见根类加载器加载的类。 由父加载器加载的类不能看见子加载器加载的类。 如果两个加载器之间没有直接或间接的父子关系，那么它们各自加载的类互不可见。 了解了命名空间后，就明白前面代码的输出结果了。 （1）删除掉MySample的class文件，在MyCat的构造方法里打印MySample的class。MySample由MyClassLoader加载，MyCat由AppClassLoader加载，父加载器加载的类是看不到子加载器加载的类，则在MyCat中看不到MySample。 （2）删除掉MySample的class文件，在MySample的构造方法中打印MyCat的class，MySample由MycalssLoader加载，MyCat由AppClassLoader加载，子加载器能够看见父加载器加载的类，则MySample可以看到MyCat的class。 NO.2复制一份MyPerson.class到指定的路径下。 123456789101112131415161718192021222324252627282930313233public class MyPerson &#123; //内部维护一个MyPerson的类型的属性 private MyPerson person; public MyPerson() &#123; &#125; //传进来一个对象，强制转换为MyPerson public void setPerson(Object o) &#123; this.person = (MyPerson)o; &#125;&#125;-----------------------------------------public class MyTest14 &#123; public static void main(String[] args) throws Exception&#123; //创建两个MyClassLoader的实例，都去加载位于path路径下的MyPerson.class文件 MyClassLoader loader1 = new MyClassLoader("loader1"); MyClassLoader loader2 = new MyClassLoader("loader2"); loader1.setPath("C:\\Users\\Administrator\\Desktop\\jvmTest\\"); loader2.setPath("C:\\Users\\Administrator\\Desktop\\jvmTest\\"); //分别去加载MyPerson.class,得到其class对象 Class&lt;?&gt; clazz1 = loader1.loadClass("classLoader.MyPerson"); Class&lt;?&gt; clazz2 = loader2.loadClass("classLoader.MyPerson"); //比较两个class对象是否相等 System.out.println(clazz1 == clazz2); //通过class对象，创建实例 Object o1 = clazz1.newInstance(); Object o2 = clazz2.newInstance(); //使用反射的方式去调用MyPerson的setPerson方法 Method setPerson = clazz1.getMethod("setPerson", Object.class); //调用o1的setPerson方法，将o2传进去。 setPerson.invoke(o1,o2); &#125;&#125; 输出结果： 1true 通过系统类加载器加载，没什么问题。 从classPath中删除掉MyPerson.class文件，再运行程序。 从结果可以看出，两个class对象最终都是由MyClassLoader来加载得到的，但是得到的class并不是同一个，并且在执行o1的setPath方法时还报错，说无法将MyPerson转换为MyPerson，这就很奇怪了？ 其实，想想类加载器的命名空间，还是挺简单的。 一个类在Java虚拟机中的唯一性，是由类与类加载器一起共同决定的，每一个类加载，都有自己独立的命名空间。在此处，loader1与loader2虽然都是MyClassLoader的实例，但是它们之间并不存在双亲委托的关系，即是两个不同的类加载器，即存在两个不同的命名空间，clazz1和clazz2属于不同的命名空间。使用反射去调用MyPerson的serPerson方法，想把o2赋值给o1中的Person属性，但因为clazz1和clazz2是属于不同的命名空间，推广开，o1和o2也属于不同的命名空间，两者之间是不可见的，所以不能将o2赋值给o1的Person属性。 总结通过这个自定义类加载器，我们深入剖析了类加载器的双亲委托机制，这里再放一遍关于类加载器的双亲委托模型的好处： 可以确保Java核心类库的类型安全：所有的Java应用都至少会引用java.lang.Object类，也就是说在运行期，java.lang.Object这个类会被加载到Java虚拟机中；如果这个加载过程是由各自的类加载器去加载的话，那系统中会产生多个版本的Object类，这些类位于不同的命名空间中，相互之间不兼容，不可见，应用程序将会变得混乱。而通过双亲委托机制，Java核心类库中的类都由启动加载器来完成加载，从而保证了Java应用使用的都是同一个Java核心类库，它们之间是相互兼容的。 可以确保Java核心类库所提供的类不会被自定义的类所替代。 不同的类加载器可以加载相同名称的类，这些相同名称的类可以并存在Java虚拟机中。不同类加载器所加载的类是不兼容的，这就相当于在Java虚拟机中创建了一个又一个的相互隔离的Java类空间。 最后，提一句，内建于JVM的启动类加载器会加载java.lang.ClassLoader以及其他的Java平台类，当JVM启动时，一块特殊的机器码会运行，它会加载扩展类加载器与系统类加载器，这块特殊的机器码叫做启动类加载器（Bootstap）。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
        <tag>自定义类加载器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制（四）：解析ClassLoader]]></title>
    <url>%2F2019%2F03%2F15%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E8%A7%A3%E6%9E%90ClassLoader%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E8%A7%A3%E6%9E%90ClassLoader%2F</url>
    <content type="text"><![CDATA[ClassLoader类ClassLoader介绍ClassLoader顾名思义就是类加载器，它是一个直接继承Object的抽象类，除了启动类加载器以外，所有的类加载器都继承ClassLocader类，应用程序可以去实现这个抽象类，来扩展Java虚拟机加载类的方式。一个类加载器的作用就是加载类，通过一个类的二进制名，一个类加载器就可以通过这个类的二进制名去尝试定位或者生成（在动态加载中，类加载器可以去生成字节码数据）这个二进制名所定义的字节码数据。它的一般策略就是先将这个二进制名转换成这个类的Class文件名，然后从文件系统中读取这个文件。 二进制名(binary name)：Java虚拟机规范规定类加载器加载的类名必须是一个规范的字符串。 例如： 12345&gt; （1）"java.lang.String"&gt; （2）"javax.swing.JSpinner$DefaultEditor"&gt; （3）"java.security.KeyStore$Builder$FileBuilder$1"&gt; （4）"java.net.URLClassLoader$3$1"&gt; （2）表示javax.swing.JSpinner的内部类DefaultEditor。 （3）表示java.security.KeyStore的内部类Builder的内部类FileBuilder中的第一个内部类。 /(ㄒoㄒ)/~~ 每一个类的Class对象都包含着对其类加载器的引用，意思是可以直接通过类的Class对象获取其类加载器。 1clazz.getClassLoader(); 对于数组来说，它的Class对象不是由类加载来加载创建的，而是在运行期自动创建的。但是对于元素为引用类型的数组来说，是可以通过clazz.getClassLoader()返回类加载器的，只不过返回的是它的component的类加载器。对于元素类型是基本类型的数组来说，是没有类加载器的。 ClassLoader源码解析ClassLoader的机制这个ClassLoader类是通过双亲委托模型来寻找类和资源的（见前文：类加载机制（三）：类的加载与类加载器）：每一个类加载器都有一个父加载器，当收到加载一个类的请求时，类加载器就会去委托它的父加载器去尝试加载类，虚拟机内建的类加载，即启动类加载器是没有父加载器，它是作为类加载器实例的父加载器的。 内部属性1private final ClassLoader parent; ClassLoader类内部维护了一个ClassLoader,代表着当前类加载器的父加载器。 构造函数123protected ClassLoader(ClassLoader parent) &#123; this(checkCreateClassLoader(), parent); &#125; 有参的构造函数，chuan’jian通过传入一个类加载器作为当前类加载器的父加载器。 123protected ClassLoader() &#123; this(checkCreateClassLoader(), getSystemClassLoader()); &#125; 无参的构造函数，使用getSystemClassLoader()获取到系统类加载器作为当前类加载器的父加载器（这个方法也会在后面进行分析）。 类的加载过程123public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false); &#125; loadClass(String name)方法是ClassLoader类中默认的加载类的方法，它可以加载具有指定的二进制名的类。调用这个方法等价于调用loadClass(name, false)。 再来看看loadClass(name, false) 123456789101112131415161718192021222324252627282930313233343536protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 首先，检查这个类是否已经被加载 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; //若父类加载器不为空，使用父类加载器去加载 c = parent.loadClass(name, false); &#125; else &#123; //若父类加载器为空，使用虚拟机内置的启动类加载器进行加载 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; &#125; if (c == null) &#123; long t1 = System.nanoTime(); //若仍没加载到，就调用findClass(name)来找到这个类，调用的是 //当前类加载器的 findClass(String)方法 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; //若resolve参数为真，就调用resolveClass将这个class对象完成连接 if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; loadClass的作用就是根据特定的二进制名加载类。在ClassLoader抽象类中，它搜寻class文件的默认实现是按如下步骤进行的： 执行findLoadedClass(String)查看类是否已经加载加载器不能加载的类。 123456789&gt; protected final Class&lt;?&gt; findLoadedClass(String name) &#123;&gt; //检查这个二进制名是否合法&gt; if (!checkName(name))&gt; return null;&gt; return findLoadedClass0(name);&gt; &#125;&gt; &gt; private native final Class&lt;?&gt; findLoadedClass0(String name);&gt; 如果Java虚拟机已经将这个类加载器记录为这个二进制名代表的类的类加载器后，就直接返回这个二进制名代表的类的class对象，否则，就返回null。而这一 执行当前类的父类加载器的loadClass。若parent为空，则使用Java虚拟机的内置根加载器来进行加载。 执行findClass(String)来找到这个类，调用的是当前类加载器的 findClass(String)方法。 1234&gt; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;&gt; throw new ClassNotFoundException(name);&gt; &#125;&gt; findClass(String)的作用是根据二进制名找到class文件，将class文件转换为字节数组，如上代码所示，这个类是没有执行语句的，所以这个类是需要继承了ClassLoader的类加载器来重载来完成上述功能的，且这个类加载器的实现是遵循双亲委托机制的，这个方法是由loadClass方法调用的。 最后，就可以执行defineClass方法了，将Class文件的字节数组转换成Class对象的实例。 123456&gt; protected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len)&gt; throws ClassFormatError&gt; &#123;&gt; return defineClass(name, b, off, len, null);&gt; &#125;&gt; 当传入类的二进制名（可以为空），字节数组，偏移量，数组长度，就由Java虚拟机来完成最后的加载工作。 从上文所诉的过程，可以看出加载类的过程其实很简单，当时也体现出了双亲委托机制的思想，从当前类开始，不断的调用其父类加载器，直到启动类加载器为止。 下篇博客，我会用一个自定义类加载器来深入剖析双亲委托机制。类加载机制（五）：自定义类加载器与深入双亲委托机制]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
        <tag>ClassLoader</tag>
        <tag>源码解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制（三）：类的加载与类加载器]]></title>
    <url>%2F2019%2F03%2F14%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E4%B8%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E4%B8%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[类的加载引言类的加载属于Java虚拟机类加载机制的第一个阶段，它的作用就是将二进制形式的Java类型加载到内存中去，最终形成的就是内存中的Class对象，这个对象封装了类的数据结构。而这个加载过程，就是由一个叫类加载器的程序所完成的，也就是说，一个Java类是由类加载器所加载到内存中的。 类的预先加载在类的加载中，类加载器并不需要等到某个类被首次主动使用时再加载它。JVM规范允许类加载器在预料到某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError）错误。 如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 类加载器与双亲委托机制顾名思义，类加载器就是用来把类加载到Java虚拟机中的。而从JDK1.2开始，类的加载就是遵循双亲委托机制来进行加载的，这种机制很好的保证了Java平台的安全与程序的有序。 类加载器类加载器一共有两种类型： Java虚拟机自带的加载器 —-根类加载器（Bootstrap） —-扩展类加载器（Extension） —-系统（应用）加载器（System） 用户自定义的类加载器 —-java.lang.classLoader的子类 —-用户可以定制类的加载方式 虚拟机自带加载器 根（Bootstrp）类加载器（启动类加载器）：负责加载的虚拟机的核心类库，比如 java.lang.*等。根类加载器是从系统属性sun.boot.class.path所指定的目录中加载类库。根类加载器本身的实现依赖于底层操作系统，属于虚拟机实现的一部分，它并没有实现java.lang.classLoader类。 扩展类加载器（Extension）：负责加载JDK的安装目录的jre\lib\ext子目录下的类库，从系统属性java.ext.dirs所指定的目录中加载类库。扩展类加载器是纯Java类，它继承于java.lang.classLoader类。 系统（System）类加载器（应用类加载器）：从环境变量classPath或者从系统属性java.class.path所指定的目录下加载类，它是用户自定义类加载器的默认父加载器。系统类加载器是纯Java类，它继承于java.lang.classLoader类。 自定义类加载器有时想对字节码文件进行加密处理，使用Java虚拟机自带的加载器就无法加载已经加了密的字节码文件，这时就可以使用自定义加载器对加密的字节码文件进行解密，就可以将其还原为正确的字节码文件 。 双亲委托机制在Java虚拟机的类加载阶段，Java程序一般是由上述的类加载器一起配合着加载的。而这些类加载器它们之间配合着加载类采用的是一种叫双亲委托机制的加载机制。除了根类加载器以外，每一个类加载器都有一个父类加载器。 双亲委托机制的基本流程是这样：当一个类接收到类的加载请求时，它首先不会对其进行加载，而是交给它的父加载器Parent来进行尝试加载，如果这个父加载器不能对这个类进行加载，就继续往上传递，一直到根类加载器为止，如果最后根类加载器也无法加载，又会一级级的传递下来，让适合的类加载器来进行加载。 如上图所示，自定义类加载器Loader1想要加载Test类，它不会先去加载这个类，而是一级级的往上传递，到达根类加载器后，若根类记载器无法加载，再一级级的传递下来，最后才Loader1来完成加载。 需要指出的是，加载器之间的父子关系实际上指的是加载器对象之间的包装关系，而不是类之间的继承关系。一对父子加载器可能是同一个类加载器类的两个不同实例，也可能不是。在子加载器对象中还包装了一个父加载器对象（请看后续博客:类加载机制（四）：解析ClassLoader）。 代码测试NO.11234567891011public static void main(String[] args) &#123; //获取到系统类加载 ClassLoader classLoader = ClassLoader.getSystemClassLoader(); //打印出各类加载器 System.out.println(classLoader); while (null != classLoader)&#123; //获取此类加载器的父加载器 classLoader = classLoader.getParent(); System.out.println(classLoader); &#125; &#125; 输出结果： 123sun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@4554617cnull 启动类加载器，即根类加载器为null。 NO.212345678910111213141516public class MyTest12 &#123; public static void main(String[] args) &#123; String[] strings = new String[1]; MyTest12[] myTest12s = new MyTest12[1]; int[] ints = new int[1]; System.out.println(strings.getClass()); System.out.println(strings.getClass().getClassLoader()); System.out.println("----------"); System.out.println(myTest12s.getClass()); System.out.println(myTest12s.getClass().getClassLoader()); System.out.println("----------"); System.out.println(ints.getClass()); System.out.println(ints.getClass().getClassLoader()); &#125;&#125; 输出结果： 12345678class [Ljava.lang.String;null----------class [LclassLoader.MyTest12;sun.misc.Launcher$AppClassLoader@18b4aac2----------class [Inull 前文已说过，基本数组类的class类型直接继承于java.lang.Object,从上可以看出，component类型为基本数据类型的数组是由启动类加载器所加载的，而引用类型的数组则是由系统类加载器加载的。 双亲委托机制的好处 考虑到章节的完整性，先po出双亲委托机制的好处，关于命名空间导致类不相同的问题，请看后续博客：类加载机制（五）：自定义类加载器与深入双亲委托机制。 可以确保Java核心类库的类型安全，让Java类随着它的类加载器一起具备了一种带有优先级的层次关系：比如，所有的Java应用都至少会引用java.lang.Object类，也就是说在运行期，java.lang.Object这个类会被加载到Java虚拟机中；如果这个加载过程是由各自的类加载器去加载的话，那系统中会产生多个版本的Object类，这些类位于不同的命名空间中，相互之间不兼容，不可见，应用程序将会变得混乱。而通过双亲委托机制，Java核心类库中的类都由启动加载器来完成加载，从而保证了Java应用使用的都是同一个Java核心类库，它们之间是相互兼容的。 可以确保Java核心类库所提供的类不会被自定义的类所替代。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
        <tag>类加载器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制（二）：类的初始化]]></title>
    <url>%2F2019%2F03%2F13%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E7%B1%BB%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E7%B1%BB%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[类的初始化引言一般Java程序的class文件经过加载、连接后，就进入初始化阶段，顺序执行static语句，为静态变量赋予正确的值，执行static代码块，初始化类。 类的使用方式Java程序对类的使用分为两种： —-主动使用 —-被动使用 所有的Java虚拟机实现必须在每个类或接口被Java程序首次主动使用时才会初始化它们。 主动使用方式主动使用分为七种： —-创建类的实例 —-访问某个类或接口的静态变量，或者对该静态变量赋值 —-调用类的静态方法 —-反射（如Class.forName(com.test.Test)） —-初始化一个子类 —-Java虚拟机启动时被标明为启动类的类 —-JDK1.7开始提供的动态语言支持：java.lang.invoke.MethodHandle实例的解析结果REF_getStatic,REF_putStatic,REF_invokeStatic句柄对应的类没有初始化，则初始化。 除了以上七种情况，其他使用Java类的方法都被看作是对类的被动使用，都不会导致类的初始化。 类的初始化步骤对于类来说： 假如这个类还没有被加载和连接，那就先进行加载和连接 假如类存在直接父类，并且这个父类还没有被初始化，那就先初始化父类 假如类中存在初始化语句，那就一次执行这些初始化语句 对于接口来说： 当Java虚拟机初始化一个类时，要求它的所有父类都已经被初始化，但是这条规则并不适用于接口。 在初始化一个类时，并不会先初始化它所实现的接口 在初始化一个接口时，并不会先初始化它的父接口 因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化。只有当程序首次使用特定接口的静态变量时，才会导致该接口的初始化。 示例NO.11234567891011121314151617public class MyTest1 &#123; public static void main(String[] args) &#123; System.out.println(Son.str); &#125;&#125;class Parent&#123; public static String str = "parent str"; static &#123; System.out.println("parent static启动"); &#125;&#125;class Son extends Parent&#123; static &#123; System.out.println("son static启动"); &#125;&#125; 输出结果 输出结果显示只有Parent类被加载了。对于静态字段来说，只有直接定义了该字段的类才会被初始化。虽然Son没有被主动使用，但它已经被加载了。类加载器并不需要等到某个类被首次主动使用时再加载它。 将Parent类中的str变量注释掉，添加到Son类中 输出结果： 输出结果显示Parent类与Son类都被初始化了。通过使用Son的静态变量，导致Son的初始化，而当一个类在初始化时，首先要求其父类全部都已经初始化，即导致Parent初始化。 我们还可以从第一段打印类加载信息（通过添加虚拟机参数-XX:+TraceClassLoading）看出，虽然Son没有被主动使用，但它已经被加载了。类加载器并不需要等到某个类被“首次主动使用”时再加载它。 NO.212345678910111213141516171819public class MyTest2 &#123; public static void main(String[] args) &#123; System.out.println(Parent2.str); System.out.println(Parent2.bi); System.out.println(Parent2.si); System.out.println(Parent2.icons_1); System.out.println(Parent2.iconst_2); &#125;&#125;class Parent2&#123; public static final String str = "Hello Jvm"; public static final int bi = 127; public static final int si = 32767; public static final int icons_1 = 1; public static final int iconst_2 = 2; static &#123; System.out.println("Parent2 init"); &#125;&#125; 输出结果 12345Hello Jvm1273276712 将Parent的class文件从classPath中删除掉，再运行程序，程序没报错，输出结果一样。 常量的本质含义：常量在编译阶段会存入调用这个常量的常量池中。本质上，调用这个常量并没有直接引用到定义常量的类，因此并不会触发定义常量的类的初始化。如：Paren2中定义的常量被存入到了MyTest2中，之后两个类就没有任何关系了。甚至将Paren2的.class文件删除也没关系。 1234567891011public class MyTest3 &#123; public static void main(String[] args) &#123; System.out.println(Parent3.str); &#125;&#125;class Parent3&#123; public static final String str = UUID.randomUUID().toString().replace("-",""); static &#123; System.out.println("Paren3 init"); &#125;&#125; 输出结果: 12Paren3 init2b00eb3dbd934bf7ab610407058d276f 输出结果显示Parent3被成功初始化了。而且，删除掉Parent3的class文件，也会报java.lang.NoClassDefFoundError的错误。 在编译期间，对于并不能确定的常量来说，不会被存入到调用类的常量池中。而是在运行期间，主动使用常量的所属类，完成所属类的初始化。 NO.31234567891011121314151617public class MyTest4 &#123; public static void main(String[] args) &#123;// Parent4 parent4 = new Parent4(); Parent4[] parent4s = new Parent4[1]; int[] ints = new int[1]; System.out.println(parent4s.getClass()); System.out.println(parent4s.getClass().getSuperclass()); System.out.println("=============="); System.out.println(ints.getClass()); System.out.println(ints.getClass().getSuperclass()); &#125;&#125;class Parent4&#123; static &#123; System.out.println("Paren4 init"); &#125;&#125; 输出结果 12345class [LclassLoader.Parent4;class java.lang.Object==============class [Iclass java.lang.Object 输出结果显示并没有触发Parent的初始化过程，但是却触发了class [LclassLoader.Parent4;的初始化阶段，打印出的这个名称，它直接继承class java.lang.Object，代表了数组的component，即数组的组成元素。 将class文件反编译后，可以看出它的创建动作由助记符newarray触发。 anewarray：表示创建一个引用类型的数组（类、接口、数组），并将其引用值压入栈顶。newarray：表示创建一个基本类型的数组（int、char），并将其引用值压入栈顶。 NO.4123456789101112131415161718192021public class MyTest6 &#123; public static void main(String[] args) &#123; Single instance = Single.getInstance(); System.out.println("count1:" + Single.count1); System.out.println("count2:" + Single.count2); &#125;&#125;class Single&#123; public static int count1; public static int count2 = 0; private static Single single = new Single(); private Single()&#123; count1++; count2++; System.out.println("构造方法count1:" + count1); System.out.println("构造方法count2:" + count2); &#125; public static Single getInstance()&#123; return single; &#125;&#125; 输出结果： 1234构造方法count1:1构造方法count2:1count1:1count2:1 在MyTest6中调用Single的静态方法，触发Single的初始化阶段。 —-连接阶段，将静态变量全置为默认值： count1 = 0 count2 = 0 single = null —-初始化阶段，顺序执行静态语句： 执行到此句时 private static Single single = new Single();,执行Single的构造方法。 count1 = 1 count2 = 1 并将其打印，最后再在MyTest6的main方法中调用时，直接从Single的常量池中取出。 修改下Single的代码 123456789101112131415class Single&#123; public static int count1; private static Single single = new Single(); private Single()&#123; count1++; count2++; System.out.println("构造方法count1:" + count1); System.out.println("构造方法count2:" + count2); &#125; //调下顺序 public static int count2 = 0; public static Single getInstance()&#123; return single; &#125;&#125; 输出结果： 1234构造方法count1:1构造方法count2:1count1:1count2:0 再修改下Single的代码 123456789101112131415class Single&#123; //初值赋为1 public static int count1 = 1; private static Single single = new Single(); private Single()&#123; count1++; count2++; System.out.println("构造方法count1:" + count1); System.out.println("构造方法count2:" + count2); &#125; public static int count2 = 0; public static Single getInstance()&#123; return single; &#125;&#125; 输出结果： 1234构造方法count1:2构造方法count2:1count1:2count2:0 经过上面的程序可以看出，静态变量的声明语句，以及静态代码块都被看做类的初始化语句，Java虚拟机会按照初始化语句在类文件中的先后顺序来依次执行它们。 NO.512345678910111213141516171819202122232425public class MyTest7 &#123; static &#123; System.out.println("MyTest7 invoked"); &#125; public static void main(String[] args) &#123; Parent7 parent7; System.out.println("---------------");// parent7 = new Parent7(); Son7 son7 = new Son7(); System.out.println("---------------"); System.out.println(Son7.a); &#125;&#125;class Parent7&#123; static int a = 5; static &#123; System.out.println("Parent7 invoked"); &#125;&#125;class Son7 extends Parent7&#123; static int b = 6; static &#123; System.out.println("Son7 invoked"); &#125;&#125; 输出结果： 123456MyTest7 invoked---------------Parent7 invokedSon7 invoked---------------5 输出结果显示：首先使用MyTest7的启动类，导致了MyTest7的初始化，执行了静态代码块；然后声明了一个Parent7的变量，并不会导致Parent7的初始化；最后创建了一个Son7的实例，触发Son7的初始化，触发Parent7的初始化。 将Son7 son7 = new Son7();替换为parent7 = new Parent7(); 输出结果： 12345MyTest7 invoked---------------Parent7 invoked---------------5 输出结果显示：只有Parent7初始化，而Son7并没有初始化。 上述代码也印证了，在创建实例时以及启动类时，会导致类的初始化；当一个类初始化时，会先初始化它的父类。 NO.61234567891011121314151617181920public class MyTest8 &#123; public static void main(String[] args) &#123; //System.out.println(Son8.a); Son8.doSomething(); &#125;&#125;class Parent8&#123; static int a = 1; static &#123; System.out.println("Parent8 invoked"); &#125; static void doSomething()&#123; System.out.println("Parent8'doSomething"); &#125;&#125;class Son8 extends Parent8&#123; static &#123; System.out.println("Son8 invoked"); &#125;&#125; 输出结果： 12Parent8 invokedParent8'doSomething 输出结果显示：Parent8被初始化了。 调用类的静态方法时，会导致类的初始化。 NO.712345678910111213141516171819202122232425262728293031public class StaticTest&#123; public static void main(String[] args) &#123; staticFunction(); &#125; static StaticTest st = new StaticTest(); static &#123; System.out.println("1"); &#125; &#123; System.out.println("2"); &#125; StaticTest() &#123; System.out.println("3"); System.out.println("a="+a+",b="+b); &#125; public static void staticFunction()&#123; System.out.println("4"); &#125; int a=110; static int b =112;&#125; 输出结果： 1234523a=110,b=014 在准备阶段： st = null，b = 0 调用类的静态方法、且为启动类，将类进行初始化，顺序执行静态语句： 初始化st 首先执行代码块，打印出2 然后执行构造方法，打印3，以及a=110，此时b还未初始化，即b=0 执行静态代码块，打印出1 执行静态方法： 打印出4 NO.81234567891011121314151617181920public class MyTest9 &#123; public static void main(String[] args) throws ClassNotFoundException &#123; //获取一个系统加载器 ClassLoader classLoader = ClassLoader.getSystemClassLoader(); //使用这个加载器去加载ClassLoad类，得到一个class对象 Class&lt;?&gt; aClass = classLoader.loadClass("classLoader.ClassLoad"); System.out.println(aClass); System.out.println("-----------"); //使用反射获取class对象 Class&lt;?&gt; aClass1 = Class.forName("classLoader.ClassLoad"); System.out.println(aClass1); System.out.println(aClass == aClass1); &#125;&#125;class ClassLoad&#123; static &#123; System.out.println("CL invoked"); &#125;&#125; 输出结果： 12345class classLoader.ClassLoad-----------CL invokedclass classLoader.ClassLoadtrue 关于类加载器（类加载机制（三）：类的加载与类加载器） 可以看出调用ClassLoader类的loadClass方法加载一个类，并不是对类的主动使用，不会导致类的初始化。而使用反射则是对类的主动使用，会触发初始化，并且两个class对象是同一个，这也印证了前文所说的class对象在内存中只会存在一个的说法。 结论​ 类的初始化是类加载过程的最后阶段，在前面的类加载过程中，都是有虚拟机来进行主导和控制（除了用户可以自定义类加载外，请看我后续博客），到了初始化阶段，才真正开始执行Java程序中的字节码。 ​ 在连接中的准备阶段，静态变量被赋予了默认值，到了初始化阶段，这些变量才被赋予真正的值。在对类进行初始化时，Java虚拟机会按照初始化语句在类文件中的先后顺序来一次执行它们。 ​ 一个类只有在被首次主动使用才会触发初始化阶段，也只有上文提到的七种方式才算主动使用，其他都是被动使用。]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
        <tag>类的初始化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类加载机制（一）：简述类加载过程]]></title>
    <url>%2F2019%2F03%2F13%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E7%AE%80%E8%BF%B0%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%2F%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E7%AE%80%E8%BF%B0%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[类加载机制（一）：简述类加载过程引言Java源文件经过编译之后，生成了一连串的16进制的字节码，即以.class结尾的文件，而这些描述了Java程序各种信息的字节码，还必须要加载到Java虚拟机之后，才能被运行及使用，而加载class文件的过程就是jvm的类加载机制。 类加载过程与大多数语言一样，Java类型也需要加载、连接与初始化，而不同的是，在Java代码中，类型的这些过程都是在程序运行期所完成的。这个加载过程分为加载、连接（验证、准备、解析）、初始化,整个过程简单来说： 加载：查找并加载类的二进制数据，即加载class文件 连接： —-验证：确保被加载的类的正确性 —-准备：为类的静态变量分配内存，并将其设置为默认值 —-解析：将类中的符号引用转换为直接引用 初始化：顺序执行静态代码，即为类的静态变量赋予正确的初始值以及执行静态代码块 类的加载类的加载指的是将类的class文件中的二进制数据从硬盘读取到内存中，将其放置在运行时数据区的方法区（虚拟机规范并未要求，但hotspot虚拟机将其放置在虚拟机中）内，然后在内存中创建唯一一个类的class对象，用以封装类在方法区中的数据结构，无论new出多少个对象，最终对应的class对象只有一个。 类的加载方式加载.class文件的方式 —-从本地文件系统中加载 —-通过网络下载.class文件 —-从jar，war等归档文件中加载.class文件 —-从专有数据库中提取.class文件 —-将Java源文件动态编译为.class文件 编写一个MyCat类，添加虚拟机参数-XX:+TraceClassLoading参数，运行代码，可以看出，MyCat类被虚拟机从本地文件系统加载到内存中。 12345678&gt; jvm虚拟机参数：都以-XX:开始&gt; -XX:+&lt;option&gt; 表示开启option选项 ,&gt; -XX:-&lt;option&gt; 表示关闭option选项，&gt; -XX:&lt;option&gt;=&lt;value&gt;,表示将option值设置为value&gt; &gt; -XX:+TraceClassLoading&gt; 有时候我们需要监控系统中哪些类被加载进来，什么样的类加载的比较频繁，什么样的类加载的比较少，可以使用这个参数来配置打印出程序执行过程中类的加载信息。&gt; 类加载器类的加载是通过类加载器来加载的，虚拟机中有两种类型的加载器。 Java虚拟机自带的加载器 —-根类加载器（Bootstrap） —-扩展类加载器（Extension） —-系统（应用）加载器（System） 用户自定义的类加载器 —-java.lang.classLoader的子类 —-用户可以定制类的加载方式 后续请看我的关于类加载器的文章 类加载机制（三）：类的加载与类加载器 类加载机制（四）：解析ClassLoader 类加载机制（五）：自定义类加载器与深入双亲委托机制 类加载机制（六）：getSystemClassLoader与Launcher 类加载机制（七）：线程上下文类加载器 类的连接类被加载后，就进入连接阶段。连接就是将已经加载到内存中的类的二进制数据合并到虚拟机的运行时环境中。 类的验证类的验证的内容 —-类文件的结构检查 —-语义检查 —-字节码验证 —-二进制兼容性的验证 类的准备将静态变量设置为默认值，而实例变量将会在对象实例化时随着对象一起分配到Java堆中去。 类的解析将类中的符号引用转换为直接引用，（摘自深入理解JAVA虚拟机）。 符号引用： 符号引用：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义的定位到目标即可。在Java中，一个java类将会编译成一个class文件。在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。比如org.simple.People类引用了org.simple.Language类，在编译时People类并不知道Language类的实际内存地址，因此只能使用符号org.simple.Language（假设是这个，当然实际中是由类似于CONSTANT_Class_info的常量来表示的）来表示Language类的地址。各种虚拟机实现的内存布局可能有所不同，但是它们能接受的符号引用都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用： 直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同。有了直接引用，那引用的目标必定已经在内存中存在。 类的初始化到了初始化阶段，才真正开始执行类中定义的Java代码，在初始化阶段，就会为类变量赋予正确的初始值。 后续请看我的关于类的初始化的文章。 类加载机制（二）：类的初始化]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashSet解析]]></title>
    <url>%2F2019%2F03%2F09%2FHashSet%E8%A7%A3%E6%9E%90%2FHashSet%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[HashSet解析基本用法 HashSet实现了Set接口，Set表示无重复元素、且不保证访问顺序的容器接口。与HashMap类似，它有如下的构造方法。 123456789public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public HashSet(Collection&lt;? extends E&gt; c) &#123;map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;public HashSet(int initialCapacity, float loadFactor) &#123;map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;public HashSet(int initialCapacity) &#123;map = new HashMap&lt;&gt;(initialCapacity);&#125; initialCapacity（初始容量，默认16），loadFactor（负载因子，默认0.75）与HashMap中的含义是一样的。 HashSet的用法也很简单。 1234567891011121314151617List a= new ArrayList(); a.add(1); a.add(1); //直接传入个容器类进去 Set c = new HashSet&lt;&gt;(a); Iterator iterator = c.iterator(); while (iterator.hasNext()) &#123; System.out.println(iterator.next()); &#125; 因为HashSet中是无重复元素的，所以结果为1。这个特性可以将其用于去重。 基本原理HashSet其实就是HashMap实现的，在HashSet内部有个HashMap实例变量。 1private transient HashMap&lt;E,Object&gt; map; 还有个常量。在Map中有key，有value，而在HashSet中相当于只有key，所有的value都是这个常量。 1private static final Object PRESENT = new Object(); 再来看看add(E e)方法 12345 public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 直接调用HashMap的put方法，将元素作为key，常量PRESENT作为value存入，null值也可以存入，若集合中已有元素，则保持集合不变返回false。 检查也是HashMap的方法： 12345public boolean contains(Object o) &#123; return map.containsKey(o);&#125; 检查map中是否有对应的key。 删除也是HashMap的方法： 12345public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; 删除对应key的节点。 结论HashSet原理较为简单，实现了Set接口，内部维护了一个HashMap，特点是无重复元素，元素无顺序，可以用于去重，集合运算，若想了解更深层次的，可以看看HashMap的实现。]]></content>
      <tags>
        <tag>HashSet</tag>
        <tag>容器类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap解析之hash(key)]]></title>
    <url>%2F2019%2F03%2F07%2FHashMap%E8%A7%A3%E6%9E%90%E4%B9%8Bhash(key)%2FHashMap%E8%A7%A3%E6%9E%90%E4%B9%8Bhash(key)%2F</url>
    <content type="text"><![CDATA[HashMap解析之hash(key)引言 HashMap是Map接口的一个实现类，它的实现方式利用了hash，使用了数组链表的形式来存储数据，HashMap内部维护了一个Node&lt;k,v&gt;类型的数组table（哈希表），每个元素table[i]指向一个单向链表，根据键存取值，通过相应的运算得到数组中的索引位置,然后再操作table[i]指向的单向链表。这个数组在初次使用的时候会被初始化，并且，数组长度为2的次方数。 1transient Node&lt;K,V&gt;[] table; 在HashMap中，它是一种数组链表的形式，每个存入的元素被包装成一个Node,Node是一个内部类，源码如下： 123456789101112131415161718192021222324252627static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + "=" + value; &#125; 123456789101112131415161718192021222324252627282930313233343536373839 public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 在Node中，维护了节点元素、元素的key、key的hash值，以及下一个节点next，这种方式就构成了一个单向链表的形式。 hash（key）先来看看put方法： 1234567public V put(K key, V value) &#123; //计算出key的hash值，一起传入 return putVal(hash(key), key, value, false, true);&#125; 方便讲解，直接给出结论。 向HashMap中put、get、remove元素时，是根据节点的key的hash值来对哈希表进行操作的，那是如何通过hash值来进行索引的呢，先看看hash(key)的源码： 12345678910111213141516171819//由节点的key值计算 static final int hash(Object key) &#123; int h; //若key为null，则hash值为0，所以在HashCode中key值可以为空； // 否则，将key的hashcode值与hashcode的右移16位进行异或 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;------------------------------------------//根据hash值取得对应的节点tab[i = (n - 1) &amp; hash] 计算过程如下： 了解了hash值的计算过程以及如何存取节点到数组中后，应该要知道为什么需要这样来建立索引？ 因为数组索引是由hash值确定的，所以最重要的就是避免hash冲突，即以上的这些对hashCode的操作都是为了避免hash冲突，使节点在数组中分布均匀。 针对这个计算过程，提出三个问题（此处参考原PO） 1.为什么不直接采用经过hashCode（）处理的哈希码作为存储数组table的下标位置？ 2.为什么采用哈希码与运算(&amp;)（数组长度-1）计算数组下标？ 3.为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？ 第一个问题 因为直接算出来的hashCode值是2进制的32位数，要是直接使用这个数的话，就可能会出现hashCode的值远远大于数组实际元素个数，这样节点分布就会极不均匀，并且也浪费了大量的空间，所以，采用哈希码与运算(&amp;)（数组长度-1）计算数组下标。 第二个问题 1.数组长度-1 数组长度=2的幂=（二进制表示）100…00的形式=首位为1、后面均为0。要是直接去&amp;哈希码，会有如下几个后果。 （1）算出的下标值就会集中于某几位，这样增大了hash冲突的可能性。 （2）数组长度为偶数，最后一位0，&amp;出结果肯定为偶数，这样浪费了一半空间，而且也增大了hash冲突的可能性。 (数组长度-1)=（二进制表示）011…11的形式=首位为0、后面均为1。 （1）这样&amp;出的结果，就会由hash码的低位来决定，并且最后一位为1，&amp;出的结果是奇数还是偶数，由hash码的最后以为决定。 2.&amp;运算 hash码与运算数组长度 实际上=将hash值对数组长度取模，减小索引的值。为了提高效率，采用位运算&amp;，只有但数组长度=2的幂次方时，h&amp;(n-1)才等价与h%n。 这样做的结果，都是为了让&amp;出的结果，由hash码来控制，能让结果更加的均匀。 第三个问题 因为一般数组长度只会对应hash码的后几位，这样求出的结果也会易造成hash冲突，经过移位运算，得到的hash码更加均匀，提高了数组索引的随机性和均匀性。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>容器类</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList原理解析]]></title>
    <url>%2F2019%2F03%2F04%2FLinkedList%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2FLinkedList%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LinkedList原理解析 在前面我们对ArrayList(See my ArrayList原理解析 page for details.)已做了解析，ArrayList操作维护的是内部数组，元素在内存中是连续存放的，可以通过索引直接访问，访问效率高，但是对于删除和移动来说，性能就较低了。而LinkedList呢，顾名思义，它是一个链表，更确切的说，它是一个双向链表，因为LinkedList的元素都是单独存放的，元素之间在逻辑上通过链接连在一起，下面，我们就解析下LinkedList的原理。 在LinkedList中元素以节点（Node）的方式进行存储： 12345678910111213141516171819202122232425 private static class Node&lt;E&gt; &#123; //代表本节点元素 E item; //代表后继元素 Node&lt;E&gt; next; //代表前驱元素 Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 在LinkedList中有个内部类Node,它来表示LinkedList中的元素。而在其内部也保存着当前节点的前驱和后继两个节点。 在LinkedList中维护着三个变量： 12345 transient int size = 0;transient Node&lt;E&gt; first;transient Node&lt;E&gt; last; LinkedList的长度，头节点以及尾节点。LinkedList里的操作大都是围绕着这三个变量来进行的。我们先从add方法看起。 1234567 public boolean add(E e) &#123; linkLast(e); return true;&#125; Ladd(E e)方法，将调用linkLast(E e)方法，插入新节点。 123456789101112131415161718192021 void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; 第一步：创建新节点，前驱节点指向尾节点，后继节点为空。 1final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); 第二步：令尾节点为这个新建的节点；若原来链表为空，则头节点指向新节点；非空，则尾节点的后继节点指向新节点；链表长度加1；modCount加1，用于迭代时判断链表的结构变化。 这是在链表末尾进行插入，若要指定位置插入呢？再看看另外一个add(int index,E element)方法 1234567891011121314151617 public void add(int index, E element) &#123; //检查索引值是否满足index &gt;= 0 &amp;&amp; index &lt;= size checkPositionIndex(index); //若index值与链表长度相同，则插入到链表末尾。 if (index == size) linkLast(element); else linkBefore(element, node(index));&#125; 检查完毕，并且想要插入的位置与链表长度包不同，这调用linkBefore方法进行插入。 因为链表无法向数组那样可以直接查找索引，进行插入，所以要根据索引值查找到对应的节点，在这里调用了node方法来查找节点值 123456789101112131415161718192021222324252627 Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 与链表长度的一半来进行比较，若index小于链表长度的一半，则从头开始；反之，则从尾节点开始。最后返回找到对应索引值的节点。 找到index对应的节点后，就可以插入了。 12345678910111213141516171819202122232425 void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; //如果index节点为头节点，则新节点为头节点；不然则插入到index节点之前 if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125; 在中间插入，LinkedList只需要分配内存就行，而ArrayList则需要其他空间，还要移动后续的元素。 我们再来看看remove(int index)方法。 1234567 public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125; remove(int index)方法同样也需要检查index值，然后找到index值对应的节点，最后调用unlink删除节点后，返回删除的节点。 123456789E unlink(Node&lt;E&gt; x) &#123;// assert x != null;final E element = x.item;final Node&lt;E&gt; next = x.next;final Node&lt;E&gt; prev = x.prev; 1234567891011if (prev == null) &#123; first = next;&#125; else &#123; prev.next = next; x.prev = null;&#125; 1234567891011if (next == null) &#123; last = prev;&#125; else &#123;j next.prev = prev; x.next = null;&#125; 123456789 x.item = null; size--; modCount++; return element;&#125; remove(int index)方法的基本思路也很简单：将删除节点x的前驱节点指向x的后继节点，将x的候后继节点的前驱节点指向x的前驱节点。 首先，若x的前驱节点为空，即x为头节点，则x的后继自然就是头节点了。 然后，若x的后继节点为空，即x为尾节点，则x的前驱自然就是头节点了。 结论以上，我们介绍了LinkedList的几个方法，其余方法也都类似，就是链表的一些基本操作。LinkedList内部是以node节点的方式来进行维护的，每个节点内部又有前驱和后继节点，这就相当于一个双向链表，并且在内部还维护着头节点、尾节点以及长度。通过这些，可以得出一些关于LinkedList的一些特点： (1)LinkedList不需要预先分配空间，按需进行分配; (2)进行头、尾的插入很方便; (3)按索引插入，时间复杂度较低，为O(N/2),但插入效率较高，为O(1); (4)查找的话，效率也较低，时间复杂度为O（N），不管是否已排序； (5)在两端进行查找、删除，时间复杂度为O(1); (6)在中间进行查找、删除，需要逐个比对，时间复杂度为O(N),但修改效率就只有O(1)。 综上，若进行的操作涉及大量的插入、删除，尤其是在两端的插入、删除，并且查找中间元素的操作较少的话，使用LinkedList是比较好的选择。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>容器类</tag>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList原理解析]]></title>
    <url>%2F2019%2F03%2F02%2FArrayList%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2FArrayList%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[ArrayList的基本原理 ArrayList是我们平时编码经常用到的动态数组容器类，要想分析它的原理，我们先来看看一个简易的DynamicArray类（摘自Java编程的逻辑） 一个简易的动态数组类1234567public static class DynamicArray&lt;E&gt;&#123; private static final int DEFAULT_CAPACITY = 10; private int size; private Object[] elementData; 1234567891011121314151617181920212223242526272829public Dynamicarray() &#123; this.elementData = new Object[DEFAULT_CAPACITY];&#125;public void ensureCapacity(int minCapacity)&#123; int oldCapacity = elementData.length; if(oldCapacity &gt;= minCapacity)&#123; return; &#125; int newCapacity = oldCapacity * 2; if(newCapacity &lt; minCapacity)&#123; newCapacity = minCapacity; &#125; elementData = Arrays.copyOf(elementData,newCapacity);&#125;public void add(E e)&#123; 1234567891011121314151617181920212223 ensureCapacity(size + 1); elementData[size++] = e; &#125; public E get(int index)&#123; return (E) elementData[index]; &#125; public E set(int index,E e)&#123; E e1 = get(index); elementData[index] = e; return e1; &#125;&#125; 在这个类中，定义了一个内部数组elementData，数组元素个数size，一个静态常量DEFAULT_CAPACITY,它表示数组的默认空间大小。这个动态数组类的操作基本都是基于内部数组element和size。ensureCapacity方法,在每次做add操作时，都会被调用，它是检查当前数组容量，并增大容量，然后根据新的容量，复制原来数组的。 ArrayList源码解析： ArrayList的基本原理与上文中的动态数组类是差不多的，它同样有静态常量默认空间，实例变量内部数组、元素个数。同样，内部方法基本都是操作elementData这个数组，size实时记录着这个数组的大小，首先我们从add方法说起（各源码内注释已说明白，就不再叙述）。 添加方法add(E e)： 1234567891011public boolean add(E e) &#123; //首先，调用ensureCapacityInternal方法，确保数组容量够。将当前元素个数加一，即最小容量minCapacity传入方法。 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125; 检查数组容量方法ensureCapacityInternal(int minCapacity)： 1234567891011121314151617181920212223private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123;//如果数组为空，则返回默认值与minCapacity之间的最大值 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; 1234567 //如果minCapacity大于当前数组的长度，就调用grow方法增大容量, if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125; modCount++表示内部的修改次数，而这个参数与arrayList的迭代有关,下篇博客再讲解。 增大数组容量grow方法(int minCapacity)： 1234567891011121314151617181920212223242526272829303132333435 private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; //定义一个新的容量newCapacity，它的值为当前容量右移一位，即除以2，再加上当前数组容量，即当前数组容量的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //如果还小于当前元素个数加一，新的容量就等于minCapacity if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //如果newCapacity大于一个静态常量MAX_ARRAY_SIZE，就调用hugeCapacity方法， 将newCapacity设定为Integer包装类的最大值0x7fffffff,其中MAX_ARRAY_SIZE为Integer.MAX_VALUE-8， 减8是因为在一些vm中，在数组中会保留一些头信息，尝试分配更大的数组可能导致OutOfMemoryError: 请求的数组大小超过VM限制 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: //以newCapacity为数组size，创建了一个新的数组，复制原内容，赋值给elementData elementData = Arrays.copyOf(elementData, newCapacity);&#125; 123456789101112131415private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); //如果minCapacity还大于MAX_ARRAY_SIZE，就返回Integer的最大值0x7fffffff return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 再来看看remove(int index)方法: 123public E remove(int index) &#123; rangeCheck(index); 12345678910111213141516171819modCount++;E oldValue = elementData(index);//计算出需要移动多少位int numMoved = size - index - 1;if (numMoved &gt; 0)//移动数组 System.arraycopy(elementData, index+1, elementData, index, numMoved);//将size减1，GC会回收未经使用的对象elementData[--size] = null; // clear to let GC do its work 123 return oldValue;&#125; 这里modCount依旧加一。 结论 上面，我们介绍了ArrayList的add和remove方法，其他方法也都是对内部数组elementData和元素个数size的操作，就不再探究了。总之，ArrayList就是一个动态数组，实现动态的原理，就是对内部的elementData、size和默认空间DEFAULT_CAPACITY进行操作。创建ArrayList时，会默认初始化一个DEFAULT_CAPACITY大小的数组。每次要做增加操作，就进行数组容量检查，若不够，就增加容量，做删除操作，size就减一，保持size实时记录当前元素个数。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>容器类</tag>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[包装类的缓存机制]]></title>
    <url>%2F2019%2F02%2F28%2F%E5%8C%85%E8%A3%85%E7%B1%BB%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%2F%E5%8C%85%E8%A3%85%E7%B1%BB%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[包装类的缓存机制与valueOf()引言Java有8种基本类型，每种都有一个包装类型，有很多静态方法、变量等，方便对数据进行操作。包装类可以由valueOf()静态方法去创建，也可以用new关键字去创建实例对象，但为什么推荐使用valueOf()来创建呢。 首先，我们来看一个例子: public class Test { public static void main(String[] args) { Integer a = 1; Integer b = 1; Integer c = 128; Integer d = 128; if(a == b){ System.out.println(&quot;a与b相同&quot;); } if(c == d){ System.out.println(&quot;c与d相同&quot;); } } } 运行结果 ​ a与b相同 c与d不相同 ​ 分析 这段代码创建了4个Integer类型的对象实例a、b、c、d，照常理来说，4个对象，其引用地址不同，此例子的输出应该都为不相同，但结果确是a与b相同，c与d不同，这是为什么？ 此处我们是采用自动装箱的方式来创建的Integer对象，而这相当于调用了valueOf()的方法，所以就得从valueOf()这个静态方法说起。 ###valueof的分析 首先，看看Integer的valueOf()方法的源码 public static Integer valueOf(int i) { if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } 分析 此段代码中如果不满足i&gt;=IntegerCache.low &amp;&amp; i&lt;= IntegerCache.high这个表达式，就通过new来得到对象，如果满足呢？ 再来看看IntegerCache类，IntegCache类是Integer类的一个内部静态类，其源码如下。 /** * Cache to support the object identity semantics of autoboxing for values between * -128 and 127 (inclusive) as required by JLS. * * The cache is initialized on first usage. The size of the cache * may be controlled by the {@code -XX:AutoBoxCacheMax=&lt;size&gt;} option. * During VM initialization, java.lang.Integer.IntegerCache.high property * may be set and saved in the private system properties in the * sun.misc.VM class. */ private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; } private IntegerCache() {} } 分析 首先，从Javadoc中看出这个类是用来实现缓存的。它定义了三个静态参数，缓存数组cache,数组最小值low，赋值为-128以及数组最大值high，最大值映射到了“java.lang.Integer.IntegerCache.high”上。 ，并支持 -128 到 127 之间的自动装箱过程。最大值 127 可以通过 JVM 的启动参数 -XX:AutoBoxCacheMax=size 修改。 修改jvm参数后 ​ 运行结果 ​ a与b相同 c与d不相同 结论IntegerCache这个Integer私有静态类代表Integer缓存，它在被首次主动使用时，会被初始化，static代码块中的会被执行，通过一个 for 循环创建出一个值为-128~127的一个缓存数组cache，以后，如果创建的值在low和high之间，就可以使用缓存中包含的实例对象，而不是创建一个新的实例(在自动装箱的情况下)。这种机制使我们可以根据应用程序的实际情况灵活地调整来提高性能。是什么原因选择这个 -128 到 127 这个范围呢？因为这个范围的整数值是使用最广泛的，通过使用共享对象，就可以节省内存空间了。在程序中第一次使用 Integer 的时候也需要一定的额外时间来初始化这个缓存。这种机制在其他包装类中也有类似的实现。这种缓存策略也是一种设计模式，叫做享元模式。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>容器类</tag>
        <tag>缓存机制</tag>
      </tags>
  </entry>
</search>
